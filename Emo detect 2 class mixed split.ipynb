{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZxMFyB4dErFs"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PoPt9VhQErF3"
   },
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Q7SyOV4GErF4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IdhOWUqOErF6"
   },
   "outputs": [],
   "source": [
    "mylist= os.listdir('Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pUzweG2GErF7"
   },
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_positive')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_positive')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_positive')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_positive')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_negative')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_negative')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_negative')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_negative')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_negative')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_negative')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_negative')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_negative')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_positive')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfyVmzKDJHWJ"
   },
   "source": [
    "# Новый раздел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b_s-sBUmErF9"
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('Data/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wPYnZSAFErF_"
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rLsRJqUiErF_"
   },
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "k7WkUEDSErGA"
   },
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "idKtBRkSErGB",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VayX3ZpFErGD"
   },
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1dDscrV6ErGF"
   },
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tJJqAdj4ErGF"
   },
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9rRGgLRCErGG"
   },
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bCIEcx4jErGG"
   },
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mR31cET1ErGH"
   },
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mA2lP4ABErGH",
    "outputId": "d732bcc7-40d2-4b1e-e69c-da53267660ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "AdIO0OdLErGK"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "k9HxzfsfErGL"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxGfDCriErGL",
    "outputId": "881aadb4-aff6-4f72-ba0e-629b802ffeac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 13828     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 343,428\n",
      "Trainable params: 343,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "A4inKfXiErGM"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zYXawkxErGN",
    "outputId": "8c6a7b9b-99f4-40cc-9fec-6853e79b9b0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 1.3602 - accuracy: 0.3627 - val_loss: 1.2787 - val_accuracy: 0.4305\n",
      "Epoch 2/700\n",
      "95/95 [==============================] - 9s 99ms/step - loss: 1.2169 - accuracy: 0.4924 - val_loss: 1.1887 - val_accuracy: 0.5313\n",
      "Epoch 3/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 1.1397 - accuracy: 0.5169 - val_loss: 1.1252 - val_accuracy: 0.5504\n",
      "Epoch 4/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 1.0867 - accuracy: 0.5288 - val_loss: 1.0831 - val_accuracy: 0.5477\n",
      "Epoch 5/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 1.0405 - accuracy: 0.5533 - val_loss: 1.0337 - val_accuracy: 0.5586\n",
      "Epoch 6/700\n",
      "95/95 [==============================] - 10s 100ms/step - loss: 1.0056 - accuracy: 0.5381 - val_loss: 1.0044 - val_accuracy: 0.5259\n",
      "Epoch 7/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.9807 - accuracy: 0.5433 - val_loss: 0.9753 - val_accuracy: 0.5695\n",
      "Epoch 8/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.9585 - accuracy: 0.5566 - val_loss: 1.0037 - val_accuracy: 0.5559\n",
      "Epoch 9/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.9396 - accuracy: 0.5665 - val_loss: 0.9372 - val_accuracy: 0.5477\n",
      "Epoch 10/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.9188 - accuracy: 0.5711 - val_loss: 0.9311 - val_accuracy: 0.5504\n",
      "Epoch 11/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.9089 - accuracy: 0.5811 - val_loss: 0.9072 - val_accuracy: 0.5668\n",
      "Epoch 12/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.9008 - accuracy: 0.5685 - val_loss: 0.9146 - val_accuracy: 0.5559\n",
      "Epoch 13/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.8844 - accuracy: 0.5811 - val_loss: 0.9354 - val_accuracy: 0.5204\n",
      "Epoch 14/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.8842 - accuracy: 0.5831 - val_loss: 0.8777 - val_accuracy: 0.5913\n",
      "Epoch 15/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.8715 - accuracy: 0.5870 - val_loss: 0.9081 - val_accuracy: 0.5123\n",
      "Epoch 16/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.8607 - accuracy: 0.5897 - val_loss: 0.8889 - val_accuracy: 0.5722\n",
      "Epoch 17/700\n",
      "95/95 [==============================] - 12s 126ms/step - loss: 0.8611 - accuracy: 0.5745 - val_loss: 0.8570 - val_accuracy: 0.5858\n",
      "Epoch 18/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.8514 - accuracy: 0.5784 - val_loss: 0.8971 - val_accuracy: 0.5586\n",
      "Epoch 19/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.8451 - accuracy: 0.6082 - val_loss: 0.8460 - val_accuracy: 0.6158\n",
      "Epoch 20/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.8399 - accuracy: 0.6016 - val_loss: 0.8390 - val_accuracy: 0.5913\n",
      "Epoch 21/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.8365 - accuracy: 0.6036 - val_loss: 0.8535 - val_accuracy: 0.5695\n",
      "Epoch 22/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.8297 - accuracy: 0.6102 - val_loss: 0.8338 - val_accuracy: 0.6049\n",
      "Epoch 23/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.8279 - accuracy: 0.6029 - val_loss: 0.8497 - val_accuracy: 0.5804\n",
      "Epoch 24/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.8253 - accuracy: 0.6016 - val_loss: 0.8365 - val_accuracy: 0.5858\n",
      "Epoch 25/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.8183 - accuracy: 0.6062 - val_loss: 0.8255 - val_accuracy: 0.5967\n",
      "Epoch 26/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.8151 - accuracy: 0.6135 - val_loss: 0.8231 - val_accuracy: 0.5995\n",
      "Epoch 27/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.8108 - accuracy: 0.6023 - val_loss: 0.8392 - val_accuracy: 0.5886\n",
      "Epoch 28/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.8086 - accuracy: 0.6062 - val_loss: 0.8640 - val_accuracy: 0.5531\n",
      "Epoch 29/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.8086 - accuracy: 0.6109 - val_loss: 0.8285 - val_accuracy: 0.6022\n",
      "Epoch 30/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7978 - accuracy: 0.6135 - val_loss: 0.8404 - val_accuracy: 0.5613\n",
      "Epoch 31/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.8002 - accuracy: 0.6089 - val_loss: 0.8239 - val_accuracy: 0.5749\n",
      "Epoch 32/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7967 - accuracy: 0.6274 - val_loss: 0.8154 - val_accuracy: 0.6022\n",
      "Epoch 33/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7920 - accuracy: 0.6168 - val_loss: 0.8023 - val_accuracy: 0.5858\n",
      "Epoch 34/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7911 - accuracy: 0.6234 - val_loss: 0.8269 - val_accuracy: 0.5967\n",
      "Epoch 35/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7907 - accuracy: 0.6267 - val_loss: 0.7966 - val_accuracy: 0.6104\n",
      "Epoch 36/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7886 - accuracy: 0.6188 - val_loss: 0.8104 - val_accuracy: 0.5886\n",
      "Epoch 37/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7845 - accuracy: 0.6161 - val_loss: 0.8142 - val_accuracy: 0.5995\n",
      "Epoch 38/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7838 - accuracy: 0.6135 - val_loss: 0.7990 - val_accuracy: 0.6104\n",
      "Epoch 39/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7791 - accuracy: 0.6214 - val_loss: 0.8447 - val_accuracy: 0.5831\n",
      "Epoch 40/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7832 - accuracy: 0.6267 - val_loss: 0.7937 - val_accuracy: 0.6049\n",
      "Epoch 41/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7805 - accuracy: 0.6208 - val_loss: 0.7934 - val_accuracy: 0.5913\n",
      "Epoch 42/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7742 - accuracy: 0.6254 - val_loss: 0.8131 - val_accuracy: 0.5913\n",
      "Epoch 43/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7741 - accuracy: 0.6248 - val_loss: 0.8213 - val_accuracy: 0.5668\n",
      "Epoch 44/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7739 - accuracy: 0.6353 - val_loss: 0.7849 - val_accuracy: 0.6158\n",
      "Epoch 45/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7710 - accuracy: 0.6294 - val_loss: 0.8192 - val_accuracy: 0.5995\n",
      "Epoch 46/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7682 - accuracy: 0.6334 - val_loss: 0.8223 - val_accuracy: 0.5831\n",
      "Epoch 47/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7677 - accuracy: 0.6148 - val_loss: 0.7971 - val_accuracy: 0.5940\n",
      "Epoch 48/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7632 - accuracy: 0.6459 - val_loss: 0.7812 - val_accuracy: 0.6240\n",
      "Epoch 49/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7600 - accuracy: 0.6439 - val_loss: 0.7763 - val_accuracy: 0.6076\n",
      "Epoch 50/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7614 - accuracy: 0.6261 - val_loss: 0.8289 - val_accuracy: 0.5831\n",
      "Epoch 51/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7628 - accuracy: 0.6294 - val_loss: 0.7857 - val_accuracy: 0.6076\n",
      "Epoch 52/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7617 - accuracy: 0.6327 - val_loss: 0.7795 - val_accuracy: 0.6104\n",
      "Epoch 53/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7529 - accuracy: 0.6367 - val_loss: 0.7937 - val_accuracy: 0.6049\n",
      "Epoch 54/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7535 - accuracy: 0.6492 - val_loss: 0.8190 - val_accuracy: 0.5858\n",
      "Epoch 55/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7531 - accuracy: 0.6347 - val_loss: 0.7899 - val_accuracy: 0.5831\n",
      "Epoch 56/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7574 - accuracy: 0.6360 - val_loss: 0.8050 - val_accuracy: 0.5995\n",
      "Epoch 57/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7523 - accuracy: 0.6314 - val_loss: 0.8020 - val_accuracy: 0.5804\n",
      "Epoch 58/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7491 - accuracy: 0.6439 - val_loss: 0.7729 - val_accuracy: 0.6294\n",
      "Epoch 59/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.7449 - accuracy: 0.6420 - val_loss: 0.7765 - val_accuracy: 0.6158\n",
      "Epoch 60/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.7488 - accuracy: 0.6439 - val_loss: 0.7702 - val_accuracy: 0.6104\n",
      "Epoch 61/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7490 - accuracy: 0.6393 - val_loss: 0.7853 - val_accuracy: 0.5967\n",
      "Epoch 62/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.7460 - accuracy: 0.6367 - val_loss: 0.7885 - val_accuracy: 0.5940\n",
      "Epoch 63/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7451 - accuracy: 0.6393 - val_loss: 0.7866 - val_accuracy: 0.5777\n",
      "Epoch 64/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7449 - accuracy: 0.6439 - val_loss: 0.7806 - val_accuracy: 0.6022\n",
      "Epoch 65/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7467 - accuracy: 0.6433 - val_loss: 0.7685 - val_accuracy: 0.6049\n",
      "Epoch 66/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7408 - accuracy: 0.6426 - val_loss: 0.7726 - val_accuracy: 0.6131\n",
      "Epoch 67/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7425 - accuracy: 0.6347 - val_loss: 0.7793 - val_accuracy: 0.5940\n",
      "Epoch 68/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7401 - accuracy: 0.6433 - val_loss: 0.7728 - val_accuracy: 0.6049\n",
      "Epoch 69/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7309 - accuracy: 0.6519 - val_loss: 0.7812 - val_accuracy: 0.6104\n",
      "Epoch 70/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7377 - accuracy: 0.6559 - val_loss: 0.7902 - val_accuracy: 0.6076\n",
      "Epoch 71/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7409 - accuracy: 0.6367 - val_loss: 0.7714 - val_accuracy: 0.6131\n",
      "Epoch 72/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7321 - accuracy: 0.6479 - val_loss: 0.8189 - val_accuracy: 0.5668\n",
      "Epoch 73/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7331 - accuracy: 0.6473 - val_loss: 0.7676 - val_accuracy: 0.6213\n",
      "Epoch 74/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7339 - accuracy: 0.6380 - val_loss: 0.7762 - val_accuracy: 0.6076\n",
      "Epoch 75/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7352 - accuracy: 0.6532 - val_loss: 0.8063 - val_accuracy: 0.5777\n",
      "Epoch 76/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7286 - accuracy: 0.6499 - val_loss: 0.7785 - val_accuracy: 0.6049\n",
      "Epoch 77/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7263 - accuracy: 0.6532 - val_loss: 0.7542 - val_accuracy: 0.6240\n",
      "Epoch 78/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7261 - accuracy: 0.6519 - val_loss: 0.7549 - val_accuracy: 0.6185\n",
      "Epoch 79/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7251 - accuracy: 0.6552 - val_loss: 0.7962 - val_accuracy: 0.5940\n",
      "Epoch 80/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7245 - accuracy: 0.6459 - val_loss: 0.7730 - val_accuracy: 0.6185\n",
      "Epoch 81/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7238 - accuracy: 0.6651 - val_loss: 0.7701 - val_accuracy: 0.6022\n",
      "Epoch 82/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.7183 - accuracy: 0.6532 - val_loss: 0.7808 - val_accuracy: 0.6131\n",
      "Epoch 83/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.7256 - accuracy: 0.6486 - val_loss: 0.7544 - val_accuracy: 0.6213\n",
      "Epoch 84/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.7193 - accuracy: 0.6492 - val_loss: 0.8017 - val_accuracy: 0.5831\n",
      "Epoch 85/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7255 - accuracy: 0.6545 - val_loss: 0.7585 - val_accuracy: 0.6131\n",
      "Epoch 86/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7132 - accuracy: 0.6545 - val_loss: 0.7558 - val_accuracy: 0.6213\n",
      "Epoch 87/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7194 - accuracy: 0.6664 - val_loss: 0.7845 - val_accuracy: 0.6022\n",
      "Epoch 88/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7122 - accuracy: 0.6506 - val_loss: 0.7921 - val_accuracy: 0.5913\n",
      "Epoch 89/700\n",
      "95/95 [==============================] - 12s 132ms/step - loss: 0.7155 - accuracy: 0.6539 - val_loss: 0.7512 - val_accuracy: 0.6104\n",
      "Epoch 90/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.7186 - accuracy: 0.6578 - val_loss: 0.7455 - val_accuracy: 0.6104\n",
      "Epoch 91/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.7097 - accuracy: 0.6664 - val_loss: 0.7464 - val_accuracy: 0.6267\n",
      "Epoch 92/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7145 - accuracy: 0.6499 - val_loss: 0.7986 - val_accuracy: 0.5967\n",
      "Epoch 93/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.7117 - accuracy: 0.6711 - val_loss: 0.7575 - val_accuracy: 0.6213\n",
      "Epoch 94/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.7095 - accuracy: 0.6612 - val_loss: 0.7543 - val_accuracy: 0.6185\n",
      "Epoch 95/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.7124 - accuracy: 0.6519 - val_loss: 0.7701 - val_accuracy: 0.6049\n",
      "Epoch 96/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7119 - accuracy: 0.6618 - val_loss: 0.7622 - val_accuracy: 0.5995\n",
      "Epoch 97/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7083 - accuracy: 0.6545 - val_loss: 0.7422 - val_accuracy: 0.6049\n",
      "Epoch 98/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6973 - accuracy: 0.6850 - val_loss: 0.7493 - val_accuracy: 0.6104\n",
      "Epoch 99/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.7068 - accuracy: 0.6664 - val_loss: 0.7465 - val_accuracy: 0.6376\n",
      "Epoch 100/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.7104 - accuracy: 0.6559 - val_loss: 0.7617 - val_accuracy: 0.6240\n",
      "Epoch 101/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.7059 - accuracy: 0.6525 - val_loss: 0.7659 - val_accuracy: 0.6049\n",
      "Epoch 102/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.7008 - accuracy: 0.6678 - val_loss: 0.7636 - val_accuracy: 0.6158\n",
      "Epoch 103/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6971 - accuracy: 0.6664 - val_loss: 0.7860 - val_accuracy: 0.5967\n",
      "Epoch 104/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6988 - accuracy: 0.6717 - val_loss: 0.7511 - val_accuracy: 0.6376\n",
      "Epoch 105/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.7010 - accuracy: 0.6678 - val_loss: 0.7604 - val_accuracy: 0.6022\n",
      "Epoch 106/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6955 - accuracy: 0.6724 - val_loss: 0.7364 - val_accuracy: 0.6240\n",
      "Epoch 107/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6981 - accuracy: 0.6744 - val_loss: 0.7386 - val_accuracy: 0.6322\n",
      "Epoch 108/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6929 - accuracy: 0.6631 - val_loss: 0.7372 - val_accuracy: 0.6267\n",
      "Epoch 109/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6942 - accuracy: 0.6724 - val_loss: 0.7443 - val_accuracy: 0.6267\n",
      "Epoch 110/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6942 - accuracy: 0.6605 - val_loss: 0.7452 - val_accuracy: 0.6294\n",
      "Epoch 111/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6915 - accuracy: 0.6605 - val_loss: 0.7530 - val_accuracy: 0.6076\n",
      "Epoch 112/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6944 - accuracy: 0.6612 - val_loss: 0.7470 - val_accuracy: 0.6049\n",
      "Epoch 113/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.6919 - accuracy: 0.6585 - val_loss: 0.7392 - val_accuracy: 0.6158\n",
      "Epoch 114/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6861 - accuracy: 0.6764 - val_loss: 0.7387 - val_accuracy: 0.6431\n",
      "Epoch 115/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6840 - accuracy: 0.6724 - val_loss: 0.7340 - val_accuracy: 0.6322\n",
      "Epoch 116/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.6853 - accuracy: 0.6731 - val_loss: 0.7328 - val_accuracy: 0.6403\n",
      "Epoch 117/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6820 - accuracy: 0.6797 - val_loss: 0.7501 - val_accuracy: 0.6213\n",
      "Epoch 118/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6854 - accuracy: 0.6777 - val_loss: 0.7309 - val_accuracy: 0.6322\n",
      "Epoch 119/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6897 - accuracy: 0.6757 - val_loss: 0.7493 - val_accuracy: 0.6049\n",
      "Epoch 120/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.6801 - accuracy: 0.6757 - val_loss: 0.8119 - val_accuracy: 0.5749\n",
      "Epoch 121/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6843 - accuracy: 0.6658 - val_loss: 0.7591 - val_accuracy: 0.6185\n",
      "Epoch 122/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6848 - accuracy: 0.6671 - val_loss: 0.7350 - val_accuracy: 0.6213\n",
      "Epoch 123/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.6791 - accuracy: 0.6770 - val_loss: 0.7270 - val_accuracy: 0.6267\n",
      "Epoch 124/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.6809 - accuracy: 0.6678 - val_loss: 0.7471 - val_accuracy: 0.6185\n",
      "Epoch 125/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.6801 - accuracy: 0.6803 - val_loss: 0.7846 - val_accuracy: 0.5967\n",
      "Epoch 126/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6734 - accuracy: 0.6757 - val_loss: 0.7819 - val_accuracy: 0.5695\n",
      "Epoch 127/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6711 - accuracy: 0.6790 - val_loss: 0.7427 - val_accuracy: 0.6267\n",
      "Epoch 128/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6772 - accuracy: 0.6790 - val_loss: 0.7683 - val_accuracy: 0.6049\n",
      "Epoch 129/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6803 - accuracy: 0.6684 - val_loss: 0.7515 - val_accuracy: 0.6131\n",
      "Epoch 130/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6747 - accuracy: 0.6731 - val_loss: 0.7491 - val_accuracy: 0.6158\n",
      "Epoch 131/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6798 - accuracy: 0.6757 - val_loss: 0.7294 - val_accuracy: 0.6403\n",
      "Epoch 132/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6730 - accuracy: 0.6731 - val_loss: 0.7593 - val_accuracy: 0.6131\n",
      "Epoch 133/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6738 - accuracy: 0.6764 - val_loss: 0.7280 - val_accuracy: 0.6267\n",
      "Epoch 134/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6733 - accuracy: 0.6724 - val_loss: 0.7340 - val_accuracy: 0.6240\n",
      "Epoch 135/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6722 - accuracy: 0.6790 - val_loss: 0.7372 - val_accuracy: 0.6322\n",
      "Epoch 136/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6721 - accuracy: 0.6777 - val_loss: 0.7629 - val_accuracy: 0.5967\n",
      "Epoch 137/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6677 - accuracy: 0.6817 - val_loss: 0.7416 - val_accuracy: 0.6294\n",
      "Epoch 138/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6657 - accuracy: 0.6896 - val_loss: 0.7674 - val_accuracy: 0.5995\n",
      "Epoch 139/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6639 - accuracy: 0.6896 - val_loss: 0.7227 - val_accuracy: 0.6294\n",
      "Epoch 140/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6661 - accuracy: 0.6777 - val_loss: 0.7429 - val_accuracy: 0.6485\n",
      "Epoch 141/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6610 - accuracy: 0.6982 - val_loss: 0.7314 - val_accuracy: 0.6158\n",
      "Epoch 142/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6634 - accuracy: 0.6870 - val_loss: 0.7235 - val_accuracy: 0.6267\n",
      "Epoch 143/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6603 - accuracy: 0.6856 - val_loss: 0.7777 - val_accuracy: 0.5858\n",
      "Epoch 144/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6618 - accuracy: 0.6837 - val_loss: 0.7319 - val_accuracy: 0.6240\n",
      "Epoch 145/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6553 - accuracy: 0.6982 - val_loss: 0.7374 - val_accuracy: 0.6131\n",
      "Epoch 146/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6600 - accuracy: 0.6803 - val_loss: 0.7234 - val_accuracy: 0.6349\n",
      "Epoch 147/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6563 - accuracy: 0.6863 - val_loss: 0.7396 - val_accuracy: 0.6294\n",
      "Epoch 148/700\n",
      "95/95 [==============================] - 12s 129ms/step - loss: 0.6574 - accuracy: 0.6929 - val_loss: 0.7339 - val_accuracy: 0.6240\n",
      "Epoch 149/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6545 - accuracy: 0.6936 - val_loss: 0.7287 - val_accuracy: 0.6322\n",
      "Epoch 150/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.6570 - accuracy: 0.6909 - val_loss: 0.7392 - val_accuracy: 0.6158\n",
      "Epoch 151/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6605 - accuracy: 0.6889 - val_loss: 0.7248 - val_accuracy: 0.6294\n",
      "Epoch 152/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6538 - accuracy: 0.6823 - val_loss: 0.7223 - val_accuracy: 0.6403\n",
      "Epoch 153/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6503 - accuracy: 0.6797 - val_loss: 0.7643 - val_accuracy: 0.6158\n",
      "Epoch 154/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6576 - accuracy: 0.6863 - val_loss: 0.7214 - val_accuracy: 0.6322\n",
      "Epoch 155/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.6497 - accuracy: 0.6936 - val_loss: 0.7704 - val_accuracy: 0.6104\n",
      "Epoch 156/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.6507 - accuracy: 0.6909 - val_loss: 0.7466 - val_accuracy: 0.6104\n",
      "Epoch 157/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6514 - accuracy: 0.7035 - val_loss: 0.7204 - val_accuracy: 0.6403\n",
      "Epoch 158/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6473 - accuracy: 0.6949 - val_loss: 0.7201 - val_accuracy: 0.6403\n",
      "Epoch 159/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6493 - accuracy: 0.6942 - val_loss: 0.7248 - val_accuracy: 0.6240\n",
      "Epoch 160/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6479 - accuracy: 0.6903 - val_loss: 0.7244 - val_accuracy: 0.6240\n",
      "Epoch 161/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6475 - accuracy: 0.6916 - val_loss: 0.7167 - val_accuracy: 0.6567\n",
      "Epoch 162/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.6457 - accuracy: 0.6962 - val_loss: 0.7246 - val_accuracy: 0.6294\n",
      "Epoch 163/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6446 - accuracy: 0.6837 - val_loss: 0.7136 - val_accuracy: 0.6322\n",
      "Epoch 164/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.6358 - accuracy: 0.6929 - val_loss: 0.7196 - val_accuracy: 0.6431\n",
      "Epoch 165/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6462 - accuracy: 0.6876 - val_loss: 0.7194 - val_accuracy: 0.6403\n",
      "Epoch 166/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6382 - accuracy: 0.6962 - val_loss: 0.7943 - val_accuracy: 0.5913\n",
      "Epoch 167/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6429 - accuracy: 0.7015 - val_loss: 0.7263 - val_accuracy: 0.6158\n",
      "Epoch 168/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6380 - accuracy: 0.7002 - val_loss: 0.7183 - val_accuracy: 0.6349\n",
      "Epoch 169/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6436 - accuracy: 0.6923 - val_loss: 0.7222 - val_accuracy: 0.6349\n",
      "Epoch 170/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6364 - accuracy: 0.6976 - val_loss: 0.7687 - val_accuracy: 0.5995\n",
      "Epoch 171/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6370 - accuracy: 0.7088 - val_loss: 0.7351 - val_accuracy: 0.6049\n",
      "Epoch 172/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6373 - accuracy: 0.6976 - val_loss: 0.7195 - val_accuracy: 0.6431\n",
      "Epoch 173/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6376 - accuracy: 0.6976 - val_loss: 0.7245 - val_accuracy: 0.6131\n",
      "Epoch 174/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6365 - accuracy: 0.6982 - val_loss: 0.7272 - val_accuracy: 0.6213\n",
      "Epoch 175/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6327 - accuracy: 0.6989 - val_loss: 0.7734 - val_accuracy: 0.6022\n",
      "Epoch 176/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6323 - accuracy: 0.6962 - val_loss: 0.7254 - val_accuracy: 0.6131\n",
      "Epoch 177/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6316 - accuracy: 0.6995 - val_loss: 0.7311 - val_accuracy: 0.6131\n",
      "Epoch 178/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6252 - accuracy: 0.6995 - val_loss: 0.7256 - val_accuracy: 0.6267\n",
      "Epoch 179/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6312 - accuracy: 0.7187 - val_loss: 0.7560 - val_accuracy: 0.6104\n",
      "Epoch 180/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.6364 - accuracy: 0.7148 - val_loss: 0.7326 - val_accuracy: 0.6485\n",
      "Epoch 181/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6261 - accuracy: 0.7042 - val_loss: 0.7235 - val_accuracy: 0.6240\n",
      "Epoch 182/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6330 - accuracy: 0.6949 - val_loss: 0.7167 - val_accuracy: 0.6403\n",
      "Epoch 183/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6232 - accuracy: 0.7015 - val_loss: 0.7161 - val_accuracy: 0.6512\n",
      "Epoch 184/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6279 - accuracy: 0.7015 - val_loss: 0.7165 - val_accuracy: 0.6376\n",
      "Epoch 185/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6269 - accuracy: 0.7114 - val_loss: 0.7403 - val_accuracy: 0.6076\n",
      "Epoch 186/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.6202 - accuracy: 0.7009 - val_loss: 0.7232 - val_accuracy: 0.6322\n",
      "Epoch 187/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.6227 - accuracy: 0.7035 - val_loss: 0.7141 - val_accuracy: 0.6349\n",
      "Epoch 188/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6192 - accuracy: 0.7075 - val_loss: 0.7612 - val_accuracy: 0.5967\n",
      "Epoch 189/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6202 - accuracy: 0.7002 - val_loss: 0.7299 - val_accuracy: 0.6294\n",
      "Epoch 190/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6217 - accuracy: 0.7101 - val_loss: 0.7530 - val_accuracy: 0.6185\n",
      "Epoch 191/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6144 - accuracy: 0.7201 - val_loss: 0.7292 - val_accuracy: 0.6213\n",
      "Epoch 192/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6104 - accuracy: 0.7201 - val_loss: 0.7484 - val_accuracy: 0.6049\n",
      "Epoch 193/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6186 - accuracy: 0.7095 - val_loss: 0.7247 - val_accuracy: 0.6185\n",
      "Epoch 194/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6145 - accuracy: 0.7194 - val_loss: 0.7159 - val_accuracy: 0.6403\n",
      "Epoch 195/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6121 - accuracy: 0.7148 - val_loss: 0.7149 - val_accuracy: 0.6267\n",
      "Epoch 196/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6191 - accuracy: 0.7068 - val_loss: 0.7234 - val_accuracy: 0.6240\n",
      "Epoch 197/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.6160 - accuracy: 0.7148 - val_loss: 0.7288 - val_accuracy: 0.6131\n",
      "Epoch 198/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.6064 - accuracy: 0.7253 - val_loss: 0.7115 - val_accuracy: 0.6376\n",
      "Epoch 199/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.6104 - accuracy: 0.7167 - val_loss: 0.7225 - val_accuracy: 0.6076\n",
      "Epoch 200/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6058 - accuracy: 0.7141 - val_loss: 0.7107 - val_accuracy: 0.6458\n",
      "Epoch 201/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6065 - accuracy: 0.7134 - val_loss: 0.7194 - val_accuracy: 0.6104\n",
      "Epoch 202/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6150 - accuracy: 0.7095 - val_loss: 0.7482 - val_accuracy: 0.6185\n",
      "Epoch 203/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6092 - accuracy: 0.7134 - val_loss: 0.7162 - val_accuracy: 0.6349\n",
      "Epoch 204/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6058 - accuracy: 0.7187 - val_loss: 0.7211 - val_accuracy: 0.6322\n",
      "Epoch 205/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6050 - accuracy: 0.7273 - val_loss: 0.7676 - val_accuracy: 0.6049\n",
      "Epoch 206/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6066 - accuracy: 0.7134 - val_loss: 0.7239 - val_accuracy: 0.6431\n",
      "Epoch 207/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6019 - accuracy: 0.7134 - val_loss: 0.7271 - val_accuracy: 0.6240\n",
      "Epoch 208/700\n",
      "95/95 [==============================] - 12s 128ms/step - loss: 0.5992 - accuracy: 0.7227 - val_loss: 0.7162 - val_accuracy: 0.6322\n",
      "Epoch 209/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6066 - accuracy: 0.7114 - val_loss: 0.7110 - val_accuracy: 0.6267\n",
      "Epoch 210/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.6025 - accuracy: 0.7267 - val_loss: 0.7130 - val_accuracy: 0.6431\n",
      "Epoch 211/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.6012 - accuracy: 0.7148 - val_loss: 0.7172 - val_accuracy: 0.6322\n",
      "Epoch 212/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6003 - accuracy: 0.7240 - val_loss: 0.7343 - val_accuracy: 0.6104\n",
      "Epoch 213/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5988 - accuracy: 0.7121 - val_loss: 0.7156 - val_accuracy: 0.6540\n",
      "Epoch 214/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.6015 - accuracy: 0.7121 - val_loss: 0.7136 - val_accuracy: 0.6267\n",
      "Epoch 215/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.5962 - accuracy: 0.7287 - val_loss: 0.7089 - val_accuracy: 0.6458\n",
      "Epoch 216/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5986 - accuracy: 0.7300 - val_loss: 0.7129 - val_accuracy: 0.6376\n",
      "Epoch 217/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.5878 - accuracy: 0.7201 - val_loss: 0.7118 - val_accuracy: 0.6431\n",
      "Epoch 218/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5914 - accuracy: 0.7220 - val_loss: 0.7549 - val_accuracy: 0.6158\n",
      "Epoch 219/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5913 - accuracy: 0.7154 - val_loss: 0.7293 - val_accuracy: 0.6267\n",
      "Epoch 220/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5924 - accuracy: 0.7280 - val_loss: 0.7336 - val_accuracy: 0.6158\n",
      "Epoch 221/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5961 - accuracy: 0.7253 - val_loss: 0.7242 - val_accuracy: 0.6322\n",
      "Epoch 222/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5917 - accuracy: 0.7340 - val_loss: 0.7302 - val_accuracy: 0.6294\n",
      "Epoch 223/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.5886 - accuracy: 0.7353 - val_loss: 0.7085 - val_accuracy: 0.6185\n",
      "Epoch 224/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5881 - accuracy: 0.7439 - val_loss: 0.7201 - val_accuracy: 0.6267\n",
      "Epoch 225/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5865 - accuracy: 0.7386 - val_loss: 0.7295 - val_accuracy: 0.6322\n",
      "Epoch 226/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5899 - accuracy: 0.7346 - val_loss: 0.7011 - val_accuracy: 0.6349\n",
      "Epoch 227/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5848 - accuracy: 0.7346 - val_loss: 0.7218 - val_accuracy: 0.6322\n",
      "Epoch 228/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5910 - accuracy: 0.7287 - val_loss: 0.7590 - val_accuracy: 0.6131\n",
      "Epoch 229/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5848 - accuracy: 0.7247 - val_loss: 0.7154 - val_accuracy: 0.6376\n",
      "Epoch 230/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5805 - accuracy: 0.7340 - val_loss: 0.7211 - val_accuracy: 0.6458\n",
      "Epoch 231/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5779 - accuracy: 0.7426 - val_loss: 0.7300 - val_accuracy: 0.6267\n",
      "Epoch 232/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5857 - accuracy: 0.7333 - val_loss: 0.7076 - val_accuracy: 0.6376\n",
      "Epoch 233/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5785 - accuracy: 0.7419 - val_loss: 0.7331 - val_accuracy: 0.6158\n",
      "Epoch 234/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5818 - accuracy: 0.7280 - val_loss: 0.7406 - val_accuracy: 0.6294\n",
      "Epoch 235/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.5778 - accuracy: 0.7267 - val_loss: 0.7044 - val_accuracy: 0.6403\n",
      "Epoch 236/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5799 - accuracy: 0.7353 - val_loss: 0.7110 - val_accuracy: 0.6431\n",
      "Epoch 237/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.5757 - accuracy: 0.7333 - val_loss: 0.7566 - val_accuracy: 0.6185\n",
      "Epoch 238/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.5771 - accuracy: 0.7273 - val_loss: 0.7371 - val_accuracy: 0.6267\n",
      "Epoch 239/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5772 - accuracy: 0.7465 - val_loss: 0.7138 - val_accuracy: 0.6349\n",
      "Epoch 240/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5743 - accuracy: 0.7445 - val_loss: 0.7426 - val_accuracy: 0.6213\n",
      "Epoch 241/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5750 - accuracy: 0.7379 - val_loss: 0.7165 - val_accuracy: 0.6213\n",
      "Epoch 242/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5749 - accuracy: 0.7485 - val_loss: 0.7087 - val_accuracy: 0.6349\n",
      "Epoch 243/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5704 - accuracy: 0.7353 - val_loss: 0.7288 - val_accuracy: 0.6267\n",
      "Epoch 244/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5712 - accuracy: 0.7406 - val_loss: 0.7051 - val_accuracy: 0.6267\n",
      "Epoch 245/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5734 - accuracy: 0.7525 - val_loss: 0.7446 - val_accuracy: 0.6213\n",
      "Epoch 246/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5714 - accuracy: 0.7459 - val_loss: 0.7258 - val_accuracy: 0.6185\n",
      "Epoch 247/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5689 - accuracy: 0.7346 - val_loss: 0.7053 - val_accuracy: 0.6322\n",
      "Epoch 248/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5705 - accuracy: 0.7419 - val_loss: 0.7198 - val_accuracy: 0.6322\n",
      "Epoch 249/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5634 - accuracy: 0.7538 - val_loss: 0.7508 - val_accuracy: 0.6185\n",
      "Epoch 250/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5699 - accuracy: 0.7373 - val_loss: 0.7042 - val_accuracy: 0.6376\n",
      "Epoch 251/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5608 - accuracy: 0.7551 - val_loss: 0.7077 - val_accuracy: 0.6294\n",
      "Epoch 252/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5675 - accuracy: 0.7498 - val_loss: 0.7228 - val_accuracy: 0.6403\n",
      "Epoch 253/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5668 - accuracy: 0.7359 - val_loss: 0.7930 - val_accuracy: 0.6076\n",
      "Epoch 254/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5624 - accuracy: 0.7392 - val_loss: 0.7197 - val_accuracy: 0.6322\n",
      "Epoch 255/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.5644 - accuracy: 0.7412 - val_loss: 0.7150 - val_accuracy: 0.6376\n",
      "Epoch 256/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5613 - accuracy: 0.7631 - val_loss: 0.7229 - val_accuracy: 0.6240\n",
      "Epoch 257/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5595 - accuracy: 0.7439 - val_loss: 0.7168 - val_accuracy: 0.6294\n",
      "Epoch 258/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5567 - accuracy: 0.7498 - val_loss: 0.7386 - val_accuracy: 0.6213\n",
      "Epoch 259/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5620 - accuracy: 0.7492 - val_loss: 0.7006 - val_accuracy: 0.6294\n",
      "Epoch 260/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5580 - accuracy: 0.7518 - val_loss: 0.6984 - val_accuracy: 0.6267\n",
      "Epoch 261/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5583 - accuracy: 0.7551 - val_loss: 0.7080 - val_accuracy: 0.6567\n",
      "Epoch 262/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5564 - accuracy: 0.7485 - val_loss: 0.7119 - val_accuracy: 0.6540\n",
      "Epoch 263/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5574 - accuracy: 0.7545 - val_loss: 0.7050 - val_accuracy: 0.6267\n",
      "Epoch 264/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5490 - accuracy: 0.7591 - val_loss: 0.7749 - val_accuracy: 0.6022\n",
      "Epoch 265/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5516 - accuracy: 0.7551 - val_loss: 0.7371 - val_accuracy: 0.6322\n",
      "Epoch 266/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5533 - accuracy: 0.7525 - val_loss: 0.7141 - val_accuracy: 0.6240\n",
      "Epoch 267/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5470 - accuracy: 0.7598 - val_loss: 0.7050 - val_accuracy: 0.6376\n",
      "Epoch 268/700\n",
      "95/95 [==============================] - 12s 129ms/step - loss: 0.5544 - accuracy: 0.7465 - val_loss: 0.7168 - val_accuracy: 0.6322\n",
      "Epoch 269/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5505 - accuracy: 0.7452 - val_loss: 0.7129 - val_accuracy: 0.6376\n",
      "Epoch 270/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5440 - accuracy: 0.7578 - val_loss: 0.7665 - val_accuracy: 0.6158\n",
      "Epoch 271/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.5452 - accuracy: 0.7578 - val_loss: 0.7116 - val_accuracy: 0.6376\n",
      "Epoch 272/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5453 - accuracy: 0.7578 - val_loss: 0.7043 - val_accuracy: 0.6322\n",
      "Epoch 273/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5415 - accuracy: 0.7584 - val_loss: 0.7296 - val_accuracy: 0.6267\n",
      "Epoch 274/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5476 - accuracy: 0.7551 - val_loss: 0.7255 - val_accuracy: 0.6240\n",
      "Epoch 275/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5397 - accuracy: 0.7637 - val_loss: 0.7272 - val_accuracy: 0.6267\n",
      "Epoch 276/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5395 - accuracy: 0.7704 - val_loss: 0.7070 - val_accuracy: 0.6431\n",
      "Epoch 277/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5375 - accuracy: 0.7730 - val_loss: 0.7042 - val_accuracy: 0.6240\n",
      "Epoch 278/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5363 - accuracy: 0.7684 - val_loss: 0.7484 - val_accuracy: 0.6376\n",
      "Epoch 279/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5413 - accuracy: 0.7512 - val_loss: 0.7137 - val_accuracy: 0.6403\n",
      "Epoch 280/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.5331 - accuracy: 0.7723 - val_loss: 0.7295 - val_accuracy: 0.6131\n",
      "Epoch 281/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5327 - accuracy: 0.7670 - val_loss: 0.7152 - val_accuracy: 0.6512\n",
      "Epoch 282/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5344 - accuracy: 0.7545 - val_loss: 0.7381 - val_accuracy: 0.6240\n",
      "Epoch 283/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5315 - accuracy: 0.7723 - val_loss: 0.7097 - val_accuracy: 0.6322\n",
      "Epoch 284/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5405 - accuracy: 0.7565 - val_loss: 0.7201 - val_accuracy: 0.6240\n",
      "Epoch 285/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5292 - accuracy: 0.7684 - val_loss: 0.7990 - val_accuracy: 0.6022\n",
      "Epoch 286/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5377 - accuracy: 0.7684 - val_loss: 0.7445 - val_accuracy: 0.6294\n",
      "Epoch 287/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.5306 - accuracy: 0.7584 - val_loss: 0.7117 - val_accuracy: 0.6458\n",
      "Epoch 288/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5312 - accuracy: 0.7631 - val_loss: 0.7064 - val_accuracy: 0.6403\n",
      "Epoch 289/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5311 - accuracy: 0.7697 - val_loss: 0.7152 - val_accuracy: 0.6485\n",
      "Epoch 290/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5239 - accuracy: 0.7598 - val_loss: 0.7110 - val_accuracy: 0.6376\n",
      "Epoch 291/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.5217 - accuracy: 0.7849 - val_loss: 0.7347 - val_accuracy: 0.6349\n",
      "Epoch 292/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5255 - accuracy: 0.7584 - val_loss: 0.7167 - val_accuracy: 0.6512\n",
      "Epoch 293/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5270 - accuracy: 0.7750 - val_loss: 0.7247 - val_accuracy: 0.6104\n",
      "Epoch 294/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5251 - accuracy: 0.7637 - val_loss: 0.7124 - val_accuracy: 0.6213\n",
      "Epoch 295/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5213 - accuracy: 0.7723 - val_loss: 0.7147 - val_accuracy: 0.6485\n",
      "Epoch 296/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5233 - accuracy: 0.7637 - val_loss: 0.7042 - val_accuracy: 0.6403\n",
      "Epoch 297/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5183 - accuracy: 0.7836 - val_loss: 0.7238 - val_accuracy: 0.6185\n",
      "Epoch 298/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5224 - accuracy: 0.7704 - val_loss: 0.7559 - val_accuracy: 0.6158\n",
      "Epoch 299/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5177 - accuracy: 0.7783 - val_loss: 0.7455 - val_accuracy: 0.6485\n",
      "Epoch 300/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5198 - accuracy: 0.7651 - val_loss: 0.7543 - val_accuracy: 0.6376\n",
      "Epoch 301/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5224 - accuracy: 0.7723 - val_loss: 0.7255 - val_accuracy: 0.6403\n",
      "Epoch 302/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5203 - accuracy: 0.7684 - val_loss: 0.7156 - val_accuracy: 0.6240\n",
      "Epoch 303/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5152 - accuracy: 0.7717 - val_loss: 0.7377 - val_accuracy: 0.6131\n",
      "Epoch 304/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5144 - accuracy: 0.7717 - val_loss: 0.8297 - val_accuracy: 0.6022\n",
      "Epoch 305/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5140 - accuracy: 0.7770 - val_loss: 0.7242 - val_accuracy: 0.6322\n",
      "Epoch 306/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5120 - accuracy: 0.7743 - val_loss: 0.7458 - val_accuracy: 0.6431\n",
      "Epoch 307/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5191 - accuracy: 0.7737 - val_loss: 0.7982 - val_accuracy: 0.6022\n",
      "Epoch 308/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5162 - accuracy: 0.7684 - val_loss: 0.7049 - val_accuracy: 0.6294\n",
      "Epoch 309/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5133 - accuracy: 0.7717 - val_loss: 0.7068 - val_accuracy: 0.6322\n",
      "Epoch 310/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.5105 - accuracy: 0.7770 - val_loss: 0.7133 - val_accuracy: 0.6240\n",
      "Epoch 311/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.5126 - accuracy: 0.7909 - val_loss: 0.7102 - val_accuracy: 0.6376\n",
      "Epoch 312/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5111 - accuracy: 0.7743 - val_loss: 0.7078 - val_accuracy: 0.6458\n",
      "Epoch 313/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5032 - accuracy: 0.7829 - val_loss: 0.7158 - val_accuracy: 0.6294\n",
      "Epoch 314/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5042 - accuracy: 0.7836 - val_loss: 0.7195 - val_accuracy: 0.6076\n",
      "Epoch 315/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5076 - accuracy: 0.7796 - val_loss: 0.7106 - val_accuracy: 0.6158\n",
      "Epoch 316/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5078 - accuracy: 0.7862 - val_loss: 0.7281 - val_accuracy: 0.6458\n",
      "Epoch 317/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5045 - accuracy: 0.7869 - val_loss: 0.7079 - val_accuracy: 0.6485\n",
      "Epoch 318/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.5028 - accuracy: 0.7842 - val_loss: 0.7202 - val_accuracy: 0.6349\n",
      "Epoch 319/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5002 - accuracy: 0.7862 - val_loss: 0.7292 - val_accuracy: 0.6185\n",
      "Epoch 320/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.5009 - accuracy: 0.7842 - val_loss: 0.7160 - val_accuracy: 0.6431\n",
      "Epoch 321/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4996 - accuracy: 0.7842 - val_loss: 0.7223 - val_accuracy: 0.6322\n",
      "Epoch 322/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4981 - accuracy: 0.7783 - val_loss: 0.7156 - val_accuracy: 0.6349\n",
      "Epoch 323/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.5016 - accuracy: 0.7829 - val_loss: 0.7067 - val_accuracy: 0.6240\n",
      "Epoch 324/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4967 - accuracy: 0.7836 - val_loss: 0.7080 - val_accuracy: 0.6267\n",
      "Epoch 325/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4990 - accuracy: 0.7783 - val_loss: 0.7050 - val_accuracy: 0.6267\n",
      "Epoch 326/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4961 - accuracy: 0.7876 - val_loss: 0.7256 - val_accuracy: 0.6458\n",
      "Epoch 327/700\n",
      "95/95 [==============================] - 12s 129ms/step - loss: 0.4975 - accuracy: 0.7862 - val_loss: 0.8125 - val_accuracy: 0.6049\n",
      "Epoch 328/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.4899 - accuracy: 0.7889 - val_loss: 0.7286 - val_accuracy: 0.6240\n",
      "Epoch 329/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4946 - accuracy: 0.7803 - val_loss: 0.7234 - val_accuracy: 0.6240\n",
      "Epoch 330/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4938 - accuracy: 0.7988 - val_loss: 0.7376 - val_accuracy: 0.6213\n",
      "Epoch 331/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4880 - accuracy: 0.7922 - val_loss: 0.7417 - val_accuracy: 0.6267\n",
      "Epoch 332/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4860 - accuracy: 0.7856 - val_loss: 0.7713 - val_accuracy: 0.6104\n",
      "Epoch 333/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4918 - accuracy: 0.7895 - val_loss: 0.7245 - val_accuracy: 0.6213\n",
      "Epoch 334/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4867 - accuracy: 0.7909 - val_loss: 0.7111 - val_accuracy: 0.6267\n",
      "Epoch 335/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4900 - accuracy: 0.7862 - val_loss: 0.7176 - val_accuracy: 0.6294\n",
      "Epoch 336/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4854 - accuracy: 0.7968 - val_loss: 0.7374 - val_accuracy: 0.6158\n",
      "Epoch 337/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4868 - accuracy: 0.7929 - val_loss: 0.7093 - val_accuracy: 0.6240\n",
      "Epoch 338/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4866 - accuracy: 0.7909 - val_loss: 0.7090 - val_accuracy: 0.6294\n",
      "Epoch 339/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4795 - accuracy: 0.7876 - val_loss: 0.7340 - val_accuracy: 0.6376\n",
      "Epoch 340/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4850 - accuracy: 0.7909 - val_loss: 0.7218 - val_accuracy: 0.6240\n",
      "Epoch 341/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4865 - accuracy: 0.7842 - val_loss: 0.7140 - val_accuracy: 0.6431\n",
      "Epoch 342/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4819 - accuracy: 0.7856 - val_loss: 0.7232 - val_accuracy: 0.6322\n",
      "Epoch 343/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4832 - accuracy: 0.7948 - val_loss: 0.7235 - val_accuracy: 0.6240\n",
      "Epoch 344/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4771 - accuracy: 0.7902 - val_loss: 0.7335 - val_accuracy: 0.6267\n",
      "Epoch 345/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4810 - accuracy: 0.7962 - val_loss: 0.7158 - val_accuracy: 0.6376\n",
      "Epoch 346/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.4765 - accuracy: 0.7968 - val_loss: 0.7152 - val_accuracy: 0.6267\n",
      "Epoch 347/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4695 - accuracy: 0.8107 - val_loss: 0.7840 - val_accuracy: 0.6267\n",
      "Epoch 348/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4725 - accuracy: 0.8034 - val_loss: 0.7417 - val_accuracy: 0.6185\n",
      "Epoch 349/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4730 - accuracy: 0.8008 - val_loss: 0.7119 - val_accuracy: 0.6294\n",
      "Epoch 350/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.4715 - accuracy: 0.7962 - val_loss: 0.7522 - val_accuracy: 0.6403\n",
      "Epoch 351/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4672 - accuracy: 0.8001 - val_loss: 0.7613 - val_accuracy: 0.6131\n",
      "Epoch 352/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4645 - accuracy: 0.8041 - val_loss: 0.7569 - val_accuracy: 0.6158\n",
      "Epoch 353/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4679 - accuracy: 0.8041 - val_loss: 0.7657 - val_accuracy: 0.6158\n",
      "Epoch 354/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4707 - accuracy: 0.7995 - val_loss: 0.7163 - val_accuracy: 0.6376\n",
      "Epoch 355/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4697 - accuracy: 0.8048 - val_loss: 0.7322 - val_accuracy: 0.6267\n",
      "Epoch 356/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4681 - accuracy: 0.8081 - val_loss: 0.7300 - val_accuracy: 0.6431\n",
      "Epoch 357/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4657 - accuracy: 0.8054 - val_loss: 0.7602 - val_accuracy: 0.6213\n",
      "Epoch 358/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4678 - accuracy: 0.8021 - val_loss: 0.7317 - val_accuracy: 0.6322\n",
      "Epoch 359/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4598 - accuracy: 0.8008 - val_loss: 0.7682 - val_accuracy: 0.6294\n",
      "Epoch 360/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4599 - accuracy: 0.8140 - val_loss: 0.7413 - val_accuracy: 0.6104\n",
      "Epoch 361/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4620 - accuracy: 0.8054 - val_loss: 0.7223 - val_accuracy: 0.6376\n",
      "Epoch 362/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4574 - accuracy: 0.8081 - val_loss: 0.7360 - val_accuracy: 0.6485\n",
      "Epoch 363/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4610 - accuracy: 0.8015 - val_loss: 0.7219 - val_accuracy: 0.6322\n",
      "Epoch 364/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4611 - accuracy: 0.8187 - val_loss: 0.7139 - val_accuracy: 0.6185\n",
      "Epoch 365/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4550 - accuracy: 0.8160 - val_loss: 0.7206 - val_accuracy: 0.6403\n",
      "Epoch 366/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4536 - accuracy: 0.8140 - val_loss: 0.7236 - val_accuracy: 0.6294\n",
      "Epoch 367/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4532 - accuracy: 0.8101 - val_loss: 0.7111 - val_accuracy: 0.6349\n",
      "Epoch 368/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4595 - accuracy: 0.8021 - val_loss: 0.7222 - val_accuracy: 0.6322\n",
      "Epoch 369/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4568 - accuracy: 0.8041 - val_loss: 0.7227 - val_accuracy: 0.6349\n",
      "Epoch 370/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4558 - accuracy: 0.8154 - val_loss: 0.7210 - val_accuracy: 0.6376\n",
      "Epoch 371/700\n",
      "95/95 [==============================] - 10s 111ms/step - loss: 0.4453 - accuracy: 0.8147 - val_loss: 0.7146 - val_accuracy: 0.6512\n",
      "Epoch 372/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.4541 - accuracy: 0.8074 - val_loss: 0.7189 - val_accuracy: 0.6213\n",
      "Epoch 373/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4509 - accuracy: 0.8061 - val_loss: 0.7259 - val_accuracy: 0.6403\n",
      "Epoch 374/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4496 - accuracy: 0.8120 - val_loss: 0.7465 - val_accuracy: 0.6458\n",
      "Epoch 375/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4460 - accuracy: 0.8140 - val_loss: 0.7516 - val_accuracy: 0.6213\n",
      "Epoch 376/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.4470 - accuracy: 0.8087 - val_loss: 0.7247 - val_accuracy: 0.6349\n",
      "Epoch 377/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4437 - accuracy: 0.8200 - val_loss: 0.7211 - val_accuracy: 0.6294\n",
      "Epoch 378/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4443 - accuracy: 0.8074 - val_loss: 0.8037 - val_accuracy: 0.6158\n",
      "Epoch 379/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4458 - accuracy: 0.8220 - val_loss: 0.7162 - val_accuracy: 0.6240\n",
      "Epoch 380/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4450 - accuracy: 0.8134 - val_loss: 0.7211 - val_accuracy: 0.6431\n",
      "Epoch 381/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4427 - accuracy: 0.8154 - val_loss: 0.7814 - val_accuracy: 0.6185\n",
      "Epoch 382/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4432 - accuracy: 0.8107 - val_loss: 0.7413 - val_accuracy: 0.6240\n",
      "Epoch 383/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4384 - accuracy: 0.8087 - val_loss: 0.7929 - val_accuracy: 0.6158\n",
      "Epoch 384/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4387 - accuracy: 0.8167 - val_loss: 0.7245 - val_accuracy: 0.6485\n",
      "Epoch 385/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4407 - accuracy: 0.8087 - val_loss: 0.7388 - val_accuracy: 0.6376\n",
      "Epoch 386/700\n",
      "95/95 [==============================] - 12s 127ms/step - loss: 0.4322 - accuracy: 0.8226 - val_loss: 0.7466 - val_accuracy: 0.6158\n",
      "Epoch 387/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.4374 - accuracy: 0.8114 - val_loss: 0.7513 - val_accuracy: 0.6485\n",
      "Epoch 388/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4366 - accuracy: 0.8266 - val_loss: 0.7189 - val_accuracy: 0.6240\n",
      "Epoch 389/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4295 - accuracy: 0.8253 - val_loss: 0.8012 - val_accuracy: 0.6322\n",
      "Epoch 390/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4345 - accuracy: 0.8206 - val_loss: 0.8223 - val_accuracy: 0.5886\n",
      "Epoch 391/700\n",
      "95/95 [==============================] - 11s 112ms/step - loss: 0.4299 - accuracy: 0.8226 - val_loss: 0.7336 - val_accuracy: 0.6322\n",
      "Epoch 392/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4320 - accuracy: 0.8279 - val_loss: 0.7413 - val_accuracy: 0.6376\n",
      "Epoch 393/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4302 - accuracy: 0.8226 - val_loss: 0.7254 - val_accuracy: 0.6431\n",
      "Epoch 394/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4272 - accuracy: 0.8259 - val_loss: 0.7512 - val_accuracy: 0.6349\n",
      "Epoch 395/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4322 - accuracy: 0.8193 - val_loss: 0.7482 - val_accuracy: 0.6376\n",
      "Epoch 396/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4223 - accuracy: 0.8240 - val_loss: 0.7929 - val_accuracy: 0.6294\n",
      "Epoch 397/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4267 - accuracy: 0.8253 - val_loss: 0.7460 - val_accuracy: 0.6267\n",
      "Epoch 398/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4255 - accuracy: 0.8273 - val_loss: 0.7478 - val_accuracy: 0.6485\n",
      "Epoch 399/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4241 - accuracy: 0.8312 - val_loss: 0.7545 - val_accuracy: 0.6294\n",
      "Epoch 400/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4241 - accuracy: 0.8312 - val_loss: 0.7226 - val_accuracy: 0.6431\n",
      "Epoch 401/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.4207 - accuracy: 0.8200 - val_loss: 0.7190 - val_accuracy: 0.6213\n",
      "Epoch 402/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4162 - accuracy: 0.8306 - val_loss: 0.7311 - val_accuracy: 0.6458\n",
      "Epoch 403/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4204 - accuracy: 0.8286 - val_loss: 0.7338 - val_accuracy: 0.6322\n",
      "Epoch 404/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4221 - accuracy: 0.8306 - val_loss: 0.7248 - val_accuracy: 0.6512\n",
      "Epoch 405/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4221 - accuracy: 0.8206 - val_loss: 0.7640 - val_accuracy: 0.6349\n",
      "Epoch 406/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4192 - accuracy: 0.8279 - val_loss: 0.7316 - val_accuracy: 0.6403\n",
      "Epoch 407/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4155 - accuracy: 0.8279 - val_loss: 0.7343 - val_accuracy: 0.6567\n",
      "Epoch 408/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4150 - accuracy: 0.8345 - val_loss: 0.7277 - val_accuracy: 0.6322\n",
      "Epoch 409/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4174 - accuracy: 0.8253 - val_loss: 0.7336 - val_accuracy: 0.6376\n",
      "Epoch 410/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4121 - accuracy: 0.8312 - val_loss: 0.7360 - val_accuracy: 0.6512\n",
      "Epoch 411/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4131 - accuracy: 0.8339 - val_loss: 0.7242 - val_accuracy: 0.6322\n",
      "Epoch 412/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4135 - accuracy: 0.8319 - val_loss: 0.7544 - val_accuracy: 0.6403\n",
      "Epoch 413/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4086 - accuracy: 0.8352 - val_loss: 0.7252 - val_accuracy: 0.6294\n",
      "Epoch 414/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4113 - accuracy: 0.8365 - val_loss: 0.7377 - val_accuracy: 0.6240\n",
      "Epoch 415/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4116 - accuracy: 0.8365 - val_loss: 0.7230 - val_accuracy: 0.6458\n",
      "Epoch 416/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4035 - accuracy: 0.8379 - val_loss: 0.8035 - val_accuracy: 0.6213\n",
      "Epoch 417/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.4094 - accuracy: 0.8253 - val_loss: 0.7183 - val_accuracy: 0.6431\n",
      "Epoch 418/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4059 - accuracy: 0.8392 - val_loss: 0.7220 - val_accuracy: 0.6267\n",
      "Epoch 419/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.4046 - accuracy: 0.8432 - val_loss: 0.8000 - val_accuracy: 0.6076\n",
      "Epoch 420/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.3980 - accuracy: 0.8478 - val_loss: 0.7535 - val_accuracy: 0.6512\n",
      "Epoch 421/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.4023 - accuracy: 0.8465 - val_loss: 0.7406 - val_accuracy: 0.6431\n",
      "Epoch 422/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.4031 - accuracy: 0.8445 - val_loss: 0.7247 - val_accuracy: 0.6485\n",
      "Epoch 423/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4013 - accuracy: 0.8418 - val_loss: 0.7244 - val_accuracy: 0.6431\n",
      "Epoch 424/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3986 - accuracy: 0.8412 - val_loss: 0.7411 - val_accuracy: 0.6458\n",
      "Epoch 425/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.3944 - accuracy: 0.8478 - val_loss: 0.7545 - val_accuracy: 0.6431\n",
      "Epoch 426/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.3965 - accuracy: 0.8458 - val_loss: 0.7876 - val_accuracy: 0.6322\n",
      "Epoch 427/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3978 - accuracy: 0.8432 - val_loss: 0.7711 - val_accuracy: 0.6294\n",
      "Epoch 428/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3936 - accuracy: 0.8445 - val_loss: 0.7746 - val_accuracy: 0.6185\n",
      "Epoch 429/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.4008 - accuracy: 0.8293 - val_loss: 0.7308 - val_accuracy: 0.6540\n",
      "Epoch 430/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.3904 - accuracy: 0.8498 - val_loss: 0.7452 - val_accuracy: 0.6376\n",
      "Epoch 431/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3922 - accuracy: 0.8478 - val_loss: 0.7567 - val_accuracy: 0.6267\n",
      "Epoch 432/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3947 - accuracy: 0.8392 - val_loss: 0.7408 - val_accuracy: 0.6485\n",
      "Epoch 433/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3876 - accuracy: 0.8471 - val_loss: 0.7351 - val_accuracy: 0.6431\n",
      "Epoch 434/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3912 - accuracy: 0.8412 - val_loss: 0.7442 - val_accuracy: 0.6294\n",
      "Epoch 435/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3874 - accuracy: 0.8498 - val_loss: 0.7474 - val_accuracy: 0.6294\n",
      "Epoch 436/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3887 - accuracy: 0.8438 - val_loss: 0.7283 - val_accuracy: 0.6540\n",
      "Epoch 437/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3863 - accuracy: 0.8504 - val_loss: 0.7276 - val_accuracy: 0.6431\n",
      "Epoch 438/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3825 - accuracy: 0.8432 - val_loss: 0.7517 - val_accuracy: 0.6403\n",
      "Epoch 439/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3850 - accuracy: 0.8531 - val_loss: 0.7988 - val_accuracy: 0.6322\n",
      "Epoch 440/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3828 - accuracy: 0.8537 - val_loss: 0.7380 - val_accuracy: 0.6431\n",
      "Epoch 441/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3817 - accuracy: 0.8544 - val_loss: 0.7382 - val_accuracy: 0.6349\n",
      "Epoch 442/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3769 - accuracy: 0.8498 - val_loss: 0.8819 - val_accuracy: 0.6267\n",
      "Epoch 443/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3815 - accuracy: 0.8438 - val_loss: 0.7402 - val_accuracy: 0.6322\n",
      "Epoch 444/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3792 - accuracy: 0.8537 - val_loss: 0.7327 - val_accuracy: 0.6594\n",
      "Epoch 445/700\n",
      "95/95 [==============================] - 12s 131ms/step - loss: 0.3802 - accuracy: 0.8551 - val_loss: 0.7248 - val_accuracy: 0.6512\n",
      "Epoch 446/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3783 - accuracy: 0.8471 - val_loss: 0.7598 - val_accuracy: 0.6431\n",
      "Epoch 447/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3722 - accuracy: 0.8518 - val_loss: 0.7373 - val_accuracy: 0.6540\n",
      "Epoch 448/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3777 - accuracy: 0.8537 - val_loss: 0.7646 - val_accuracy: 0.6649\n",
      "Epoch 449/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3713 - accuracy: 0.8597 - val_loss: 0.8047 - val_accuracy: 0.6458\n",
      "Epoch 450/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3756 - accuracy: 0.8637 - val_loss: 0.7298 - val_accuracy: 0.6403\n",
      "Epoch 451/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3734 - accuracy: 0.8584 - val_loss: 0.7815 - val_accuracy: 0.6076\n",
      "Epoch 452/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3719 - accuracy: 0.8604 - val_loss: 0.7396 - val_accuracy: 0.6567\n",
      "Epoch 453/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3698 - accuracy: 0.8584 - val_loss: 0.7322 - val_accuracy: 0.6512\n",
      "Epoch 454/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3727 - accuracy: 0.8584 - val_loss: 0.7585 - val_accuracy: 0.6485\n",
      "Epoch 455/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3709 - accuracy: 0.8557 - val_loss: 0.7542 - val_accuracy: 0.6458\n",
      "Epoch 456/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3642 - accuracy: 0.8709 - val_loss: 0.7627 - val_accuracy: 0.6403\n",
      "Epoch 457/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3671 - accuracy: 0.8584 - val_loss: 0.7364 - val_accuracy: 0.6458\n",
      "Epoch 458/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3614 - accuracy: 0.8716 - val_loss: 0.7455 - val_accuracy: 0.6240\n",
      "Epoch 459/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3654 - accuracy: 0.8637 - val_loss: 0.7635 - val_accuracy: 0.6376\n",
      "Epoch 460/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3641 - accuracy: 0.8637 - val_loss: 0.7409 - val_accuracy: 0.6403\n",
      "Epoch 461/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3616 - accuracy: 0.8650 - val_loss: 0.7521 - val_accuracy: 0.6403\n",
      "Epoch 462/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3612 - accuracy: 0.8537 - val_loss: 0.7553 - val_accuracy: 0.6431\n",
      "Epoch 463/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3598 - accuracy: 0.8590 - val_loss: 0.7611 - val_accuracy: 0.6649\n",
      "Epoch 464/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3617 - accuracy: 0.8690 - val_loss: 0.7421 - val_accuracy: 0.6512\n",
      "Epoch 465/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3566 - accuracy: 0.8590 - val_loss: 0.7429 - val_accuracy: 0.6431\n",
      "Epoch 466/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3552 - accuracy: 0.8676 - val_loss: 0.7491 - val_accuracy: 0.6540\n",
      "Epoch 467/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3571 - accuracy: 0.8650 - val_loss: 0.7754 - val_accuracy: 0.6294\n",
      "Epoch 468/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3578 - accuracy: 0.8643 - val_loss: 0.7646 - val_accuracy: 0.6376\n",
      "Epoch 469/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3541 - accuracy: 0.8709 - val_loss: 0.7973 - val_accuracy: 0.6431\n",
      "Epoch 470/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3514 - accuracy: 0.8670 - val_loss: 0.7725 - val_accuracy: 0.6594\n",
      "Epoch 471/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3499 - accuracy: 0.8676 - val_loss: 0.7523 - val_accuracy: 0.6458\n",
      "Epoch 472/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3492 - accuracy: 0.8590 - val_loss: 0.7677 - val_accuracy: 0.6267\n",
      "Epoch 473/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3474 - accuracy: 0.8716 - val_loss: 0.7487 - val_accuracy: 0.6458\n",
      "Epoch 474/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3509 - accuracy: 0.8756 - val_loss: 0.7392 - val_accuracy: 0.6431\n",
      "Epoch 475/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3474 - accuracy: 0.8696 - val_loss: 0.8025 - val_accuracy: 0.6131\n",
      "Epoch 476/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.3469 - accuracy: 0.8683 - val_loss: 0.7573 - val_accuracy: 0.6349\n",
      "Epoch 477/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3462 - accuracy: 0.8703 - val_loss: 0.7542 - val_accuracy: 0.6540\n",
      "Epoch 478/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3443 - accuracy: 0.8743 - val_loss: 0.7495 - val_accuracy: 0.6431\n",
      "Epoch 479/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3469 - accuracy: 0.8703 - val_loss: 0.7632 - val_accuracy: 0.6349\n",
      "Epoch 480/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3485 - accuracy: 0.8663 - val_loss: 0.7490 - val_accuracy: 0.6512\n",
      "Epoch 481/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3420 - accuracy: 0.8683 - val_loss: 0.7639 - val_accuracy: 0.6403\n",
      "Epoch 482/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3469 - accuracy: 0.8663 - val_loss: 0.7680 - val_accuracy: 0.6540\n",
      "Epoch 483/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3418 - accuracy: 0.8696 - val_loss: 0.7472 - val_accuracy: 0.6458\n",
      "Epoch 484/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3370 - accuracy: 0.8802 - val_loss: 0.7553 - val_accuracy: 0.6403\n",
      "Epoch 485/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3326 - accuracy: 0.8842 - val_loss: 0.7651 - val_accuracy: 0.6621\n",
      "Epoch 486/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3362 - accuracy: 0.8769 - val_loss: 0.7809 - val_accuracy: 0.6158\n",
      "Epoch 487/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3383 - accuracy: 0.8703 - val_loss: 0.7516 - val_accuracy: 0.6403\n",
      "Epoch 488/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3346 - accuracy: 0.8749 - val_loss: 0.7571 - val_accuracy: 0.6376\n",
      "Epoch 489/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3353 - accuracy: 0.8756 - val_loss: 0.7573 - val_accuracy: 0.6403\n",
      "Epoch 490/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3326 - accuracy: 0.8769 - val_loss: 0.7719 - val_accuracy: 0.6485\n",
      "Epoch 491/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3303 - accuracy: 0.8868 - val_loss: 0.7858 - val_accuracy: 0.6185\n",
      "Epoch 492/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3325 - accuracy: 0.8815 - val_loss: 0.7520 - val_accuracy: 0.6540\n",
      "Epoch 493/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3301 - accuracy: 0.8862 - val_loss: 0.7881 - val_accuracy: 0.6376\n",
      "Epoch 494/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3282 - accuracy: 0.8802 - val_loss: 0.8005 - val_accuracy: 0.6403\n",
      "Epoch 495/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3307 - accuracy: 0.8829 - val_loss: 0.7519 - val_accuracy: 0.6322\n",
      "Epoch 496/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3266 - accuracy: 0.8802 - val_loss: 0.8370 - val_accuracy: 0.6158\n",
      "Epoch 497/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3249 - accuracy: 0.8895 - val_loss: 0.7893 - val_accuracy: 0.6376\n",
      "Epoch 498/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3270 - accuracy: 0.8822 - val_loss: 0.7715 - val_accuracy: 0.6512\n",
      "Epoch 499/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3303 - accuracy: 0.8822 - val_loss: 0.7575 - val_accuracy: 0.6567\n",
      "Epoch 500/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.3249 - accuracy: 0.8835 - val_loss: 0.8370 - val_accuracy: 0.6403\n",
      "Epoch 501/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3247 - accuracy: 0.8795 - val_loss: 0.7462 - val_accuracy: 0.6458\n",
      "Epoch 502/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3230 - accuracy: 0.8815 - val_loss: 0.7763 - val_accuracy: 0.6349\n",
      "Epoch 503/700\n",
      "95/95 [==============================] - 12s 130ms/step - loss: 0.3188 - accuracy: 0.8875 - val_loss: 0.7623 - val_accuracy: 0.6567\n",
      "Epoch 504/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3175 - accuracy: 0.8928 - val_loss: 0.7601 - val_accuracy: 0.6431\n",
      "Epoch 505/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3224 - accuracy: 0.8809 - val_loss: 0.7659 - val_accuracy: 0.6376\n",
      "Epoch 506/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3164 - accuracy: 0.8915 - val_loss: 0.8075 - val_accuracy: 0.6213\n",
      "Epoch 507/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3143 - accuracy: 0.8835 - val_loss: 0.7590 - val_accuracy: 0.6621\n",
      "Epoch 508/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3167 - accuracy: 0.8928 - val_loss: 0.7582 - val_accuracy: 0.6349\n",
      "Epoch 509/700\n",
      "95/95 [==============================] - 11s 113ms/step - loss: 0.3148 - accuracy: 0.8908 - val_loss: 0.7806 - val_accuracy: 0.6458\n",
      "Epoch 510/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3119 - accuracy: 0.8848 - val_loss: 0.7936 - val_accuracy: 0.6567\n",
      "Epoch 511/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3182 - accuracy: 0.8842 - val_loss: 0.8179 - val_accuracy: 0.6294\n",
      "Epoch 512/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3108 - accuracy: 0.8868 - val_loss: 0.8089 - val_accuracy: 0.6431\n",
      "Epoch 513/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3048 - accuracy: 0.9007 - val_loss: 0.7724 - val_accuracy: 0.6594\n",
      "Epoch 514/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3130 - accuracy: 0.8974 - val_loss: 0.7794 - val_accuracy: 0.6567\n",
      "Epoch 515/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3101 - accuracy: 0.8921 - val_loss: 0.7833 - val_accuracy: 0.6649\n",
      "Epoch 516/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3112 - accuracy: 0.8842 - val_loss: 0.7568 - val_accuracy: 0.6621\n",
      "Epoch 517/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3046 - accuracy: 0.8941 - val_loss: 0.7868 - val_accuracy: 0.6485\n",
      "Epoch 518/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3078 - accuracy: 0.8928 - val_loss: 0.7699 - val_accuracy: 0.6458\n",
      "Epoch 519/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3040 - accuracy: 0.8968 - val_loss: 0.7746 - val_accuracy: 0.6240\n",
      "Epoch 520/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.3044 - accuracy: 0.8968 - val_loss: 0.8013 - val_accuracy: 0.6431\n",
      "Epoch 521/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3075 - accuracy: 0.8961 - val_loss: 0.7708 - val_accuracy: 0.6431\n",
      "Epoch 522/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3108 - accuracy: 0.8908 - val_loss: 0.7742 - val_accuracy: 0.6485\n",
      "Epoch 523/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3045 - accuracy: 0.8948 - val_loss: 0.7602 - val_accuracy: 0.6458\n",
      "Epoch 524/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3001 - accuracy: 0.8961 - val_loss: 0.8354 - val_accuracy: 0.6376\n",
      "Epoch 525/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3000 - accuracy: 0.9021 - val_loss: 0.8107 - val_accuracy: 0.6485\n",
      "Epoch 526/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.3047 - accuracy: 0.8961 - val_loss: 0.7953 - val_accuracy: 0.6540\n",
      "Epoch 527/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.3001 - accuracy: 0.8968 - val_loss: 0.7819 - val_accuracy: 0.6376\n",
      "Epoch 528/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2961 - accuracy: 0.9034 - val_loss: 0.7935 - val_accuracy: 0.6512\n",
      "Epoch 529/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.3021 - accuracy: 0.8888 - val_loss: 0.7786 - val_accuracy: 0.6567\n",
      "Epoch 530/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2968 - accuracy: 0.8968 - val_loss: 0.8001 - val_accuracy: 0.6403\n",
      "Epoch 531/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2972 - accuracy: 0.8974 - val_loss: 0.7886 - val_accuracy: 0.6294\n",
      "Epoch 532/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2971 - accuracy: 0.8961 - val_loss: 0.7898 - val_accuracy: 0.6376\n",
      "Epoch 533/700\n",
      "95/95 [==============================] - 10s 106ms/step - loss: 0.2965 - accuracy: 0.9001 - val_loss: 0.7781 - val_accuracy: 0.6458\n",
      "Epoch 534/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2948 - accuracy: 0.8941 - val_loss: 0.7986 - val_accuracy: 0.6485\n",
      "Epoch 535/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2956 - accuracy: 0.8901 - val_loss: 0.7803 - val_accuracy: 0.6512\n",
      "Epoch 536/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2987 - accuracy: 0.9021 - val_loss: 0.8162 - val_accuracy: 0.6512\n",
      "Epoch 537/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2921 - accuracy: 0.9001 - val_loss: 0.7684 - val_accuracy: 0.6567\n",
      "Epoch 538/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2835 - accuracy: 0.9014 - val_loss: 0.7741 - val_accuracy: 0.6540\n",
      "Epoch 539/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2900 - accuracy: 0.8961 - val_loss: 0.7687 - val_accuracy: 0.6594\n",
      "Epoch 540/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2908 - accuracy: 0.8888 - val_loss: 0.8020 - val_accuracy: 0.6594\n",
      "Epoch 541/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2871 - accuracy: 0.9087 - val_loss: 0.8112 - val_accuracy: 0.6158\n",
      "Epoch 542/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2830 - accuracy: 0.9107 - val_loss: 0.7799 - val_accuracy: 0.6567\n",
      "Epoch 543/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2849 - accuracy: 0.9054 - val_loss: 0.7924 - val_accuracy: 0.6567\n",
      "Epoch 544/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2821 - accuracy: 0.9034 - val_loss: 0.8066 - val_accuracy: 0.6322\n",
      "Epoch 545/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2843 - accuracy: 0.9126 - val_loss: 0.8213 - val_accuracy: 0.6540\n",
      "Epoch 546/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2851 - accuracy: 0.9073 - val_loss: 0.7813 - val_accuracy: 0.6540\n",
      "Epoch 547/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2836 - accuracy: 0.9040 - val_loss: 0.7920 - val_accuracy: 0.6431\n",
      "Epoch 548/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2752 - accuracy: 0.9100 - val_loss: 0.7963 - val_accuracy: 0.6621\n",
      "Epoch 549/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2823 - accuracy: 0.9133 - val_loss: 0.8063 - val_accuracy: 0.6403\n",
      "Epoch 550/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2711 - accuracy: 0.9246 - val_loss: 0.8256 - val_accuracy: 0.6322\n",
      "Epoch 551/700\n",
      "95/95 [==============================] - 11s 114ms/step - loss: 0.2790 - accuracy: 0.9100 - val_loss: 0.7817 - val_accuracy: 0.6676\n",
      "Epoch 552/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2753 - accuracy: 0.9060 - val_loss: 0.8321 - val_accuracy: 0.6376\n",
      "Epoch 553/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2786 - accuracy: 0.9107 - val_loss: 0.7859 - val_accuracy: 0.6376\n",
      "Epoch 554/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2772 - accuracy: 0.9107 - val_loss: 0.7829 - val_accuracy: 0.6376\n",
      "Epoch 555/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2715 - accuracy: 0.9107 - val_loss: 0.8180 - val_accuracy: 0.6349\n",
      "Epoch 556/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2718 - accuracy: 0.9087 - val_loss: 0.8375 - val_accuracy: 0.6349\n",
      "Epoch 557/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2755 - accuracy: 0.9159 - val_loss: 0.7981 - val_accuracy: 0.6431\n",
      "Epoch 558/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2716 - accuracy: 0.9107 - val_loss: 0.8373 - val_accuracy: 0.6376\n",
      "Epoch 559/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2691 - accuracy: 0.9087 - val_loss: 0.8111 - val_accuracy: 0.6322\n",
      "Epoch 560/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2715 - accuracy: 0.9113 - val_loss: 0.7954 - val_accuracy: 0.6512\n",
      "Epoch 561/700\n",
      "95/95 [==============================] - 13s 133ms/step - loss: 0.2628 - accuracy: 0.9166 - val_loss: 0.8238 - val_accuracy: 0.6240\n",
      "Epoch 562/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2646 - accuracy: 0.9166 - val_loss: 0.8169 - val_accuracy: 0.6403\n",
      "Epoch 563/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2628 - accuracy: 0.9146 - val_loss: 0.8456 - val_accuracy: 0.6458\n",
      "Epoch 564/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2690 - accuracy: 0.9133 - val_loss: 0.7933 - val_accuracy: 0.6540\n",
      "Epoch 565/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2655 - accuracy: 0.9166 - val_loss: 0.7948 - val_accuracy: 0.6376\n",
      "Epoch 566/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2650 - accuracy: 0.9126 - val_loss: 0.8231 - val_accuracy: 0.6322\n",
      "Epoch 567/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2597 - accuracy: 0.9126 - val_loss: 0.8215 - val_accuracy: 0.6267\n",
      "Epoch 568/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2613 - accuracy: 0.9166 - val_loss: 0.7918 - val_accuracy: 0.6676\n",
      "Epoch 569/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2634 - accuracy: 0.9120 - val_loss: 0.8173 - val_accuracy: 0.6431\n",
      "Epoch 570/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2583 - accuracy: 0.9179 - val_loss: 0.8168 - val_accuracy: 0.6458\n",
      "Epoch 571/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2646 - accuracy: 0.9179 - val_loss: 0.7963 - val_accuracy: 0.6567\n",
      "Epoch 572/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2550 - accuracy: 0.9252 - val_loss: 0.8118 - val_accuracy: 0.6594\n",
      "Epoch 573/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2549 - accuracy: 0.9173 - val_loss: 0.8193 - val_accuracy: 0.6431\n",
      "Epoch 574/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2564 - accuracy: 0.9259 - val_loss: 0.8074 - val_accuracy: 0.6594\n",
      "Epoch 575/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2530 - accuracy: 0.9173 - val_loss: 0.8112 - val_accuracy: 0.6403\n",
      "Epoch 576/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2551 - accuracy: 0.9153 - val_loss: 0.8183 - val_accuracy: 0.6431\n",
      "Epoch 577/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2538 - accuracy: 0.9219 - val_loss: 0.8506 - val_accuracy: 0.6294\n",
      "Epoch 578/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2526 - accuracy: 0.9232 - val_loss: 0.8048 - val_accuracy: 0.6594\n",
      "Epoch 579/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2554 - accuracy: 0.9252 - val_loss: 0.8406 - val_accuracy: 0.6322\n",
      "Epoch 580/700\n",
      "95/95 [==============================] - 11s 112ms/step - loss: 0.2518 - accuracy: 0.9265 - val_loss: 0.8442 - val_accuracy: 0.6294\n",
      "Epoch 581/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2514 - accuracy: 0.9199 - val_loss: 0.8059 - val_accuracy: 0.6431\n",
      "Epoch 582/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2511 - accuracy: 0.9239 - val_loss: 0.8200 - val_accuracy: 0.6485\n",
      "Epoch 583/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2448 - accuracy: 0.9285 - val_loss: 0.8162 - val_accuracy: 0.6540\n",
      "Epoch 584/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2461 - accuracy: 0.9159 - val_loss: 0.8160 - val_accuracy: 0.6621\n",
      "Epoch 585/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2472 - accuracy: 0.9246 - val_loss: 0.8060 - val_accuracy: 0.6567\n",
      "Epoch 586/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2540 - accuracy: 0.9133 - val_loss: 0.8134 - val_accuracy: 0.6431\n",
      "Epoch 587/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2422 - accuracy: 0.9312 - val_loss: 0.8143 - val_accuracy: 0.6540\n",
      "Epoch 588/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2460 - accuracy: 0.9279 - val_loss: 0.8183 - val_accuracy: 0.6458\n",
      "Epoch 589/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2485 - accuracy: 0.9259 - val_loss: 0.8178 - val_accuracy: 0.6431\n",
      "Epoch 590/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2404 - accuracy: 0.9239 - val_loss: 0.8610 - val_accuracy: 0.6403\n",
      "Epoch 591/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2428 - accuracy: 0.9298 - val_loss: 0.8417 - val_accuracy: 0.6431\n",
      "Epoch 592/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.2447 - accuracy: 0.9265 - val_loss: 0.8314 - val_accuracy: 0.6403\n",
      "Epoch 593/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2369 - accuracy: 0.9318 - val_loss: 0.8523 - val_accuracy: 0.6403\n",
      "Epoch 594/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2377 - accuracy: 0.9305 - val_loss: 0.8363 - val_accuracy: 0.6512\n",
      "Epoch 595/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2388 - accuracy: 0.9285 - val_loss: 0.8111 - val_accuracy: 0.6594\n",
      "Epoch 596/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2340 - accuracy: 0.9332 - val_loss: 0.8897 - val_accuracy: 0.6240\n",
      "Epoch 597/700\n",
      "95/95 [==============================] - 11s 112ms/step - loss: 0.2387 - accuracy: 0.9272 - val_loss: 0.8189 - val_accuracy: 0.6540\n",
      "Epoch 598/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2362 - accuracy: 0.9358 - val_loss: 0.9671 - val_accuracy: 0.6240\n",
      "Epoch 599/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2343 - accuracy: 0.9265 - val_loss: 0.8635 - val_accuracy: 0.6540\n",
      "Epoch 600/700\n",
      "95/95 [==============================] - 10s 107ms/step - loss: 0.2398 - accuracy: 0.9285 - val_loss: 0.8371 - val_accuracy: 0.6594\n",
      "Epoch 601/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2393 - accuracy: 0.9232 - val_loss: 0.8077 - val_accuracy: 0.6540\n",
      "Epoch 602/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2288 - accuracy: 0.9398 - val_loss: 0.8603 - val_accuracy: 0.6267\n",
      "Epoch 603/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2343 - accuracy: 0.9298 - val_loss: 0.8231 - val_accuracy: 0.6594\n",
      "Epoch 604/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2350 - accuracy: 0.9279 - val_loss: 0.8316 - val_accuracy: 0.6376\n",
      "Epoch 605/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2326 - accuracy: 0.9252 - val_loss: 0.8556 - val_accuracy: 0.6322\n",
      "Epoch 606/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2240 - accuracy: 0.9332 - val_loss: 0.8281 - val_accuracy: 0.6567\n",
      "Epoch 607/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2258 - accuracy: 0.9272 - val_loss: 0.8241 - val_accuracy: 0.6594\n",
      "Epoch 608/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2236 - accuracy: 0.9365 - val_loss: 0.8779 - val_accuracy: 0.6376\n",
      "Epoch 609/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2299 - accuracy: 0.9285 - val_loss: 0.8442 - val_accuracy: 0.6485\n",
      "Epoch 610/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2253 - accuracy: 0.9345 - val_loss: 0.8981 - val_accuracy: 0.6294\n",
      "Epoch 611/700\n",
      "95/95 [==============================] - 11s 113ms/step - loss: 0.2186 - accuracy: 0.9358 - val_loss: 0.8377 - val_accuracy: 0.6431\n",
      "Epoch 612/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2213 - accuracy: 0.9371 - val_loss: 0.8215 - val_accuracy: 0.6676\n",
      "Epoch 613/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2221 - accuracy: 0.9345 - val_loss: 0.8396 - val_accuracy: 0.6512\n",
      "Epoch 614/700\n",
      "95/95 [==============================] - 10s 109ms/step - loss: 0.2252 - accuracy: 0.9285 - val_loss: 0.8300 - val_accuracy: 0.6540\n",
      "Epoch 615/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2239 - accuracy: 0.9265 - val_loss: 0.8317 - val_accuracy: 0.6458\n",
      "Epoch 616/700\n",
      "95/95 [==============================] - 10s 110ms/step - loss: 0.2219 - accuracy: 0.9358 - val_loss: 0.8805 - val_accuracy: 0.6403\n",
      "Epoch 617/700\n",
      "95/95 [==============================] - 11s 111ms/step - loss: 0.2190 - accuracy: 0.9385 - val_loss: 0.8451 - val_accuracy: 0.6349\n",
      "Epoch 618/700\n",
      "95/95 [==============================] - 10s 108ms/step - loss: 0.2178 - accuracy: 0.9365 - val_loss: 0.8510 - val_accuracy: 0.6376\n",
      "Epoch 619/700\n",
      "95/95 [==============================] - 11s 116ms/step - loss: 0.2183 - accuracy: 0.9385 - val_loss: 0.9016 - val_accuracy: 0.6349\n",
      "Epoch 620/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2247 - accuracy: 0.9285 - val_loss: 0.9021 - val_accuracy: 0.6240\n",
      "Epoch 621/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2137 - accuracy: 0.9378 - val_loss: 0.9319 - val_accuracy: 0.6185\n",
      "Epoch 622/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2189 - accuracy: 0.9318 - val_loss: 0.8326 - val_accuracy: 0.6594\n",
      "Epoch 623/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2152 - accuracy: 0.9398 - val_loss: 0.8837 - val_accuracy: 0.6213\n",
      "Epoch 624/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2131 - accuracy: 0.9398 - val_loss: 0.8558 - val_accuracy: 0.6458\n",
      "Epoch 625/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2180 - accuracy: 0.9418 - val_loss: 0.8483 - val_accuracy: 0.6431\n",
      "Epoch 626/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.2095 - accuracy: 0.9424 - val_loss: 0.8554 - val_accuracy: 0.6567\n",
      "Epoch 627/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2133 - accuracy: 0.9351 - val_loss: 0.8616 - val_accuracy: 0.6458\n",
      "Epoch 628/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2131 - accuracy: 0.9404 - val_loss: 0.8513 - val_accuracy: 0.6567\n",
      "Epoch 629/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2083 - accuracy: 0.9404 - val_loss: 0.8724 - val_accuracy: 0.6458\n",
      "Epoch 630/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2076 - accuracy: 0.9504 - val_loss: 0.9616 - val_accuracy: 0.6240\n",
      "Epoch 631/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2055 - accuracy: 0.9424 - val_loss: 0.8740 - val_accuracy: 0.6267\n",
      "Epoch 632/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.2076 - accuracy: 0.9424 - val_loss: 0.8635 - val_accuracy: 0.6458\n",
      "Epoch 633/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2049 - accuracy: 0.9418 - val_loss: 0.8604 - val_accuracy: 0.6458\n",
      "Epoch 634/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2030 - accuracy: 0.9345 - val_loss: 0.8493 - val_accuracy: 0.6594\n",
      "Epoch 635/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2015 - accuracy: 0.9437 - val_loss: 0.8443 - val_accuracy: 0.6703\n",
      "Epoch 636/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2040 - accuracy: 0.9424 - val_loss: 0.8592 - val_accuracy: 0.6485\n",
      "Epoch 637/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2029 - accuracy: 0.9398 - val_loss: 0.8495 - val_accuracy: 0.6512\n",
      "Epoch 638/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2047 - accuracy: 0.9411 - val_loss: 0.8816 - val_accuracy: 0.6485\n",
      "Epoch 639/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2045 - accuracy: 0.9411 - val_loss: 0.8718 - val_accuracy: 0.6431\n",
      "Epoch 640/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.2023 - accuracy: 0.9398 - val_loss: 0.8844 - val_accuracy: 0.6594\n",
      "Epoch 641/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2028 - accuracy: 0.9358 - val_loss: 0.8581 - val_accuracy: 0.6512\n",
      "Epoch 642/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.2038 - accuracy: 0.9391 - val_loss: 0.8460 - val_accuracy: 0.6649\n",
      "Epoch 643/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.2027 - accuracy: 0.9490 - val_loss: 0.8560 - val_accuracy: 0.6512\n",
      "Epoch 644/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1963 - accuracy: 0.9471 - val_loss: 0.8948 - val_accuracy: 0.6267\n",
      "Epoch 645/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1960 - accuracy: 0.9477 - val_loss: 0.8630 - val_accuracy: 0.6403\n",
      "Epoch 646/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1920 - accuracy: 0.9457 - val_loss: 0.8802 - val_accuracy: 0.6349\n",
      "Epoch 647/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1950 - accuracy: 0.9464 - val_loss: 0.8792 - val_accuracy: 0.6403\n",
      "Epoch 648/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1961 - accuracy: 0.9424 - val_loss: 0.9025 - val_accuracy: 0.6431\n",
      "Epoch 649/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1887 - accuracy: 0.9504 - val_loss: 0.9022 - val_accuracy: 0.6458\n",
      "Epoch 650/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1982 - accuracy: 0.9418 - val_loss: 0.8985 - val_accuracy: 0.6403\n",
      "Epoch 651/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1926 - accuracy: 0.9464 - val_loss: 0.8797 - val_accuracy: 0.6512\n",
      "Epoch 652/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1940 - accuracy: 0.9523 - val_loss: 0.8839 - val_accuracy: 0.6376\n",
      "Epoch 653/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1910 - accuracy: 0.9464 - val_loss: 0.9501 - val_accuracy: 0.6240\n",
      "Epoch 654/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1850 - accuracy: 0.9471 - val_loss: 0.8766 - val_accuracy: 0.6540\n",
      "Epoch 655/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1884 - accuracy: 0.9537 - val_loss: 0.8746 - val_accuracy: 0.6621\n",
      "Epoch 656/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1873 - accuracy: 0.9457 - val_loss: 0.8659 - val_accuracy: 0.6567\n",
      "Epoch 657/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1872 - accuracy: 0.9490 - val_loss: 0.9071 - val_accuracy: 0.6240\n",
      "Epoch 658/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.1860 - accuracy: 0.9484 - val_loss: 0.8733 - val_accuracy: 0.6567\n",
      "Epoch 659/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1862 - accuracy: 0.9530 - val_loss: 0.8937 - val_accuracy: 0.6512\n",
      "Epoch 660/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1881 - accuracy: 0.9431 - val_loss: 0.8812 - val_accuracy: 0.6540\n",
      "Epoch 661/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1885 - accuracy: 0.9471 - val_loss: 0.8864 - val_accuracy: 0.6376\n",
      "Epoch 662/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1821 - accuracy: 0.9550 - val_loss: 0.8750 - val_accuracy: 0.6512\n",
      "Epoch 663/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1817 - accuracy: 0.9543 - val_loss: 0.9023 - val_accuracy: 0.6485\n",
      "Epoch 664/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1842 - accuracy: 0.9457 - val_loss: 0.8913 - val_accuracy: 0.6512\n",
      "Epoch 665/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1772 - accuracy: 0.9537 - val_loss: 0.9322 - val_accuracy: 0.6376\n",
      "Epoch 666/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1767 - accuracy: 0.9616 - val_loss: 0.9010 - val_accuracy: 0.6512\n",
      "Epoch 667/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1801 - accuracy: 0.9504 - val_loss: 0.8704 - val_accuracy: 0.6567\n",
      "Epoch 668/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1793 - accuracy: 0.9510 - val_loss: 0.8995 - val_accuracy: 0.6431\n",
      "Epoch 669/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1830 - accuracy: 0.9537 - val_loss: 0.9087 - val_accuracy: 0.6458\n",
      "Epoch 670/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1785 - accuracy: 0.9504 - val_loss: 0.8816 - val_accuracy: 0.6567\n",
      "Epoch 671/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1735 - accuracy: 0.9570 - val_loss: 0.9304 - val_accuracy: 0.6322\n",
      "Epoch 672/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1784 - accuracy: 0.9563 - val_loss: 0.9109 - val_accuracy: 0.6485\n",
      "Epoch 673/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.1741 - accuracy: 0.9570 - val_loss: 0.9184 - val_accuracy: 0.6349\n",
      "Epoch 674/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.1732 - accuracy: 0.9537 - val_loss: 0.9346 - val_accuracy: 0.6403\n",
      "Epoch 675/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.1744 - accuracy: 0.9563 - val_loss: 0.9075 - val_accuracy: 0.6376\n",
      "Epoch 676/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1728 - accuracy: 0.9629 - val_loss: 0.8839 - val_accuracy: 0.6458\n",
      "Epoch 677/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1710 - accuracy: 0.9510 - val_loss: 0.9252 - val_accuracy: 0.6185\n",
      "Epoch 678/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1715 - accuracy: 0.9484 - val_loss: 0.9234 - val_accuracy: 0.6376\n",
      "Epoch 679/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.1732 - accuracy: 0.9530 - val_loss: 0.8999 - val_accuracy: 0.6540\n",
      "Epoch 680/700\n",
      "95/95 [==============================] - 12s 125ms/step - loss: 0.1663 - accuracy: 0.9603 - val_loss: 0.8962 - val_accuracy: 0.6458\n",
      "Epoch 681/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1682 - accuracy: 0.9616 - val_loss: 0.8944 - val_accuracy: 0.6458\n",
      "Epoch 682/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1685 - accuracy: 0.9610 - val_loss: 0.9064 - val_accuracy: 0.6567\n",
      "Epoch 683/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1644 - accuracy: 0.9543 - val_loss: 0.9061 - val_accuracy: 0.6458\n",
      "Epoch 684/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1696 - accuracy: 0.9563 - val_loss: 0.9576 - val_accuracy: 0.6267\n",
      "Epoch 685/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1597 - accuracy: 0.9610 - val_loss: 0.9137 - val_accuracy: 0.6376\n",
      "Epoch 686/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1608 - accuracy: 0.9623 - val_loss: 0.9007 - val_accuracy: 0.6594\n",
      "Epoch 687/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1690 - accuracy: 0.9557 - val_loss: 0.9641 - val_accuracy: 0.6322\n",
      "Epoch 688/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1624 - accuracy: 0.9603 - val_loss: 0.9396 - val_accuracy: 0.6403\n",
      "Epoch 689/700\n",
      "95/95 [==============================] - 10s 105ms/step - loss: 0.1639 - accuracy: 0.9537 - val_loss: 0.9137 - val_accuracy: 0.6322\n",
      "Epoch 690/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.1629 - accuracy: 0.9623 - val_loss: 0.9140 - val_accuracy: 0.6458\n",
      "Epoch 691/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1622 - accuracy: 0.9610 - val_loss: 0.9093 - val_accuracy: 0.6594\n",
      "Epoch 692/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1589 - accuracy: 0.9623 - val_loss: 0.9067 - val_accuracy: 0.6458\n",
      "Epoch 693/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1596 - accuracy: 0.9610 - val_loss: 0.9881 - val_accuracy: 0.6267\n",
      "Epoch 694/700\n",
      "95/95 [==============================] - 10s 104ms/step - loss: 0.1582 - accuracy: 0.9623 - val_loss: 0.9282 - val_accuracy: 0.6376\n",
      "Epoch 695/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1598 - accuracy: 0.9629 - val_loss: 0.9484 - val_accuracy: 0.6485\n",
      "Epoch 696/700\n",
      "95/95 [==============================] - 10s 102ms/step - loss: 0.1585 - accuracy: 0.9623 - val_loss: 0.9191 - val_accuracy: 0.6512\n",
      "Epoch 697/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1599 - accuracy: 0.9643 - val_loss: 0.9410 - val_accuracy: 0.6349\n",
      "Epoch 698/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1598 - accuracy: 0.9576 - val_loss: 0.9148 - val_accuracy: 0.6485\n",
      "Epoch 699/700\n",
      "95/95 [==============================] - 10s 103ms/step - loss: 0.1552 - accuracy: 0.9656 - val_loss: 0.9459 - val_accuracy: 0.6458\n",
      "Epoch 700/700\n",
      "95/95 [==============================] - 10s 101ms/step - loss: 0.1590 - accuracy: 0.9590 - val_loss: 1.0140 - val_accuracy: 0.6322\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "FNzT2NOfErGO",
    "outputId": "aa0b6a16-3efb-4df8-8de1-887a43beb79e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfrw8e+dXgmQ0APSm1JFFBEbFsqufVHsrgr66k9dV1fdXcvqurbVdV0LNtaOCjZUVERBcBGk995DS2gppGee94/nDDOTTBpkMpPM/bkurpk558yZe0Jy7vN0McaglFIqfEUEOwCllFLBpYlAKaXCnCYCpZQKc5oIlFIqzGkiUEqpMKeJQCmlwpwmAqVqSETeEpG/1/DYrSJyzrGeR6n6oIlAKaXCnCYCpZQKc5oIVKPiVMncKyLLReSwiLwpIq1E5BsRyRWRGSLSzOv4C0RklYgcEpFZItLLa98AEVnsvO8jIK7cZ/1GRJY6750rIn2PMuabRWSjiBwQkaki0tbZLiLyLxHJFJEcEVkhIic4+0aJyGontp0ics9R/cCUQhOBapwuBc4FugO/Bb4B/gy0wP7O3wEgIt2BScBdzr5pwJciEiMiMcDnwLtAc2Cyc16c9w4AJgLjgVTgVWCqiMTWJlARORt4AhgDtAG2AR86u88DTne+R4pzzH5n35vAeGNMMnAC8GNtPlcpb5oIVGP0H2PMXmPMTmAOMN8Ys8QYUwh8Bgxwjrsc+NoY870xpgT4JxAPnAqcAkQDzxtjSowxU4AFXp8xDnjVGDPfGFNmjHkbKHLeVxtXARONMYuNMUXAA8AQEekIlADJQE9AjDFrjDG7nfeVAL1FpIkx5qAxZnEtP1epIzQRqMZor9fzAj+vk5znbbF34AAYY1zADqCds2+n8Z2VcZvX8+OAPzrVQodE5BDQ3nlfbZSPIQ9719/OGPMj8CLwEpApIq+JSBPn0EuBUcA2EflJRIbU8nOVOkITgQpnu7AXdMDWyWMv5juB3UA7Z5tbB6/nO4DHjTFNvf4lGGMmHWMMidiqpp0AxpgXjDEnAr2xVUT3OtsXGGMuBFpiq7A+ruXnKnWEJgIVzj4GRovIcBGJBv6Ird6ZC/wClAJ3iEi0iFwCDPZ67+vALSJystOomygio0UkuZYxTAJuEJH+TvvCP7BVWVtF5CTn/NHAYaAQcDltGFeJSIpTpZUDuI7h56DCnCYCFbaMMeuAq4H/APuwDcu/NcYUG2OKgUuA64ED2PaET73euxC4GVt1cxDY6Bxb2xhmAA8Cn2BLIV2AK5zdTbAJ5yC2+mg/8Iyz7xpgq4jkALdg2xqUOiqiC9MopVR40xKBUkqFOU0ESikV5jQRKKVUmNNEoJRSYS4q2AHUVlpamunYsWOww1BKqQZl0aJF+4wxLfztC1giEJGJwG+ATGPMCVUcdxK2z/YVzjD+KnXs2JGFCxfWXaBKKRUGRGRbZfsCWTX0FjCiqgNEJBJ4CpgewDiUUkpVIWCJwBgzGzsQpyr/hx1IkxmoOJRSSlUtaI3FItIOuBh4pQbHjhORhSKyMCsrK/DBKaVUGAlmY/HzwH3GGJfvvF4VGWNeA14DGDRoUIWh0CUlJWRkZFBYWBiQQENJXFwc6enpREdHBzsUpVQjEcxEMAj40EkCacAoESk1xnxe2xNlZGSQnJxMx44dqS6pNGTGGPbv309GRgadOnUKdjhKqUYiaInAGHPkSiYibwFfHU0SACgsLGz0SQBAREhNTUWrx5RSdSmQ3UcnAWcCaSKSATyMXfEJY8yEAHxeXZ8yJIXL91RK1Z+AJQJjzNhaHHt9oOJwKywp41B+CWlJMURF6oBqpZRyC5srYlFJGZm5hZS66n7a7UOHDvHyyy/X+n2jRo3i0KFDdR6PUkrVRtgkApwqlUCsv1BZIigtLa3yfdOmTaNp06Z1Ho9SStVGg5tr6Gi5a9YDsQzP/fffz6ZNm+jfvz/R0dHExcXRrFkz1q5dy/r167nooovYsWMHhYWF3HnnnYwbNw7wTJeRl5fHyJEjOe2005g7dy7t2rXjiy++ID4+PgDRKqWUr0aXCP725SpW78qpsL3MZSgsKSM+JpKIWja49m7bhId/e3yl+5988klWrlzJ0qVLmTVrFqNHj2blypVHunhOnDiR5s2bU1BQwEknncSll15Kamqqzzk2bNjApEmTeP311xkzZgyffPIJV199da3iVEqpo9HoEkF16mNhzsGDB/v083/hhRf47LPPANixYwcbNmyokAg6depE//79ATjxxBPZunVrPUSqlFKNMBFUdud+uKiUTVl5dE5LJCkusKNyExMTjzyfNWsWM2bM4JdffiEhIYEzzzzT7wjo2NjYI88jIyMpKCgIaIxKKeUWPo3FjkCUCJKTk8nNzfW7Lzs7m2bNmpGQkMDatWuZN29eACJQSqmj1+hKBJVxNwsEoNMQqampDB06lBNOOIH4+HhatWp1ZN+IESOYMGECvXr1okePHpxyyil1H4BSSh0DCUR3ykAaNGiQKb8wzZo1a+jVq1eV7ysoLmNDZi7HpSaQEh8TyBADribfVymlvInIImPMIH/7wqZqKJAlAqWUasjCJxE4j5oHlFLKV/gkAi0RKKWUX+GTCIwhlhIwrmCHopRSISVsEkFEcQ49IjKIcBUHOxSllAopYZMIEOerat2QUkr5CJtEcGRBlwBUDR3tNNQAzz//PPn5+XUckVJK1VzYJAJ3iaA+p6GuCU0ESqlgC6ORxbZEIAEoEXhPQ33uuefSsmVLPv74Y4qKirj44ov529/+xuHDhxkzZgwZGRmUlZXx4IMPsnfvXnbt2sVZZ51FWloaM2fOrPPYlFKqOo0vEXxzP+xZUXG7KYOSfJIiYiGqliOLW/eBkU9Wutt7Gurp06czZcoUfv31V4wxXHDBBcyePZusrCzatm3L119/Ddg5iFJSUnjuueeYOXMmaWlptYtJKaXqSNhUDQn1s+j79OnTmT59OgMGDGDgwIGsXbuWDRs20KdPH77//nvuu+8+5syZQ0pKSr3Eo5RS1Wl8JYLK7txLiyBzNXkxbWia1jpgH2+M4YEHHmD8+PEV9i1evJhp06bx17/+leHDh/PQQw8FLA6llKqpsCkRHBlaHIBJJrynoT7//POZOHEieXl5AOzcuZPMzEx27dpFQkICV199Nffeey+LFy+u8F6llAqGxlciqJR7HEHdNxZ7T0M9cuRIrrzySoYMGQJAUlIS7733Hhs3buTee+8lIiKC6OhoXnnlFQDGjRvHiBEjaNu2rTYWK6WCImDTUIvIROA3QKYx5gQ/+68C7sPOB5cL3GqMWVbdeY92GmpcZbBnOdlRLUhpmV7j7xGKdBpqpVRtBWsa6reAEVXs3wKcYYzpAzwGvBbAWDwji3X+UaWU8hGwqiFjzGwR6VjF/rleL+cBgb1NF7EpQCedU0opH6HSWHwj8M2xnKAmVVwGafBzDTW0FeWUUqEv6IlARM7CJoL7qjhmnIgsFJGFWVlZFfbHxcWxf//+ai+SBqEhVw0ZY9i/fz9xcXHBDkUp1YgEtdeQiPQF3gBGGmP2V3acMeY1nDaEQYMGVbiSp6enk5GRgb8k4c11KItiySbuYOGxBR5EcXFxpKc37MZupVRoCVoiEJEOwKfANcaY9cdyrujoaDp16lTtcXv+filrI7oy4M9Tj+XjlFKqUQlYIhCRScCZQJqIZAAPA9EAxpgJwENAKvCyMyFcaWVdm+pKSUQcMa6CQH6EUko1OIHsNTS2mv03ATcF6vP9KY2MJ6a04VYLKaVUIAS9sbg+lUbGE+PSRKCUUt7CKhGURcYRS1Gww1BKqZASXokgKoE4oyUCpZTyFlaJwBUVTzxFlLka7lgCpZSqa2GVCIi2iaCwpCzYkSilVMgIr0QQk0g8RRwuLAl2JEopFTLCKhFExiYSJS7y8g8HOxSllAoZYZUIIuKaAFCYezDIkSilVOgIq0QQmdgMgKLcA0GORCmlQkdYJYLoxOYAFB3WEoFSSrmFVSKITbKJoDRPE4FSSrmFVSKIa5IKgCnQRKCUUm5hlQjinUTgKjgU5EiUUip0hFUiiE22VUNSqIlAKaXcwioRSFQsBcQSWZQd7FCUUipkhFUiAMgjkahiTQRKKeUWdongcEQS0SW5wQ5DKaVCRtglgoLIZGJLc4IdhlJKhYywSwSFUcnEl2mJQCml3MIuERRFNyHRlRfsMJRSKmSEXSIojU4h0WgiUEopt7BLBCYuhSQKMGW6JoFSSkEYJoKIBDsD6eEcnYFUKaUgDBNBlJMIcg/uC3IkSikVGgKWCERkoohkisjKSvaLiLwgIhtFZLmIDAxULN5inGkm8rI1ESilGpBJY2HxuwE5dSBLBG8BI6rYPxLo5vwbB7wSwFiOiHcSQUHO/vr4OKWUOnbGwPpv4dC2gJw+YInAGDMbqKoi/kLgHWPNA5qKSJtAxeOW2LQFAH1n3gD7Ngb645RS6tiVFYNxQXR8QE4fzDaCdsAOr9cZzrYKRGSciCwUkYVZWVnH9KFprdI9L7b9fEznUkqpelGSbx+jEwJy+gbRWGyMec0YM8gYM6hFixbHdK74JmmeF7HJxxiZUkoF0IYZcHgflBTY142wRLATaO/1Ot3ZFlgRXl9ZIgP+cUopdVRKi+D9S+Hdi7wSQeMrEUwFrnV6D50CZBtjdtdrBKWF9fpxSilVY+7rU+Yar6qhwJQIogJyVkBEJgFnAmkikgE8DEQDGGMmANOAUcBGIB+4IVCxlFcYkUic6zAUH66vj1RKqdopcRKBqyzgVUMBSwTGmLHV7DfAbYH6/Kq8d8qX3DT3bEoKD9vMpJQKL6s+g8nXw72bITG15u8zxvbeiQhgtXLmWsjdBc27uD9UG4sDIbW5HUuQm6frEigVluZNsI/71tXufbOfgUebQ3F+3ccEsPVnePlkePdi20bg1ogbi4OmbfMmFJtI8nJ1XQKlwpI4lz7jqt37FrxhH4uquYl0lUHu3trH9dZoz/Nir+uTlgjqXofUBAqJJf+wlgiUCktHmwjcXGVV75/+V3i2OxQcrMU5y8Vy0GsU8aaZ9lFLBHWnVXIcBcRSmK/rEigVlkTs49EmgrKiqvev+dI+FmbX/JzF5a5HB7d4ni9x5hiKSar5+WohLBNBRIRQFJlAXF4GfHgV7F0d7JCUUvWppiUCY+DQjorbS6tJBMbYx/Ilh72rPPvyD8A393vq/8snggNbqCCuadWfe5TCMhEArEoaQs+CxbD2K/j2vmCHo5SqTzVNBHP+Cc+fUPGiXNMxSN7HbZ4Fr5wKi9+BGY/A051g/iuw7ENbLVRUg0QQEZhLdtgmguzU/p4XCbXoPqaUavjciaC6un53Fc+Run6nSqm0uJoPcO76S7wSwf5N9nHnQvj5X57tX90FE4b6Ng4DHNhczWfUnbBNBPGpx3leJKRVfqBSqvFxJ4Kyai7oBYfsY0S5IVfVlQjcJY3SAs+2SGfUkr9lcjNX2zmFvOXuqvoz6lDYJoLu3Xp4Xuxa4qm3U0o1fu5EUF1dv7uxt/zFu6ZtBIXZnjEH7qRT/oLvlrXW//bxs+1jj9H+99eBgI0sDnU9unTxvNi50LbKD7w2eAEpperPkRKBn7tzN2Og0CkRlO8lVFmJ4NB22D7fc9H/8Er7+Eg2rJ1mn2/83v97v3/I87zdibBzkX2e2tW+P4DCtkQQERXFs129ln2b+YSnDk8p1bi5p4jwvsCXldhePO6BYDsXe/aVLwGUr1Iyxjb2znwCPr0JCsqtyZWXCZt+8N3Wpj9Exflui4y1j637wn1b4bqvICaxxl/raIVtiQCgZdd+dso7sPVxLw2Gh3QJS6UaNWNgz3L73LvRd8N024snbw/87i047LUIVvkLf/kSwdL34YvbILmt/890lwy8leTbAWLe5/rdW5DYAlr1tgmg07CafqtjEtaJoGuLcoMzXKXBCUQpVX9WfmKrcMD3Au+uJnI/evfr37UUup/vGYjmffFe9w0snWSfV9bAm7Gg4rbifIhOtD2SbvkZcnZB13MD1kW0KmFbNQTQu02TYIegVP3YNBMeSdHqT/BtlPWuGtrxq30UsSuDfXqzZ9+sf/iWHtxVRY+kwKQrfJe9rWo+oLYDPM9T0uGkGz3Pu58flCQAYZ4IUhKi2ZfUM9hhKBV4Kybbx+2/BDeOkCCep+67/5ICmPeSszvCrgxWfrCZd1VRSYHvGAFvI5+Gbuf535foLLV7wqVw+btw2h/gL3sgvlntv0YdCutEALBrzFesdHWsuMPlqn6wiVINjXaT9vQYAs+dfZH3YC7Br7y9niqhfeshv5JuoAOvgasmw8m3eLZd+wVc8B9IP8m+PvkWSGppSx8BmkiuNsK6jQCgV7tUlklsxR2fjbN3UQHutqWUqicrpkDTDp56foC9K2Hr/6BJG882qSQR/PCoZ4TxhunQ/uSqP+/k8TB/AlwxCTqfabe5yuzz9oOP7jsESNgngujICIoS20G+s0DFnpXQ+gRPUdrlClq9nVJ1rrKLXDj4xKmPP8VrYcQN0+2/tgM926SSv/fNzlTQQ26HX16Er++2r5PbQK6z3Pr/m+c5vnlneOig7/UjIjLkkgBo1RAA/W95k8PGKRVMGAoLJ3p2FmmJQDUijalqyBj/32fZh/Dm+ZW/z90W4G2X15iBqgaZgW3U9Z6W5rhT7ePxl0DLXr7HNpCbyIYRZYAlNmnOTy28+vl+9QfPc++Jnz66Gr68s/4CU6rONMKSwKSx8Dc/0zJ/Nh52zIM3z/Ms7lLdxd1bcZ5nbqFWfTzbO50OF78GHYd56vpjkqDXBfZ5x6G1/w4hQhOBo9dpF/vf8frZnudrvoRFb9VLPEo1KCs/gfXTaz5CP2c37F52FJ/zKbw8BFZ9Duu/qfrYHfM90zQU1mI1wk0/2jFFUfFw/Zee7dd9Cf0ut9VrF70Mp90N92yA3hfC9dNg0I21/z4hQhOBo1O/05mXepH/neWXkPO2d3W5HgeqQSjK9UwxHBYCXCU05ffwwe/gpyfh/d9Vf/yEofDq6TU//7a58OoZMOUGO1Pn5Otq9j7332ZNq3jdd/pg+/hX1q0zoTmc8zDEJNjE0HFog25/0UTgJkLLK17iurK/VNz3aDOY9ZTndVmpnUEwdw+8MsQWUVXD8sXttqova32wI/GVvdMzW2VDVd3MnAD5zlQulfXFB1v/7yqzf2f/HQm7l/o/bu20yj/T3cvHPYtos05Vx5XUyvP8+Evs4xWT4P8W+z++kdBE4KVziyRuveFGPisbSkF0M7jkdc/OWf/wPH8sFZ7pAhNH2Ndb58DUOyovfu7fBN/9peqShapf7rafkhC66BoD/+ptE1Sdq8e7Ve8749IimPdK5Rdqd28bsH8f3qty/fQUPNocpj9Y9ed9OBb+3c+W8D4uV1KY8TBsnwdL3rOvL3zR/zm6nQfpg6Hjafb12A8h/UT7vOcoSO3i/32NREATgYiMEJF1IrJRRO73s7+DiMwUkSUislxERgUynpo4pXMqH6Y/yEmFL7G1zciqD/ZeXHrx27DwTf/HTb7Odjfbv6HuAj2wBZZ/XHfnCzs1rCrJ3WPrvesjibvnqS8/S2VdMvUxSNIrESz/CL69H35+vtwhzqXHOxH89BS80N/eOK36HGY9YbfX5O8md7dNoKs/r7hv4vmw4A37PLWbZ/tJN9nH1n3tALCbvofB421bQPcR1X9mIxKwRCAikcBLwEigNzBWRHqXO+yvwMfGmAHAFcDLgYqnNp67vD8uieTMZ2dTGp1U/RvcVk/1353NXfz96Wl7YakLb5xj50LRUsbRcf8/VVev+/mttt5758K6jyF3j+/vi3siNPc0BNUpLYbiw7X7zLIS+5lb5gSuK6lg5+T/4ApPNVf5qS3c3S/dvXoANs6wj3Oe9W0D2F9HSzb+aQskt4IOp0KTdBg8zm6P9ZpzLCLC9g5qwPX9RyOQJYLBwEZjzGZjTDHwIXBhuWMM4P5fSAHqb222KrRrGs/H44cAMKewFkXCXYttMbgC5w9u5RT4/P/Z53lZ8O/+kOlMgJWdUbs1St3D20tqeSEIFwc216xXyp4VVa8/677Q1vV0I7uWwrM97ELmboeci6J3PXVV3jwX/tEW5jxXdXw5u2CP87NwldnPfPs3sOqzyt9TVur57v9It6NqK7P+u3IbBD6+1vbqcffPd8/su3+TbVOLS7Gv966E+a/avwN3st1QbuGW2o7lGf2c5/lJN9sL/5Uf2wZegN9/A3evgrTucO6jcMlrtTt/IxTIkcXtgB1erzOA8mOyHwGmi8j/AYnAOf5OJCLjgHEAHTp0qPNA/TmhXQqnd2/BnetvZ3nkzdW/wW3vyorbvCev2vSDnbFw+MO2amnOP203tFds4qn1lBZFeRCbXLv3+JO5FtZNg2F3H/u56tKh7fbOubajMV9wZnms7Ofpvhv+4jbYvRxGPX30MR6NLGck+9Y5tv65RS9Pw2ZMkq1T3zgDelaxPKG78fSHv9lRrMdX0uvt+T6eC7GrBDK32uc5Vdx3fX6LZ4qV4lx7lz78If/HfjDG97WI53feXefvbqz99n47ktftFz919oczK4+rOv2vtr19TrzeVj9VdWcvAkN1XBDUsEQgIneKSBOx3hSRxSJSyfR6tTIWeMsYkw6MAt4VqTi+2xjzmjFmkDFmUIsWNSw214H/jB3A5cNO4KTCl7mRh1h34VfVzxKYlwlz/wOz/2kvNtvn+b/Td/dvXjHZkwTKO7DZ8wdUmeI8e/d2rP470l5QqurFEQzP97F3vnXOq1ok49cqjnNfSAJUjeIqg7dGw3uXeCY0E4EfH7OLmWz9uer3uxXl2hkx//dCxcFT3utslJV4PifKzxxbbu4pVvIPVH4MVDJmQDxtEe4SQcFBmxQy6qCK7bZf7V3/VVMgxevGcMRTMNLp3RcRGXbVO8eipiWC3xtj/i0i5wPNgGuAd4HpVbxnJ9De63W6s83bjcAIAGPMLyISB6QBx3BLUHdS4qP586henNG9JX+asozzP8ohOfZVlibcSmRBuZXMklrZP+pNP3rWJG3e2bYL+LP2q+oDeGGAHdl4axUXg/XfwfS/2C5uPY+hrd29CEdpAUTHVX1sY+BdPx4ZU/3xVS1aNPUOyFxjGxtrHoB9WP2FfdyzHHpf4Nntrhev7kLsVlYMv74O3z8IkdFwyq3+j3OVenrwLH7HNphWdcF0l1x8Qjew6lO7iMp/Blbc710icP/csnfYhuC6kNoNWvSwz/+wwia3vExIaVc35w9DNW0jcP+mjALeNcasovr+aAuAbiLSSURisI3BU8sdsx0YDiAivYA4IIsQIiKc1i2Nt39vqyZyi0q5mGfZevmPvgcO+6PteubdK2PKDZC1pnYf6G78dXdF3bui6uPdKx/9Wkk956K34JmuNWgYdP47Swo8j3kh9V/hkbHQ07ZSnUq/t9f2iOjqz1NV3/jFb1dTqqiC+/dFIv1/Rk3vastKPOeaW0kXSfdx7hLBnuX+++a71+wF2OcnEWz60Q4gm3y9/884sNlTzQWVL99Y2Zz9blHxdrbQ374AfX5np3Y4/d6K8/dERmsSOEY1TQSLRGQ6NhF8JyLJQJXdVYwxpcDtwHfAGmzvoFUi8qiIuG99/gjcLCLLgEnA9caE5qxY3VolM++B4dx0WieWH4zhvPcymXnaB5i+Y+C2BfbOKtlrKtv0o5xhcOrt9o81O6Pq49w1aO563u3zfMcxFByyF/Iv77QLargv8GDvMj+7xfd49wVnx6+2zvy9S+GfXWsXe3F+7Rq8a8O7MfSN4fDyyRW3+1PZBdynRFCDRHBwq+2rvm9jtYcCtqpm+7zqj3OLiPRcoEuLOJKoajI4C2yJwP2dcjIq753mXSIA398Lt2/u9TxfPtl3395VduoGgM2zahZbZX3wk9vAn3fBtVPh1rlw/deefb0ugD9tgrtWwInXwaVvwPVfwdl/rdlnqlqpadXQjUB/YLMxJl9EmgM3VPcmY8w0YFq5bQ95PV8NNJiZmlqnxPGX0b0Ye3IHbnt/MTfMyOXSgbdz8tZ4LmkuRJ31gP2Djk2GlPa2fvSiCfZCU9Mh8Uvft32YvY83puKdoUTY4ne20x5fWgAfX2MXwDiwpWIxvCjHDocvLYanndGVad29Goed85ePs/xn52XZRbVj/CzHN/k62xBYfurdulBSALHluvLuWWmnKrhqCnSrpB2hOK+Sqq4aVg25v/vS920y+PW1yhuW96yACcNg7CR7/Jov4d7NkJha8djyCcy7RFBa5Lmou6dIOLAZFr1tOxn4+9mWFkHhIc/rgoOQ3NrP55b4rrdbUgBL3rcJok1f263Tu83JewnGr//o6Y8PNR+TMPo5W2pyNwwntbYLxO/faH+XOp9R8T39r7L7VL2oaSIYAiw1xhwWkauBgcC/AxdW6BIRurRI4ovbh3LNm7/yyeIMPlmcweZ9h0mJj+amcx4jOtL5Q+13hU0MAB032UWup94OiS2r7hkx55++PY3mT6hY5+tvQM7mWfBEe3vR9z7OuOzdf3Jrz5zq4HtcZXYtsf3amzrNPf/sCm36w/ifKh7r7g1SnOvpHgi2dBIZ40keq6fC3Bfgxu/thfbgNnuh63JW5XGUFlZMBDucO+61X1edCBK9pgzOWATNO9WiROAkAnejfVUNrBOcUamTrvBsO5zpPxGUlbvTj4jy3J2XeZUIcnfb6sIpv7f/F/3G2vrx8iWFohzPtA1gE9bwhyp2bpj7H9/X711S+fcpzzsJ1EZqF1u188uL0PJ4uHoKPNfL/3iJhw7a3wlt6K1XNU0ErwD9RKQftjrnDeAdwE8qDw+xUZG8ctVAZq3L4pnv1jHhJ9t7IipCOL17C7q3SkLcSQDsxai5cyfe1LlYl1bSQ8fd/z0myV7IVkyGFj1h9jO2P/TBrbYqwJ/yF3eJtInAvd37TrQoz+u4Sv7wXncuzt7dMHcvtX3Qj/easdX7vIU5vongqePsHC93OvXRH19jH4sP24v762fZi9jDhzxxFOXB8g8956jJVBBlpYDxvbB7f8fSInjj7Apvq1HVUIFzt13bZQVz91Sco+7sUfoAACAASURBVH73Mvj+Ed9tRTn2rhnsz2/9t/b5T0/ZEqa7N1dJPix5F6b+n+/7Cw/ZpRTdFk60yeuiCbWL163jMNu1tTbSenjaFC77r50czrjszVBqF5vsznoAmrS1o3db9614jgYyf39jU9NEUGqMMSJyIfCiMeZNEWm4c67WkdSkWC49MZ3UpBh+XJvJO79s4/Fpa3h82hpOPK4ZCTGRPDumHy2TnaqJDqfCmHeg/Sn2dcFBu0Tek04XuMHjYdF/PRf5370F718GCam2zt6UwbJJMO2emgfpcroSuu9ovYvzNVmn1Zv3wKvJ19s/8hMuta+f9OrGV5iNb4cxfKfj8D4uNslzJ7tvvb3bXf6x7U3j3bPKX7fW8qODXxxk20P+7NU5zXvk7eFK1piVSP/bvXk3ftaG98XZze+sm14llPKlxc2zPPPj5++HZR9VfPu+jXZAWtsBtuQAdmro1eX7Z9RQSjqMedeTtMs78QZ7c9P5LDtQMn8/jP4XPNPZ7j/hEsCrtBGbDA95lVg61WLmURVwNU0EuSLyALbb6DCnr38NbqPCw5k9WnJmj5bcdlZXxr1rxwcs2mYvHIMf/4GerZO54qT2XD+0k5273C3ZGUF68Wuw7AMYcpsdQLX+GzjrL7a6o+1A3wE4Pzx2dEF+8yd7B+899bL3xa26onjBQfjgct9ta77yJIJirzvv6sY+eB8326u+/aXBcNErdlqH8nIy7NiLPpd5tnl/JniSzSav6i/vWCpbbNxV4n+7D+dCnbfXs5ypP+76b7fsHb77a7NASvtTbPVXYgtPEju8z39X1u1z7WPvCz2JAGr43bwkt4XcXdD3cltVF9fUljbG/WRLeSX59v9hwDWe3xnvBVmu+RyyatijS4WMmpbDLgeKsOMJ9mDHBDwTsKgaqFZN4vjitqF8cdtQtjwxijvOtr1u1u7J5ZEvV3PyP2Ywa52ftoF+l9tG3mbH2QUvxv0EZ/zJ7mvpTM/UYYgtIXgPt3c3cp56R/XT5O7faKuWvP9Ic71HllaTCJa87+kt4uauLy8/31FRju0xM/kG3zvy9d/51s1vn1txoZ/y0wu4vXeZHe3q3Ssp27nzL79k4bteI2zz9sDEkTY5VFYiqGqKCVPuuy16yzZQvz/GNsrPfMJ3f/l67x//bu/Mj8RcTW8wb1dPse0xW2Z7unl+founbcSfDpUMTqyJ0c/ZnjnXT/O011w1xVYTtehhqzZbHQ8Dr638xqHLWZWPYVAhq0YlAmPMHhF5HzhJRH4D/GqMeae694UzEeHu83rw+dJdbD+QT1JsFPlFZTz65WoO5ZfQvVUyGzJz6ZfelI5pXr0jEpp75kQBOO8xGHyzrWONTbbVOe764Y7D7JQVcU0qdtE79zE7uKgq+zbau7v45tWXCNwjob0VZtvlAPuWm2Lg5+dtwik8BCeP92wvPxXB13+seM5Vn/r/fHeVVp6fPu6L/mv/+Y17sU04715kS17gaXtxczfcFuXCp+NtHf7Aa+DM+ys26rpt+M7WgZe/4/c3xciit213yMhoz3xCNRGbbBNLZfPw+9POGeDV/hQ7QO27P9vXd6+1Jcsv77C9xfY56zA0SYcbv7NVT+5eRt6/S+1PsslBNWo1SgQiMgZbApiFvXX8j4jca4yZEsDYGoWv7jgN44KUhGi+XbmHeyYv466PfP+w5/zpLOJjIklL8tMjpXxiGHitnU8lZ6dthJvye9sjA+CW/8H8V6DHaN/qCbeU9r4XrtIC36U4q+J9ge57hW3IXef0DC5fUtgxzzNI62iWI6xKjlcvKX+jXsvzvjD/4vSYadLWcyEETw+cr+6GdU5f9llPQOs+vmMtWvXxHeBXPgkAR6qQrvkM3nUa07f8BI+lOQ3ofhJu+cTUcZhdkQsg3mtN3rQetg3AuxHdW1QcNGkHf1ht25Wi42yHhIPb7EW+9wU2EXQZDr9723bPbHac/3OpsCI1Gb/lDPg61xiT6bxuAcwwxvQLcHwVDBo0yCxcGIApgeuJy2WYs3Ef102sOBL1uTH96JueQue0JCIijrH7XGmx7Xbauo+9A9z+i70r3TrHzmOT3MY2QvrrjROTBB1OsQ3bEdHw6U2eqRAAfj/dnm/Gw9XH0fQ4exd86ZvwSR30Lzjjfjst9NGKirPtDEvesxOObZtrq83OuM9OiFZeZIxdqarPZbBmqu9soVV5+JCtq3f3uvLWpr/tBvrtffb1nctsg/XzJ0Czjraaz7hsCWLNV/DRVXDBf2x7TEwiHNph6/4X/td2w+17BZx+j+0qXN0CKjm77Y1FVd1gVaMkIouMMYP87qthIlhhjOnj9ToCWOa9rb409ETgtn5vLqt2ZfOHjyreMfdq04SEmEgevfB4jm+b4ufddcQYW+XzxnC7VuuVH9tG4abH2aoid/fXA84sqaVFNiH8cZ29UH023jOHPNgL66l3enqOSKSnSmfcLHjtzKOLs9cFtp7ce8DUsbh3E3z/EIx4wrZj+FsIJiLK0yg7+lk7cnz2P20SdYtNgfP/bhdUd4/PuPF7+/Pq5zSs715m145w9wRr3QcueBHa9neWWCzwNLgX5tiLf/kuqnmZtorIX/XdrqW2G6Z2u1TVqItE8AzQFzsNBNjG4+XGmPvqLMoaaiyJwC27oISdBwt4d95WcgpLWbr9EDsP2YFFfdql8MCongxo34z4mBp0cTxaNV2kxZ+8TNsYmtoNujmziG+fby98LXraHkAdh8LQu2Dey54668vfh/8975kr6ZrPICYZ3vQzE/mD+2zJxbuLqltqN7uClbvkccGLtgS0eaZNXD8/Z3tgDbjaDmIC3zER715s584B6DPG9qrqdDqMfNIzlfVVn9jvVpxvSwXrv7VVL6Of9Zzn4DZ7l+1vNC/Ahhl2PIHOiaOC5JgTgXOSS/FMBzHHGFPFqhaB09gSQXm/bNrP2Ncr9gp57MLjGdChGV1aJAU2KQTaso/gs3Fw53JbP52dYe+MB99sE1HuXjtRX1Ge7e7Zsrddi8AY+JtTXz7iKej1GzsnUodTbEPxoBvtyNXB4yHJ6bnjctleRmldPZ+d2gXSvf4W9qy0A/R6/aZirAc222mg+42t2aAzpUJYnSSCUNHYE0FxqYsHP1/JjcM68cH87bw3bxulLs//Uf/2Tfn01lP5ZuUejm/bxLfHUUNRWgxRNZj6ubydi+w4C+8RzUqpGjnqRCAiufhfkUMAY4xp4mdfQDX2RFCeMYYVO7OZv/kA/5qxnvxi34m+7hvRk/Gndz72xmWlVKOmJYJGorTMxV0fLeWr5bt9tjeJi2J4r1Z8tmQnvx/aiYd+2ztIESqlQpUmgkZmX14Ruw8VMntDFou2HeTHtb6jlXu2TuaiAe245YxquhIqpcJGVYkgkIvXqwBJS4olLSmWPum2a+ljX63m25V7uHRgO1bszOZAfglPfrOWGav3cuXJHbigX1uiIrV7oVLKPy0RNBLGGMTp/llS5uLOD5cwbYVndLG7K+qM1Zmc07slPVs3oXniUTTYKqUaJK0aCkPGGGZv2MeDn69k+wH/c/nPuufMhtnrSClVa5oIwtzcTfuYsiiDrNwitu3P90kMrZvEcdOwTgzo0JTjUhP9z3eklGrwNBGoI8pchi+X7WLN7hy+XLaL3MJScot857efevtQ+qY3reQMSqmGSBOBqtKFL/2PZTt85/Fp1SSWh397PMelJvDijxv56296065pLZdpVEqFDE0Eqkrr9uRy75RlnNurFWv25CAirN6Vw5Z9h32Oe/fGwQzr5mfBcaVUyNNEoGrt4OFiHpq6ii+X7fLZfnr3Ftx0WicGdWxGQoz2PlaqodBxBKrWmiXG8OQlfejdpgmd0hJ47Ks17DxUwOz1WcxenwXACe2aEBkRwYtjBxAbHUFsZCQpCTo5m1INTUBLBCIyAvg3EAm8YYypsKKIs/rZI9g5jZYZY66s6pxaIgiezVl5fL5kJy/8uNFne2JMJIeLy2iWEM2Sh84LUnRKqaoEpWpIRCKB9cC5QAawABhrjFntdUw34GPgbGPMQRFp6V4FrTKaCIJv7Z4crn5jPt1bJTN3036ffR2aJ9AkPopTu6TxwMieAEcGuimlgidYiWAI8Igx5nzn9QMAxpgnvI55GlhvjHmjpufVRBBaFm8/yB8+WsqJHZpRVObi63IT4gH89/qTOLNHCwpKyrRdQakgCVYbQTvAe3XvDODkcsd0BxCR/2Grjx4xxnxb/kQiMg4YB9Chg59VqlTQDOzQjJ/u9azLe8fZuTw+bQ09WiXx+pwtANzw1gKG92zJkh2H+PauYUSKsDeniN5t630Wc6WUH4EsEVwGjDDG3OS8vgY42Rhzu9cxXwElwBggHZgN9DHGVLo4rZYIGpZ7Ji9jyqIMv/teu+ZE2jaN54R2AVyXWSkFBK9EsBNo7/U63dnmLQOYb4wpAbaIyHqgG7Y9QTUCD4zsSVSEcNOwTuzNKeLvX69hze4cAMa9uwiAUzo35+lL+5HeLF4X2FEqCAJZIojCNhYPxyaABcCVxphVXseMwDYgXyciacASoL8xZr+/c4KWCBqDA4eLefHHjUz83xaf7c0SormgX1sGdGjGsG5ppOq8R0rVmaANKBORUcDz2Pr/icaYx0XkUWChMWaq2O4kzwIjgDLgcWPMh1WdUxNB42CMYeXOHFLio/l86U42ZOaxdMdBdhwo8DnunF4tuXN49yNrLyiljo6OLFYNxgfzt7Nt/2Fenb3ZZ/sZ3Vtw3vGtGNolTafOVuooaCJQDU7GwXxOe2omAJERQpnL83vap10KL181kOyCErq1SiI2KjJYYSrVYGgiUA2Sy2UoLLVjD2as3stjX6+mWUIMS71mSj2zRwvevO4k9h8uomVyXBCjVSq0aSJQjcq1E389Mt+Rt0V/PQcR0SU4lfJDE4FqVIwxHMovYfaGLCb8tPlId1S3168dxM3vLKRfegof3HwKibE6mlkpTQSqUdt5qIAP5m/j9TlbKC51+exrEhfF57cNpXOLpCBFp1Ro0ESgwkJhSRmvz97M+/O3syen8Mj2+OhIBnRoyiUD0xnVpzXx0ZEYgw5eU2FFE4EKO/vyisgvKuPDBdt5edamCvu7tEjkw3FDmL0+i1O7ptImRZfhVI2bJgIVtopLXUz6dTv92jfl2jfnk1NY6ve4+0b05PpTOxIfo11RVeOkiUApR0FxGUWlZcxYk8mLP25g6/78I/s6pSVyUsdm3HZWV45L1UFrqnHRRKCUH8YYCktcbD+Qzx8+Wspqp/dR04RoxgxqT0FxGaP7tuHkTs11cR3V4GkiUKoaW/Yd5oulOzmpY3P+8tkKn5ICwJ3Du3HLGV206kg1WJoIlKoFYwzr9uby8YKMCjOkAvx1dC8u7N+OCEFnSFUNhiYCpY7BI1NX8cmiDHKLKjY0D+2aypOX9KV984QgRKZUzWkiUOoYFZe6+HljFlEREbw3bxvTV+/12T/nT2dpMlAhTROBUnXI5TJ8umQn5/Rqyc3vLGTB1oMADOuWxvWndmRz1mHGDGpPclyUDlpTIUMTgVIBdM/kZUxbsZv84jKf7b8f2ok/nNuNpNgo7XWkgk4TgVIB5F4r4Y05m5m2cg+3ndnlyHrMbg//tjebsvK457weNE3Q2VFV/dNEoFQ9W7kzmzsmLWHzvsMV9t1yRhf+eF53oiMjghCZCleaCJQKkpIyF7PWZfHOL1vZsu8wGQftmswJMZHcNKwzxzVPYHTfNsRF6/gEFViaCJQKAat35TDqhTkM79mSH9Zm+uy7oF9b7hjelS4tkrQ9QQWEJgKlQoTLZYiIEDJzClm/N48t+/J48ItVR/ZHRwr/urw/Azs0IzYqQgesqTqjiUCpELbzUAGXvTKX3dmFFfbNvOdMOqXpBHjq2GkiUCrEZReUsDkrj2e+W4cI/G/j/iP7Tu2SyqldUikuM9x+VldiorSRWdWeJgKlGpi1e3K4Y9ISOqYm+oxiTm8Wz/CeLRl/RhfaNtXFdFTNBS0RiMgI4N9AJPCGMebJSo67FJgCnGSMqfIqr4lAhZvnZ6ynsMRFTKTwwo8bffb9tl9b/n7RCaTERwcpOtVQBCURiEgksB44F8gAFgBjjTGryx2XDHwNxAC3ayJQqnKHi0p5dfZmXpq58chAtrSkGG4e1pnhvVrRtWUShSVlxERG6PQWykdViSCQlY2DgY3GmM3GmGLgQ+BCP8c9BjwFVGwpU0r5SIyN4u5zu7P2sRE8MLInAPvyinnim7WMeH42t763iJ4Pfssz09dRUuYKcrSqoQhkImgH7PB6neFsO0JEBgLtjTFfV3UiERknIgtFZGFWVlbdR6pUAxMdGcH4M7qw9cnRjB3cgdvO6kJCTCTfrNwDwCuzNtHtL98wc23mkZKDUpWJCtYHi0gE8BxwfXXHGmNeA14DWzUU2MiUalieuKQPABf2b8f6vbk8MW0tOw/ZEcw3vLWA+OhIHrvoBC4d2E4Hqym/AtlGMAR4xBhzvvP6AQBjzBPO6xRgE5DnvKU1cAC4oKp2Am0jUKpqxhiKSl1M+GkTv2zaz/wtB47sO75tEy4e0I7zeremQ6qunxBOgtVYHIVtLB4O7MQ2Fl9pjFlVyfGzgHu0sVipujV30z4+WrCDL5bu8tl+apdUTu6UyoX929JRB601esHsPjoKeB7bfXSiMeZxEXkUWGiMmVru2FloIlAqIIwxbMrKIyYyktOfmVlh/6MXHs+I41vTsklcEKJT9UEHlCmljihzGXYdKqDUZXh+xnqfksJZPVpw/vGtuezEdCIjRNsUGhFNBEopv4wxvDV3Kx8t2EGpy7AxM+/IvhuGduTh3x4fxOhUXdJEoJSqkR0H8vnzZytYvzeXvTlFtE2JIykuir+M7k1xqYvCkjLO7d1K109ogDQRKKVqpcxleOGHDbw8ayMlZb7XiJ6tk/nmzmFabdTAaCJQSh2VguIycgpL+GFNJtNW7ObnjfsAaJMSR7dWyTx1aR/apOjkdw2BJgKlVJ0oLnXR55HvKCr1TF/Rukkcp3ZN5dohHdmYmcdlJ6YHMUJVmaoSQdBGFiulGp6YqAi+uH0oa3fnkhwXxRPfrGVjZh6fLt7Jp4t3ArB0x0HGn96FpgnRJMfprKgNgZYIlFLHZH9eEZN+3c4PazPZdaiAvTlFAHRpkcjTl/Vl/pYD3HBqJ+JjtIE5mLRqSClVb574Zg2v/rTZZ1tiTCSXn9SBu8/rjgDb9ufTu22T4AQYpjQRKKXqVXGpi9fnbObr5btZvTvH7zEfjTuF9s0TdKW1eqKJQCkVNG/P3crDU1eRlhTDvrziCvvbNY3nnRsH0zYlnrV7chjQoVkQomz8NBEopYLGGMPh4jJioyLYk11ISZmLn9Zn8bcvV/s9fsotQxjQoRmRusJandJEoJQKSVOX7WLt7hyaJ8bw49pM5m7aD0DXlklMHj+EyEghKSZKl92sA5oIlFINwulPz2T7gfwK25+4pA8XD2inU1scA00ESqkGYc3uHGavzyI+JpJnp68nJT7aJzEM6NCU0X3aMOak9jTRMQq1oolAKdUgZeYUMvgfP/jd9/RlfYmNiuDsni114FoNaCJQSjVY2fklvDhzA7ef3Y03f97Cku0HmbNh35H9sVERXHZiOsszsnn+iv50aZEUxGhDlyYCpVSjMnnhDu6dsrzC9rSkGJ4b05+ebZIBaJmsK665aSJQSjVa36/ey69b9vP6nC0+22OjIrj9rK5k5haxLOMQk28ZQmxU+DY2ayJQSjV6e3MK+XblHlbszGbLvsMs2nawwjHjz+jMDad2onVK+JUUNBEopcKOy2UY+/o8lmUcorDE5bPv2iHH0TI5lo2Zedx1Tnc6piUGKcr6o4lAKRW2jDHMXJfJhr15PPv9eopLXRWOuWRAO566rC8A0ZER9R1ivdBEoJRSwOGiUpZsP8TkRTsA+GLpLp/97ZrG8/Udp7Ep6zAD2jclu6CEqEhpFN1TNREopZQfi7YdYFPmYf70ScUeSMO6pTFnwz5S4qOZe//ZREZIgx7ZHLREICIjgH8DkcAbxpgny+2/G7gJKAWygN8bY7ZVdU5NBEqpurZqVzbzNx/gnV+2snV/PkM6p/LL5v0Vjvvg5pM5tUta/QdYB4KSCEQkElgPnAtkAAuAscaY1V7HnAXMN8bki8itwJnGmMurOq8mAqVUoGTnl+AyhmaJMazIyObjhTt4d57vveklA9pxycB0TuvWsBJCsBLBEOARY8z5zusHAIwxT1Ry/ADgRWPM0KrOq4lAKVWfylyGXYcKePzrNfxv0z5yC0sBSEuKpczlokl8NO2axnP9qR057/jWQY62csFavL4dsMPrdQZwchXH3wh8E8B4lFKq1iIjhPbNE5hwzYkYY/h25R4+WbyTGWv20r1VEqUuw4KtB5i7aT9/GtGDqUt3cXzbFB6/+IQG06YQyERQYyJyNTAIOKOS/eOAcQAdOnSox8iUUspDRBjZpw0j+7ShuNRFTJTtajp/834uf20eT3+7DoC1e3JZvP0gL1wxgG6tkli1K5serZuQFBsSl9wKgl41JCLnAP8BzjDGZFZ3Xq0aUkqForV7cnjm23X8sNb/ZaxtShx//U1vhnVLY/3ePE48rn6X5AxWG0EUtrF4OLAT21h8pTFmldcxA4ApwAhjzIaanFcTgVIqlGXlFtE8MYYHv1hJcamLuOgIfliTye7sQp/jzurRgicu6Vtv010Es/voKOB5bPfRicaYx0XkUWChMWaqiMwA+gC7nbdsN8ZcUNU5NREopRqa0jIX787bxmNfrcZV7pJ7apdUmsRF84dzu9MyOZb4mEiiIoSoOh7hrAPKlFIqBGQXlBAbFcHSHYd4aeZGABZsPVBhLqSoCGHmPWfSvnlCnX22JgKllApRJWUu3p67lVdmbWL/4WKfff3SU+jfvilFpS5yCku4+9wedG15dAvvBKv7qFJKqWpER0Zw07DO3DSsMx8v2MGE2ZsY0jmVgpIyPl28k2UZ2UeOTW+WwJ9H9arzGLREoJRSISqvqJTSMhf78or4bMlO/u/sbkc9NkFLBEop1QC5xx00TYjh3vN7BuxzGufE20oppWpME4FSSoU5TQRKKRXmNBEopVSY00SglFJhThOBUkqFOU0ESikV5jQRKKVUmGtwI4tFJAuocoH7KqQB++ownEDTeAOnIcUKDSvehhQrNKx4jyXW44wxLfztaHCJ4FiIyMLKhliHIo03cBpSrNCw4m1IsULDijdQsWrVkFJKhTlNBEopFebCLRG8FuwAaknjDZyGFCs0rHgbUqzQsOINSKxh1UaglFKqonArESillCpHE4FSSoW5sEkEIjJCRNaJyEYRuT/Y8QCIyEQRyRSRlV7bmovI9yKywXls5mwXEXnBiX+5iAys51jbi8hMEVktIqtE5M5QjVdE4kTkVxFZ5sT6N2d7JxGZ78T0kYjEONtjndcbnf0d6yvWcnFHisgSEfkq1OMVka0iskJElorIQmdbyP0uOJ/fVESmiMhaEVkjIkNCONYezs/U/S9HRO4KeLzGmEb/D4gENgGdgRhgGdA7BOI6HRgIrPTa9jRwv/P8fuAp5/ko4BtAgFOA+fUcaxtgoPM8GVgP9A7FeJ3PTHKeRwPznRg+Bq5wtk8AbnWe/z9ggvP8CuCjIP0+3A18AHzlvA7ZeIGtQFq5bSH3u+B8/tvATc7zGKBpqMZaLu5IYA9wXKDjDcoXDMIPdAjwndfrB4AHgh2XE0vHcolgHdDGed4GWOc8fxUY6++4IMX9BXBuqMcLJACLgZOxIzKjyv9OAN8BQ5znUc5xUs9xpgM/AGcDXzl/2KEcr79EEHK/C0AKsKX8zycUY/UT+3nA/+oj3nCpGmoH7PB6neFsC0WtjDG7ned7gFbO85D5Dk5VxADsnXZIxutUsywFMoHvsSXCQ8aYUj/xHInV2Z8NpNZXrI7ngT8BLud1KqEdrwGmi8giERnnbAvF34VOQBbwX6fa7Q0RSQzRWMu7ApjkPA9ovOGSCBokY1N8SPXvFZEk4BPgLmNMjve+UIrXGFNmjOmPvdMeDARu5e9jJCK/ATKNMYuCHUstnGaMGQiMBG4TkdO9d4bQ70IUtvr1FWPMAOAwtmrliBCK9QinPegCYHL5fYGIN1wSwU6gvdfrdGdbKNorIm0AnMdMZ3vQv4OIRGOTwPvGmE+dzSEbL4Ax5hAwE1u10lREovzEcyRWZ38KsL8ewxwKXCAiW4EPsdVD/w7heDHG7HQeM4HPsMk2FH8XMoAMY8x85/UUbGIIxVi9jQQWG2P2Oq8DGm+4JIIFQDenF0YMtsg1NcgxVWYqcJ3z/DpsXbx7+7VOL4FTgGyvomLAiYgAbwJrjDHPhXK8ItJCRJo6z+OxbRlrsAnhskpidX+Hy4AfnbuuemGMecAYk26M6Yj93fzRGHNVqMYrIokikux+jq3LXkkI/i4YY/YAO0Skh7NpOLA6FGMtZyyeaiF3XIGLNxiNIEFqeBmF7emyCfhLsONxYpoE7AZKsHcuN2Lren8ANgAzgObOsQK85MS/AhhUz7Gehi2OLgeWOv9GhWK8QF9giRPrSuAhZ3tn4FdgI7bIHetsj3Neb3T2dw7i78SZeHoNhWS8TlzLnH+r3H9Pofi74Hx+f2Ch8/vwOdAsVGN1YkjElvBSvLYFNF6dYkIppcJcuFQNKaWUqoQmAqWUCnOaCJRSKsxpIlBKqTCniUAppcKcJgKl6pGInCnO7KJKhQpNBEopFeY0ESjlh4hcLXZNg6Ui8qoziV2eiPxL7BoHP4hIC+fY/iIyz5kP/jOvueK7isgMsesiLBaRLs7pk7zmx3/fGbWtVNBoIlCqHBHpBVwODDV24roy4CrsiM+FxpjjgZ+Ah523vAPcZ4zpix3d6d7+PvCSMaYfcCp2FDnYmVvvwq7n0Bk715BSQRNV/SFKhrH68QAAARRJREFUhZ3hwInAAudmPR47yZcL+Mg55j3gUxFJAZoaY35ytr8NTHbm4mlnjPkMwBhTCOCc71djTIbzeil2TYqfA/+1lPJPE4FSFQnwtjHmAZ+NIg+WO+5o52cp8npehv4dqiDTqiGlKvoBuExEWsKRtXiPw/69uGcDvRL42RiTDRwUkWHO9muAn4wxuUCGiFzknCNWRBLq9VsoVUN6J6JUOcaY1SLyV+wKXBHY2WFvwy5qMtjZl4ltRwA7LfAE50K/GbjB2X4N8KqIPOqc43f1+DWUqjGdfVSpGhKRPGNMUrDjUKquadWQUkqFOS0RKKVUmNMSgVJKhTlNBEopFeY0ESilVJjTRKCUUmFOE4FSSoW5/w/sbUfnuMMgiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "kiiwcwMTErGO",
    "outputId": "f06d47f1-ba31-4d46-a58f-608dcad04c0d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4fa2201afb77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "EmoDetect.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
