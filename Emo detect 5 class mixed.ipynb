{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir('Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1880 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0        calm\n",
       "1        calm\n",
       "2        calm\n",
       "3        calm\n",
       "4        calm\n",
       "...       ...\n",
       "1875  fearful\n",
       "1876  fearful\n",
       "1877  fearful\n",
       "1878  fearful\n",
       "1879  fearful\n",
       "\n",
       "[1880 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame(feeling_list)\n",
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('Data/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1      \n",
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488, 216)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 17285     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 346,885\n",
      "Trainable params: 346,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.7264 - accuracy: 0.2171 - val_loss: 1.5797 - val_accuracy: 0.2449\n",
      "Epoch 2/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.5781 - accuracy: 0.2594 - val_loss: 1.5675 - val_accuracy: 0.2628\n",
      "Epoch 3/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.5593 - accuracy: 0.2742 - val_loss: 1.5338 - val_accuracy: 0.3112\n",
      "Epoch 4/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.5462 - accuracy: 0.3051 - val_loss: 1.5404 - val_accuracy: 0.3138\n",
      "Epoch 5/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.5368 - accuracy: 0.3226 - val_loss: 1.5218 - val_accuracy: 0.3214\n",
      "Epoch 6/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.5252 - accuracy: 0.3165 - val_loss: 1.5174 - val_accuracy: 0.3342\n",
      "Epoch 7/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.5145 - accuracy: 0.3394 - val_loss: 1.4984 - val_accuracy: 0.3571\n",
      "Epoch 8/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.5017 - accuracy: 0.3448 - val_loss: 1.4855 - val_accuracy: 0.3878\n",
      "Epoch 9/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.4906 - accuracy: 0.3649 - val_loss: 1.4828 - val_accuracy: 0.4005\n",
      "Epoch 10/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.4782 - accuracy: 0.3730 - val_loss: 1.4857 - val_accuracy: 0.3776\n",
      "Epoch 11/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.4737 - accuracy: 0.3763 - val_loss: 1.4667 - val_accuracy: 0.4133\n",
      "Epoch 12/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.4600 - accuracy: 0.3952 - val_loss: 1.4778 - val_accuracy: 0.3878\n",
      "Epoch 13/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.4496 - accuracy: 0.3770 - val_loss: 1.4878 - val_accuracy: 0.3342\n",
      "Epoch 14/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.4418 - accuracy: 0.3804 - val_loss: 1.4361 - val_accuracy: 0.4337\n",
      "Epoch 15/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.4304 - accuracy: 0.3958 - val_loss: 1.4532 - val_accuracy: 0.3673\n",
      "Epoch 16/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.4217 - accuracy: 0.4086 - val_loss: 1.4139 - val_accuracy: 0.4184\n",
      "Epoch 17/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.4122 - accuracy: 0.4241 - val_loss: 1.4160 - val_accuracy: 0.4184\n",
      "Epoch 18/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.4029 - accuracy: 0.4019 - val_loss: 1.3966 - val_accuracy: 0.4413\n",
      "Epoch 19/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3914 - accuracy: 0.4281 - val_loss: 1.4329 - val_accuracy: 0.3954\n",
      "Epoch 20/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3792 - accuracy: 0.4187 - val_loss: 1.3900 - val_accuracy: 0.4439\n",
      "Epoch 21/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.3745 - accuracy: 0.4301 - val_loss: 1.4031 - val_accuracy: 0.4235\n",
      "Epoch 22/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.3675 - accuracy: 0.4194 - val_loss: 1.3670 - val_accuracy: 0.4617\n",
      "Epoch 23/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.3526 - accuracy: 0.4301 - val_loss: 1.3800 - val_accuracy: 0.4311\n",
      "Epoch 24/700\n",
      "93/93 [==============================] - 2s 23ms/step - loss: 1.3421 - accuracy: 0.4449 - val_loss: 1.3774 - val_accuracy: 0.4286\n",
      "Epoch 25/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3335 - accuracy: 0.4483 - val_loss: 1.3698 - val_accuracy: 0.4337\n",
      "Epoch 26/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3282 - accuracy: 0.4456 - val_loss: 1.3420 - val_accuracy: 0.4617\n",
      "Epoch 27/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3180 - accuracy: 0.4523 - val_loss: 1.3655 - val_accuracy: 0.4260\n",
      "Epoch 28/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.3112 - accuracy: 0.4483 - val_loss: 1.3201 - val_accuracy: 0.4847\n",
      "Epoch 29/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.3038 - accuracy: 0.4644 - val_loss: 1.3194 - val_accuracy: 0.4745\n",
      "Epoch 30/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2993 - accuracy: 0.4509 - val_loss: 1.3016 - val_accuracy: 0.4770\n",
      "Epoch 31/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2884 - accuracy: 0.4644 - val_loss: 1.3308 - val_accuracy: 0.4413\n",
      "Epoch 32/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2872 - accuracy: 0.4637 - val_loss: 1.3215 - val_accuracy: 0.4592\n",
      "Epoch 33/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2826 - accuracy: 0.4577 - val_loss: 1.3009 - val_accuracy: 0.4770\n",
      "Epoch 34/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2710 - accuracy: 0.4550 - val_loss: 1.3058 - val_accuracy: 0.4821\n",
      "Epoch 35/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2716 - accuracy: 0.4617 - val_loss: 1.2897 - val_accuracy: 0.4719\n",
      "Epoch 36/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2674 - accuracy: 0.4664 - val_loss: 1.2861 - val_accuracy: 0.4923\n",
      "Epoch 37/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2626 - accuracy: 0.4751 - val_loss: 1.2856 - val_accuracy: 0.4745\n",
      "Epoch 38/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2642 - accuracy: 0.4751 - val_loss: 1.2949 - val_accuracy: 0.4566\n",
      "Epoch 39/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2546 - accuracy: 0.4731 - val_loss: 1.2835 - val_accuracy: 0.4821\n",
      "Epoch 40/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2515 - accuracy: 0.4906 - val_loss: 1.3088 - val_accuracy: 0.4464\n",
      "Epoch 41/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2433 - accuracy: 0.4792 - val_loss: 1.3164 - val_accuracy: 0.4388\n",
      "Epoch 42/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2409 - accuracy: 0.4704 - val_loss: 1.2842 - val_accuracy: 0.4668\n",
      "Epoch 43/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2403 - accuracy: 0.4866 - val_loss: 1.2952 - val_accuracy: 0.4592\n",
      "Epoch 44/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2402 - accuracy: 0.4651 - val_loss: 1.2876 - val_accuracy: 0.4592\n",
      "Epoch 45/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2308 - accuracy: 0.4879 - val_loss: 1.2923 - val_accuracy: 0.4643\n",
      "Epoch 46/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2333 - accuracy: 0.4819 - val_loss: 1.2579 - val_accuracy: 0.4872\n",
      "Epoch 47/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2324 - accuracy: 0.4973 - val_loss: 1.2792 - val_accuracy: 0.4592\n",
      "Epoch 48/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2240 - accuracy: 0.4913 - val_loss: 1.2681 - val_accuracy: 0.4847\n",
      "Epoch 49/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2273 - accuracy: 0.4751 - val_loss: 1.2708 - val_accuracy: 0.4796\n",
      "Epoch 50/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2243 - accuracy: 0.4805 - val_loss: 1.2535 - val_accuracy: 0.4974\n",
      "Epoch 51/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2160 - accuracy: 0.4953 - val_loss: 1.3030 - val_accuracy: 0.4439\n",
      "Epoch 52/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2219 - accuracy: 0.4872 - val_loss: 1.2467 - val_accuracy: 0.5000\n",
      "Epoch 53/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2142 - accuracy: 0.4892 - val_loss: 1.2704 - val_accuracy: 0.4490\n",
      "Epoch 54/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2139 - accuracy: 0.4987 - val_loss: 1.2663 - val_accuracy: 0.4745\n",
      "Epoch 55/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.2071 - accuracy: 0.5027 - val_loss: 1.2874 - val_accuracy: 0.4668\n",
      "Epoch 56/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2130 - accuracy: 0.4946 - val_loss: 1.2453 - val_accuracy: 0.4694\n",
      "Epoch 57/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.2010 - accuracy: 0.5000 - val_loss: 1.2632 - val_accuracy: 0.4745\n",
      "Epoch 58/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2013 - accuracy: 0.4987 - val_loss: 1.2755 - val_accuracy: 0.4643\n",
      "Epoch 59/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1967 - accuracy: 0.5101 - val_loss: 1.2730 - val_accuracy: 0.4617\n",
      "Epoch 60/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.2023 - accuracy: 0.5000 - val_loss: 1.2547 - val_accuracy: 0.4847\n",
      "Epoch 61/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.2021 - accuracy: 0.4966 - val_loss: 1.2367 - val_accuracy: 0.5026\n",
      "Epoch 62/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1907 - accuracy: 0.5067 - val_loss: 1.2656 - val_accuracy: 0.4668\n",
      "Epoch 63/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1934 - accuracy: 0.5134 - val_loss: 1.2445 - val_accuracy: 0.4745\n",
      "Epoch 64/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1926 - accuracy: 0.5020 - val_loss: 1.2381 - val_accuracy: 0.4949\n",
      "Epoch 65/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1830 - accuracy: 0.5222 - val_loss: 1.2744 - val_accuracy: 0.4566\n",
      "Epoch 66/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1830 - accuracy: 0.5094 - val_loss: 1.2568 - val_accuracy: 0.4668\n",
      "Epoch 67/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1887 - accuracy: 0.5054 - val_loss: 1.2483 - val_accuracy: 0.4796\n",
      "Epoch 68/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 1.1824 - accuracy: 0.5101 - val_loss: 1.2375 - val_accuracy: 0.4821\n",
      "Epoch 69/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1819 - accuracy: 0.5087 - val_loss: 1.2721 - val_accuracy: 0.4668\n",
      "Epoch 70/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1741 - accuracy: 0.5215 - val_loss: 1.2344 - val_accuracy: 0.5102\n",
      "Epoch 71/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 1.1759 - accuracy: 0.5161 - val_loss: 1.2554 - val_accuracy: 0.4847\n",
      "Epoch 72/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1695 - accuracy: 0.5235 - val_loss: 1.2922 - val_accuracy: 0.4490\n",
      "Epoch 73/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1753 - accuracy: 0.5195 - val_loss: 1.2502 - val_accuracy: 0.4923\n",
      "Epoch 74/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1660 - accuracy: 0.5060 - val_loss: 1.2545 - val_accuracy: 0.4770\n",
      "Epoch 75/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1687 - accuracy: 0.5255 - val_loss: 1.2376 - val_accuracy: 0.4974\n",
      "Epoch 76/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1633 - accuracy: 0.5202 - val_loss: 1.2469 - val_accuracy: 0.4923\n",
      "Epoch 77/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1641 - accuracy: 0.5202 - val_loss: 1.2768 - val_accuracy: 0.4694\n",
      "Epoch 78/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1615 - accuracy: 0.5309 - val_loss: 1.3083 - val_accuracy: 0.4337\n",
      "Epoch 79/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1619 - accuracy: 0.5181 - val_loss: 1.2263 - val_accuracy: 0.4923\n",
      "Epoch 80/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1604 - accuracy: 0.5128 - val_loss: 1.2352 - val_accuracy: 0.4898\n",
      "Epoch 81/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1565 - accuracy: 0.5276 - val_loss: 1.2310 - val_accuracy: 0.4923\n",
      "Epoch 82/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1596 - accuracy: 0.5202 - val_loss: 1.2453 - val_accuracy: 0.4872\n",
      "Epoch 83/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1534 - accuracy: 0.5323 - val_loss: 1.2481 - val_accuracy: 0.4719\n",
      "Epoch 84/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1521 - accuracy: 0.5302 - val_loss: 1.2346 - val_accuracy: 0.4872\n",
      "Epoch 85/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1477 - accuracy: 0.5336 - val_loss: 1.2207 - val_accuracy: 0.5102\n",
      "Epoch 86/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1484 - accuracy: 0.5222 - val_loss: 1.2432 - val_accuracy: 0.4898\n",
      "Epoch 87/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1462 - accuracy: 0.5336 - val_loss: 1.2713 - val_accuracy: 0.4643\n",
      "Epoch 88/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1477 - accuracy: 0.5417 - val_loss: 1.2797 - val_accuracy: 0.4643\n",
      "Epoch 89/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1386 - accuracy: 0.5282 - val_loss: 1.2294 - val_accuracy: 0.4974\n",
      "Epoch 90/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1385 - accuracy: 0.5430 - val_loss: 1.2294 - val_accuracy: 0.4974\n",
      "Epoch 91/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1394 - accuracy: 0.5255 - val_loss: 1.2295 - val_accuracy: 0.4821\n",
      "Epoch 92/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1399 - accuracy: 0.5403 - val_loss: 1.2386 - val_accuracy: 0.4872\n",
      "Epoch 93/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1386 - accuracy: 0.5309 - val_loss: 1.2405 - val_accuracy: 0.4872\n",
      "Epoch 94/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1333 - accuracy: 0.5329 - val_loss: 1.2688 - val_accuracy: 0.4770\n",
      "Epoch 95/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1314 - accuracy: 0.5450 - val_loss: 1.2464 - val_accuracy: 0.4770\n",
      "Epoch 96/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1294 - accuracy: 0.5444 - val_loss: 1.2206 - val_accuracy: 0.5077\n",
      "Epoch 97/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1314 - accuracy: 0.5383 - val_loss: 1.2349 - val_accuracy: 0.4898\n",
      "Epoch 98/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1250 - accuracy: 0.5370 - val_loss: 1.2311 - val_accuracy: 0.4923\n",
      "Epoch 99/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1297 - accuracy: 0.5464 - val_loss: 1.2405 - val_accuracy: 0.4847\n",
      "Epoch 100/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1278 - accuracy: 0.5309 - val_loss: 1.2324 - val_accuracy: 0.4770\n",
      "Epoch 101/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1185 - accuracy: 0.5410 - val_loss: 1.2157 - val_accuracy: 0.5077\n",
      "Epoch 102/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1241 - accuracy: 0.5524 - val_loss: 1.2300 - val_accuracy: 0.4898\n",
      "Epoch 103/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1222 - accuracy: 0.5316 - val_loss: 1.2172 - val_accuracy: 0.4949\n",
      "Epoch 104/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1200 - accuracy: 0.5336 - val_loss: 1.2286 - val_accuracy: 0.5102\n",
      "Epoch 105/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1199 - accuracy: 0.5390 - val_loss: 1.2340 - val_accuracy: 0.4949\n",
      "Epoch 106/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1170 - accuracy: 0.5470 - val_loss: 1.2171 - val_accuracy: 0.5077\n",
      "Epoch 107/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1150 - accuracy: 0.5484 - val_loss: 1.2235 - val_accuracy: 0.5128\n",
      "Epoch 108/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1181 - accuracy: 0.5390 - val_loss: 1.2355 - val_accuracy: 0.4770\n",
      "Epoch 109/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1130 - accuracy: 0.5484 - val_loss: 1.2182 - val_accuracy: 0.4949\n",
      "Epoch 110/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1104 - accuracy: 0.5524 - val_loss: 1.2466 - val_accuracy: 0.4872\n",
      "Epoch 111/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1063 - accuracy: 0.5544 - val_loss: 1.2320 - val_accuracy: 0.4847\n",
      "Epoch 112/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.1103 - accuracy: 0.5457 - val_loss: 1.2259 - val_accuracy: 0.5077\n",
      "Epoch 113/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1060 - accuracy: 0.5484 - val_loss: 1.2333 - val_accuracy: 0.4872\n",
      "Epoch 114/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.1033 - accuracy: 0.5558 - val_loss: 1.2213 - val_accuracy: 0.5000\n",
      "Epoch 115/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0972 - accuracy: 0.5571 - val_loss: 1.2196 - val_accuracy: 0.5128\n",
      "Epoch 116/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0982 - accuracy: 0.5551 - val_loss: 1.2175 - val_accuracy: 0.5102\n",
      "Epoch 117/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.1024 - accuracy: 0.5511 - val_loss: 1.2114 - val_accuracy: 0.4923\n",
      "Epoch 118/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0987 - accuracy: 0.5544 - val_loss: 1.2251 - val_accuracy: 0.4898\n",
      "Epoch 119/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0977 - accuracy: 0.5551 - val_loss: 1.2252 - val_accuracy: 0.4923\n",
      "Epoch 120/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0903 - accuracy: 0.5571 - val_loss: 1.2519 - val_accuracy: 0.4770\n",
      "Epoch 121/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0964 - accuracy: 0.5504 - val_loss: 1.2230 - val_accuracy: 0.4974\n",
      "Epoch 122/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0844 - accuracy: 0.5692 - val_loss: 1.2807 - val_accuracy: 0.4337\n",
      "Epoch 123/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0927 - accuracy: 0.5470 - val_loss: 1.2173 - val_accuracy: 0.5000\n",
      "Epoch 124/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0853 - accuracy: 0.5605 - val_loss: 1.2289 - val_accuracy: 0.4745\n",
      "Epoch 125/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0871 - accuracy: 0.5605 - val_loss: 1.2496 - val_accuracy: 0.4694\n",
      "Epoch 126/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.0889 - accuracy: 0.5726 - val_loss: 1.2344 - val_accuracy: 0.4719\n",
      "Epoch 127/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0846 - accuracy: 0.5652 - val_loss: 1.2164 - val_accuracy: 0.4974\n",
      "Epoch 128/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0819 - accuracy: 0.5551 - val_loss: 1.2122 - val_accuracy: 0.5051\n",
      "Epoch 129/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0801 - accuracy: 0.5652 - val_loss: 1.2133 - val_accuracy: 0.4923\n",
      "Epoch 130/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0800 - accuracy: 0.5699 - val_loss: 1.2120 - val_accuracy: 0.5000\n",
      "Epoch 131/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0741 - accuracy: 0.5598 - val_loss: 1.2323 - val_accuracy: 0.5128\n",
      "Epoch 132/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0733 - accuracy: 0.5773 - val_loss: 1.2296 - val_accuracy: 0.4821\n",
      "Epoch 133/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0748 - accuracy: 0.5733 - val_loss: 1.2266 - val_accuracy: 0.4898\n",
      "Epoch 134/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 1.0693 - accuracy: 0.5726 - val_loss: 1.2152 - val_accuracy: 0.4847\n",
      "Epoch 135/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.0654 - accuracy: 0.5726 - val_loss: 1.2109 - val_accuracy: 0.5000\n",
      "Epoch 136/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0713 - accuracy: 0.5618 - val_loss: 1.2078 - val_accuracy: 0.5051\n",
      "Epoch 137/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0715 - accuracy: 0.5625 - val_loss: 1.2546 - val_accuracy: 0.4745\n",
      "Epoch 138/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0669 - accuracy: 0.5578 - val_loss: 1.2293 - val_accuracy: 0.4898\n",
      "Epoch 139/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.0663 - accuracy: 0.5699 - val_loss: 1.2398 - val_accuracy: 0.4847\n",
      "Epoch 140/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.0652 - accuracy: 0.5786 - val_loss: 1.2555 - val_accuracy: 0.4770\n",
      "Epoch 141/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 1.0657 - accuracy: 0.5773 - val_loss: 1.2249 - val_accuracy: 0.5000\n",
      "Epoch 142/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0615 - accuracy: 0.5766 - val_loss: 1.2581 - val_accuracy: 0.4617\n",
      "Epoch 143/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 1.0625 - accuracy: 0.5739 - val_loss: 1.2356 - val_accuracy: 0.4796\n",
      "Epoch 144/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0548 - accuracy: 0.5746 - val_loss: 1.2315 - val_accuracy: 0.4694\n",
      "Epoch 145/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0598 - accuracy: 0.5652 - val_loss: 1.2096 - val_accuracy: 0.5000\n",
      "Epoch 146/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0564 - accuracy: 0.5645 - val_loss: 1.2606 - val_accuracy: 0.4643\n",
      "Epoch 147/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0562 - accuracy: 0.5927 - val_loss: 1.2540 - val_accuracy: 0.4872\n",
      "Epoch 148/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0586 - accuracy: 0.5726 - val_loss: 1.2312 - val_accuracy: 0.4898\n",
      "Epoch 149/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0523 - accuracy: 0.5860 - val_loss: 1.2134 - val_accuracy: 0.4974\n",
      "Epoch 150/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0510 - accuracy: 0.5766 - val_loss: 1.2061 - val_accuracy: 0.5051\n",
      "Epoch 151/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0505 - accuracy: 0.5753 - val_loss: 1.2114 - val_accuracy: 0.5026\n",
      "Epoch 152/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0497 - accuracy: 0.5706 - val_loss: 1.2298 - val_accuracy: 0.4770\n",
      "Epoch 153/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0465 - accuracy: 0.5719 - val_loss: 1.2465 - val_accuracy: 0.4796\n",
      "Epoch 154/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0485 - accuracy: 0.5780 - val_loss: 1.2130 - val_accuracy: 0.4949\n",
      "Epoch 155/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0468 - accuracy: 0.5766 - val_loss: 1.2057 - val_accuracy: 0.4923\n",
      "Epoch 156/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0413 - accuracy: 0.5867 - val_loss: 1.2394 - val_accuracy: 0.4974\n",
      "Epoch 157/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0459 - accuracy: 0.5766 - val_loss: 1.2356 - val_accuracy: 0.4796\n",
      "Epoch 158/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0401 - accuracy: 0.5860 - val_loss: 1.2806 - val_accuracy: 0.4668\n",
      "Epoch 159/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0316 - accuracy: 0.5820 - val_loss: 1.2690 - val_accuracy: 0.4592\n",
      "Epoch 160/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0409 - accuracy: 0.5793 - val_loss: 1.2356 - val_accuracy: 0.4643\n",
      "Epoch 161/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0306 - accuracy: 0.5860 - val_loss: 1.2268 - val_accuracy: 0.4923\n",
      "Epoch 162/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0334 - accuracy: 0.5941 - val_loss: 1.1982 - val_accuracy: 0.5153\n",
      "Epoch 163/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0373 - accuracy: 0.5773 - val_loss: 1.2259 - val_accuracy: 0.5000\n",
      "Epoch 164/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0304 - accuracy: 0.5880 - val_loss: 1.2046 - val_accuracy: 0.5051\n",
      "Epoch 165/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 1.0257 - accuracy: 0.5901 - val_loss: 1.2478 - val_accuracy: 0.4770\n",
      "Epoch 166/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0250 - accuracy: 0.5901 - val_loss: 1.2870 - val_accuracy: 0.4362\n",
      "Epoch 167/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0275 - accuracy: 0.5874 - val_loss: 1.2338 - val_accuracy: 0.4872\n",
      "Epoch 168/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0203 - accuracy: 0.5853 - val_loss: 1.2346 - val_accuracy: 0.4770\n",
      "Epoch 169/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0269 - accuracy: 0.5874 - val_loss: 1.2263 - val_accuracy: 0.4847\n",
      "Epoch 170/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0210 - accuracy: 0.5853 - val_loss: 1.2138 - val_accuracy: 0.4821\n",
      "Epoch 171/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0244 - accuracy: 0.5921 - val_loss: 1.2176 - val_accuracy: 0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0211 - accuracy: 0.5995 - val_loss: 1.2322 - val_accuracy: 0.4872\n",
      "Epoch 173/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0175 - accuracy: 0.5853 - val_loss: 1.2082 - val_accuracy: 0.4923\n",
      "Epoch 174/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0157 - accuracy: 0.5988 - val_loss: 1.2374 - val_accuracy: 0.4796\n",
      "Epoch 175/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0182 - accuracy: 0.5988 - val_loss: 1.2152 - val_accuracy: 0.4974\n",
      "Epoch 176/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0144 - accuracy: 0.5934 - val_loss: 1.2153 - val_accuracy: 0.5026\n",
      "Epoch 177/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0092 - accuracy: 0.5948 - val_loss: 1.2169 - val_accuracy: 0.4949\n",
      "Epoch 178/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0076 - accuracy: 0.6069 - val_loss: 1.2064 - val_accuracy: 0.5102\n",
      "Epoch 179/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0083 - accuracy: 0.6015 - val_loss: 1.2082 - val_accuracy: 0.5000\n",
      "Epoch 180/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0072 - accuracy: 0.5860 - val_loss: 1.1960 - val_accuracy: 0.5153\n",
      "Epoch 181/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0076 - accuracy: 0.5948 - val_loss: 1.2027 - val_accuracy: 0.4923\n",
      "Epoch 182/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0054 - accuracy: 0.5961 - val_loss: 1.2086 - val_accuracy: 0.4898\n",
      "Epoch 183/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0036 - accuracy: 0.6042 - val_loss: 1.2096 - val_accuracy: 0.4974\n",
      "Epoch 184/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0010 - accuracy: 0.5988 - val_loss: 1.2130 - val_accuracy: 0.5051\n",
      "Epoch 185/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 1.0038 - accuracy: 0.6022 - val_loss: 1.2194 - val_accuracy: 0.4770\n",
      "Epoch 186/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9993 - accuracy: 0.6095 - val_loss: 1.1918 - val_accuracy: 0.5204\n",
      "Epoch 187/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9971 - accuracy: 0.6069 - val_loss: 1.2061 - val_accuracy: 0.5255\n",
      "Epoch 188/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9969 - accuracy: 0.5974 - val_loss: 1.2148 - val_accuracy: 0.4949\n",
      "Epoch 189/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9940 - accuracy: 0.6001 - val_loss: 1.2196 - val_accuracy: 0.4847\n",
      "Epoch 190/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9982 - accuracy: 0.6089 - val_loss: 1.2123 - val_accuracy: 0.5204\n",
      "Epoch 191/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9900 - accuracy: 0.6035 - val_loss: 1.2282 - val_accuracy: 0.4796\n",
      "Epoch 192/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9930 - accuracy: 0.6055 - val_loss: 1.1972 - val_accuracy: 0.5051\n",
      "Epoch 193/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9914 - accuracy: 0.6102 - val_loss: 1.2628 - val_accuracy: 0.4668\n",
      "Epoch 194/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9862 - accuracy: 0.6055 - val_loss: 1.2091 - val_accuracy: 0.4898\n",
      "Epoch 195/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9838 - accuracy: 0.6163 - val_loss: 1.2336 - val_accuracy: 0.5026\n",
      "Epoch 196/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9835 - accuracy: 0.6116 - val_loss: 1.2069 - val_accuracy: 0.5051\n",
      "Epoch 197/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9806 - accuracy: 0.6048 - val_loss: 1.2057 - val_accuracy: 0.5000\n",
      "Epoch 198/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9832 - accuracy: 0.6102 - val_loss: 1.2186 - val_accuracy: 0.5000\n",
      "Epoch 199/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9802 - accuracy: 0.6136 - val_loss: 1.2091 - val_accuracy: 0.5230\n",
      "Epoch 200/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9741 - accuracy: 0.6102 - val_loss: 1.2366 - val_accuracy: 0.4847\n",
      "Epoch 201/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9727 - accuracy: 0.6136 - val_loss: 1.2194 - val_accuracy: 0.4898\n",
      "Epoch 202/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9724 - accuracy: 0.6163 - val_loss: 1.2116 - val_accuracy: 0.4974\n",
      "Epoch 203/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9728 - accuracy: 0.6048 - val_loss: 1.2620 - val_accuracy: 0.4668\n",
      "Epoch 204/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9708 - accuracy: 0.6163 - val_loss: 1.2076 - val_accuracy: 0.5026\n",
      "Epoch 205/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9685 - accuracy: 0.6109 - val_loss: 1.1962 - val_accuracy: 0.5102\n",
      "Epoch 206/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9734 - accuracy: 0.6196 - val_loss: 1.1940 - val_accuracy: 0.5051\n",
      "Epoch 207/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9649 - accuracy: 0.6176 - val_loss: 1.1965 - val_accuracy: 0.5179\n",
      "Epoch 208/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9723 - accuracy: 0.6102 - val_loss: 1.2044 - val_accuracy: 0.5077\n",
      "Epoch 209/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9664 - accuracy: 0.6216 - val_loss: 1.2549 - val_accuracy: 0.4821\n",
      "Epoch 210/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9642 - accuracy: 0.6169 - val_loss: 1.2247 - val_accuracy: 0.4872\n",
      "Epoch 211/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9613 - accuracy: 0.6169 - val_loss: 1.2093 - val_accuracy: 0.5255\n",
      "Epoch 212/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9596 - accuracy: 0.6304 - val_loss: 1.1966 - val_accuracy: 0.5204\n",
      "Epoch 213/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9584 - accuracy: 0.6183 - val_loss: 1.2123 - val_accuracy: 0.5051\n",
      "Epoch 214/700\n",
      "93/93 [==============================] - 2s 24ms/step - loss: 0.9572 - accuracy: 0.6284 - val_loss: 1.2224 - val_accuracy: 0.5026\n",
      "Epoch 215/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9566 - accuracy: 0.6257 - val_loss: 1.2156 - val_accuracy: 0.5000\n",
      "Epoch 216/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9569 - accuracy: 0.6263 - val_loss: 1.1982 - val_accuracy: 0.5102\n",
      "Epoch 217/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9509 - accuracy: 0.6344 - val_loss: 1.2082 - val_accuracy: 0.5000\n",
      "Epoch 218/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9530 - accuracy: 0.6324 - val_loss: 1.2009 - val_accuracy: 0.5026\n",
      "Epoch 219/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9455 - accuracy: 0.6203 - val_loss: 1.2083 - val_accuracy: 0.5128\n",
      "Epoch 220/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9454 - accuracy: 0.6257 - val_loss: 1.2199 - val_accuracy: 0.5128\n",
      "Epoch 221/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9451 - accuracy: 0.6243 - val_loss: 1.2268 - val_accuracy: 0.4770\n",
      "Epoch 222/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9431 - accuracy: 0.6284 - val_loss: 1.2116 - val_accuracy: 0.4770\n",
      "Epoch 223/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9412 - accuracy: 0.6169 - val_loss: 1.2102 - val_accuracy: 0.4949\n",
      "Epoch 224/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9428 - accuracy: 0.6223 - val_loss: 1.2133 - val_accuracy: 0.4898\n",
      "Epoch 225/700\n",
      "93/93 [==============================] - 2s 25ms/step - loss: 0.9397 - accuracy: 0.6297 - val_loss: 1.1958 - val_accuracy: 0.4872\n",
      "Epoch 226/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9403 - accuracy: 0.6243 - val_loss: 1.1992 - val_accuracy: 0.4872\n",
      "Epoch 227/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9364 - accuracy: 0.6378 - val_loss: 1.1948 - val_accuracy: 0.5306\n",
      "Epoch 228/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9361 - accuracy: 0.6310 - val_loss: 1.1856 - val_accuracy: 0.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9328 - accuracy: 0.6371 - val_loss: 1.2579 - val_accuracy: 0.4668\n",
      "Epoch 230/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9387 - accuracy: 0.6142 - val_loss: 1.1936 - val_accuracy: 0.5026\n",
      "Epoch 231/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9340 - accuracy: 0.6331 - val_loss: 1.2047 - val_accuracy: 0.4898\n",
      "Epoch 232/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9293 - accuracy: 0.6284 - val_loss: 1.2227 - val_accuracy: 0.5000\n",
      "Epoch 233/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9311 - accuracy: 0.6196 - val_loss: 1.2006 - val_accuracy: 0.4872\n",
      "Epoch 234/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9338 - accuracy: 0.6384 - val_loss: 1.2226 - val_accuracy: 0.4821\n",
      "Epoch 235/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9259 - accuracy: 0.6317 - val_loss: 1.2015 - val_accuracy: 0.5000\n",
      "Epoch 236/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9222 - accuracy: 0.6458 - val_loss: 1.2051 - val_accuracy: 0.5306\n",
      "Epoch 237/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9225 - accuracy: 0.6418 - val_loss: 1.2326 - val_accuracy: 0.4821\n",
      "Epoch 238/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9228 - accuracy: 0.6499 - val_loss: 1.1984 - val_accuracy: 0.5153\n",
      "Epoch 239/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9259 - accuracy: 0.6277 - val_loss: 1.2126 - val_accuracy: 0.5026\n",
      "Epoch 240/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9225 - accuracy: 0.6351 - val_loss: 1.2318 - val_accuracy: 0.4949\n",
      "Epoch 241/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9186 - accuracy: 0.6364 - val_loss: 1.2187 - val_accuracy: 0.4847\n",
      "Epoch 242/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9157 - accuracy: 0.6431 - val_loss: 1.2148 - val_accuracy: 0.5102\n",
      "Epoch 243/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9108 - accuracy: 0.6337 - val_loss: 1.2231 - val_accuracy: 0.4974\n",
      "Epoch 244/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.9045 - accuracy: 0.6425 - val_loss: 1.1874 - val_accuracy: 0.5230\n",
      "Epoch 245/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.9076 - accuracy: 0.6337 - val_loss: 1.2235 - val_accuracy: 0.4770\n",
      "Epoch 246/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.9078 - accuracy: 0.6458 - val_loss: 1.1946 - val_accuracy: 0.5153\n",
      "Epoch 247/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8995 - accuracy: 0.6438 - val_loss: 1.1926 - val_accuracy: 0.5179\n",
      "Epoch 248/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.9055 - accuracy: 0.6378 - val_loss: 1.1852 - val_accuracy: 0.5204\n",
      "Epoch 249/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.9009 - accuracy: 0.6324 - val_loss: 1.2008 - val_accuracy: 0.5179\n",
      "Epoch 250/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8978 - accuracy: 0.6418 - val_loss: 1.2529 - val_accuracy: 0.4821\n",
      "Epoch 251/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.9021 - accuracy: 0.6552 - val_loss: 1.2021 - val_accuracy: 0.5179\n",
      "Epoch 252/700\n",
      "93/93 [==============================] - 3s 30ms/step - loss: 0.8982 - accuracy: 0.6552 - val_loss: 1.1894 - val_accuracy: 0.5051\n",
      "Epoch 253/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.9014 - accuracy: 0.6485 - val_loss: 1.1838 - val_accuracy: 0.5077\n",
      "Epoch 254/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8990 - accuracy: 0.6378 - val_loss: 1.1946 - val_accuracy: 0.4872\n",
      "Epoch 255/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8965 - accuracy: 0.6499 - val_loss: 1.2293 - val_accuracy: 0.4872\n",
      "Epoch 256/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8963 - accuracy: 0.6492 - val_loss: 1.2137 - val_accuracy: 0.4898\n",
      "Epoch 257/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8937 - accuracy: 0.6512 - val_loss: 1.1979 - val_accuracy: 0.5153\n",
      "Epoch 258/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8898 - accuracy: 0.6384 - val_loss: 1.2308 - val_accuracy: 0.4847\n",
      "Epoch 259/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8852 - accuracy: 0.6599 - val_loss: 1.2316 - val_accuracy: 0.4872\n",
      "Epoch 260/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8841 - accuracy: 0.6532 - val_loss: 1.2151 - val_accuracy: 0.4719\n",
      "Epoch 261/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8900 - accuracy: 0.6478 - val_loss: 1.2046 - val_accuracy: 0.5000\n",
      "Epoch 262/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8854 - accuracy: 0.6485 - val_loss: 1.2068 - val_accuracy: 0.5051\n",
      "Epoch 263/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8859 - accuracy: 0.6512 - val_loss: 1.2080 - val_accuracy: 0.5179\n",
      "Epoch 264/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8816 - accuracy: 0.6458 - val_loss: 1.2020 - val_accuracy: 0.5077\n",
      "Epoch 265/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8809 - accuracy: 0.6546 - val_loss: 1.2185 - val_accuracy: 0.4923\n",
      "Epoch 266/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8827 - accuracy: 0.6452 - val_loss: 1.2144 - val_accuracy: 0.4898\n",
      "Epoch 267/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8720 - accuracy: 0.6566 - val_loss: 1.2014 - val_accuracy: 0.5077\n",
      "Epoch 268/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8743 - accuracy: 0.6606 - val_loss: 1.2089 - val_accuracy: 0.5077\n",
      "Epoch 269/700\n",
      "93/93 [==============================] - 3s 30ms/step - loss: 0.8748 - accuracy: 0.6680 - val_loss: 1.1984 - val_accuracy: 0.5051\n",
      "Epoch 270/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8706 - accuracy: 0.6472 - val_loss: 1.1930 - val_accuracy: 0.5102\n",
      "Epoch 271/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8652 - accuracy: 0.6633 - val_loss: 1.2106 - val_accuracy: 0.5051\n",
      "Epoch 272/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8699 - accuracy: 0.6633 - val_loss: 1.1856 - val_accuracy: 0.5026\n",
      "Epoch 273/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8715 - accuracy: 0.6660 - val_loss: 1.1924 - val_accuracy: 0.5179\n",
      "Epoch 274/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8631 - accuracy: 0.6754 - val_loss: 1.2518 - val_accuracy: 0.5000\n",
      "Epoch 275/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8674 - accuracy: 0.6626 - val_loss: 1.1992 - val_accuracy: 0.5026\n",
      "Epoch 276/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8625 - accuracy: 0.6620 - val_loss: 1.2357 - val_accuracy: 0.4694\n",
      "Epoch 277/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8557 - accuracy: 0.6707 - val_loss: 1.2032 - val_accuracy: 0.5306\n",
      "Epoch 278/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8533 - accuracy: 0.6720 - val_loss: 1.1877 - val_accuracy: 0.5153\n",
      "Epoch 279/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8596 - accuracy: 0.6626 - val_loss: 1.1914 - val_accuracy: 0.5000uracy\n",
      "Epoch 280/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8508 - accuracy: 0.6747 - val_loss: 1.2096 - val_accuracy: 0.4898\n",
      "Epoch 281/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8570 - accuracy: 0.6747 - val_loss: 1.2319 - val_accuracy: 0.5026\n",
      "Epoch 282/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8567 - accuracy: 0.6647 - val_loss: 1.2437 - val_accuracy: 0.4872\n",
      "Epoch 283/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8526 - accuracy: 0.6714 - val_loss: 1.2037 - val_accuracy: 0.5102\n",
      "Epoch 284/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8418 - accuracy: 0.6741 - val_loss: 1.1933 - val_accuracy: 0.5179\n",
      "Epoch 285/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8470 - accuracy: 0.6767 - val_loss: 1.1907 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8439 - accuracy: 0.6687 - val_loss: 1.1948 - val_accuracy: 0.5077\n",
      "Epoch 287/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8421 - accuracy: 0.6828 - val_loss: 1.2217 - val_accuracy: 0.4949\n",
      "Epoch 288/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8399 - accuracy: 0.6747 - val_loss: 1.2173 - val_accuracy: 0.5051\n",
      "Epoch 289/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8433 - accuracy: 0.6747 - val_loss: 1.1794 - val_accuracy: 0.5153\n",
      "Epoch 290/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8307 - accuracy: 0.6821 - val_loss: 1.2191 - val_accuracy: 0.4847\n",
      "Epoch 291/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8386 - accuracy: 0.6680 - val_loss: 1.2308 - val_accuracy: 0.5128\n",
      "Epoch 292/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8411 - accuracy: 0.6687 - val_loss: 1.2210 - val_accuracy: 0.5051\n",
      "Epoch 293/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8385 - accuracy: 0.6747 - val_loss: 1.1940 - val_accuracy: 0.5077\n",
      "Epoch 294/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8335 - accuracy: 0.6734 - val_loss: 1.1900 - val_accuracy: 0.4949\n",
      "Epoch 295/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8321 - accuracy: 0.6808 - val_loss: 1.2204 - val_accuracy: 0.4949\n",
      "Epoch 296/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8294 - accuracy: 0.6754 - val_loss: 1.2213 - val_accuracy: 0.5255\n",
      "Epoch 297/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8305 - accuracy: 0.6848 - val_loss: 1.2177 - val_accuracy: 0.5026\n",
      "Epoch 298/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8303 - accuracy: 0.6895 - val_loss: 1.1893 - val_accuracy: 0.5051\n",
      "Epoch 299/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8281 - accuracy: 0.6741 - val_loss: 1.1831 - val_accuracy: 0.5102\n",
      "Epoch 300/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8256 - accuracy: 0.6781 - val_loss: 1.1986 - val_accuracy: 0.5102\n",
      "Epoch 301/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.8252 - accuracy: 0.6882 - val_loss: 1.1854 - val_accuracy: 0.5102\n",
      "Epoch 302/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.8206 - accuracy: 0.6929 - val_loss: 1.2498 - val_accuracy: 0.4898\n",
      "Epoch 303/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8218 - accuracy: 0.6828 - val_loss: 1.2028 - val_accuracy: 0.4872\n",
      "Epoch 304/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8156 - accuracy: 0.6808 - val_loss: 1.2078 - val_accuracy: 0.5051\n",
      "Epoch 305/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8200 - accuracy: 0.6888 - val_loss: 1.2095 - val_accuracy: 0.5204\n",
      "Epoch 306/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8199 - accuracy: 0.6835 - val_loss: 1.1771 - val_accuracy: 0.5128\n",
      "Epoch 307/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8124 - accuracy: 0.6915 - val_loss: 1.2388 - val_accuracy: 0.4872\n",
      "Epoch 308/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8153 - accuracy: 0.6902 - val_loss: 1.2372 - val_accuracy: 0.5000\n",
      "Epoch 309/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8035 - accuracy: 0.6895 - val_loss: 1.2091 - val_accuracy: 0.5077\n",
      "Epoch 310/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8034 - accuracy: 0.6909 - val_loss: 1.2025 - val_accuracy: 0.4898\n",
      "Epoch 311/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8029 - accuracy: 0.6949 - val_loss: 1.2054 - val_accuracy: 0.4949\n",
      "Epoch 312/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8119 - accuracy: 0.6909 - val_loss: 1.1832 - val_accuracy: 0.5153\n",
      "Epoch 313/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8031 - accuracy: 0.6935 - val_loss: 1.2316 - val_accuracy: 0.4847\n",
      "Epoch 314/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7966 - accuracy: 0.6915 - val_loss: 1.2539 - val_accuracy: 0.4974\n",
      "Epoch 315/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.8074 - accuracy: 0.6761 - val_loss: 1.1909 - val_accuracy: 0.5026\n",
      "Epoch 316/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.8003 - accuracy: 0.6801 - val_loss: 1.1768 - val_accuracy: 0.5077\n",
      "Epoch 317/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7947 - accuracy: 0.7056 - val_loss: 1.1919 - val_accuracy: 0.5179\n",
      "Epoch 318/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7959 - accuracy: 0.7003 - val_loss: 1.2381 - val_accuracy: 0.4745\n",
      "Epoch 319/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7937 - accuracy: 0.7016 - val_loss: 1.2062 - val_accuracy: 0.5000\n",
      "Epoch 320/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7915 - accuracy: 0.7009 - val_loss: 1.2068 - val_accuracy: 0.5026\n",
      "Epoch 321/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7937 - accuracy: 0.6935 - val_loss: 1.1868 - val_accuracy: 0.4974\n",
      "Epoch 322/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7935 - accuracy: 0.7030 - val_loss: 1.2540 - val_accuracy: 0.4643\n",
      "Epoch 323/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7838 - accuracy: 0.7023 - val_loss: 1.2156 - val_accuracy: 0.5026\n",
      "Epoch 324/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7879 - accuracy: 0.6983 - val_loss: 1.2481 - val_accuracy: 0.4923\n",
      "Epoch 325/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7879 - accuracy: 0.7043 - val_loss: 1.2066 - val_accuracy: 0.5051\n",
      "Epoch 326/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7864 - accuracy: 0.6915 - val_loss: 1.2257 - val_accuracy: 0.4821\n",
      "Epoch 327/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7849 - accuracy: 0.7144 - val_loss: 1.1858 - val_accuracy: 0.5051\n",
      "Epoch 328/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7766 - accuracy: 0.6989 - val_loss: 1.1786 - val_accuracy: 0.5077\n",
      "Epoch 329/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7740 - accuracy: 0.7097 - val_loss: 1.2290 - val_accuracy: 0.4949\n",
      "Epoch 330/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7752 - accuracy: 0.7157 - val_loss: 1.2004 - val_accuracy: 0.4949\n",
      "Epoch 331/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7740 - accuracy: 0.7157 - val_loss: 1.2277 - val_accuracy: 0.4949\n",
      "Epoch 332/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7733 - accuracy: 0.7016 - val_loss: 1.1911 - val_accuracy: 0.5077\n",
      "Epoch 333/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7673 - accuracy: 0.7218 - val_loss: 1.1821 - val_accuracy: 0.5051\n",
      "Epoch 334/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7653 - accuracy: 0.7056 - val_loss: 1.2458 - val_accuracy: 0.4719\n",
      "Epoch 335/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7688 - accuracy: 0.7097 - val_loss: 1.1951 - val_accuracy: 0.5026\n",
      "Epoch 336/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7635 - accuracy: 0.7144 - val_loss: 1.1855 - val_accuracy: 0.4974\n",
      "Epoch 337/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7652 - accuracy: 0.7157 - val_loss: 1.2002 - val_accuracy: 0.5077\n",
      "Epoch 338/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7628 - accuracy: 0.7191 - val_loss: 1.2122 - val_accuracy: 0.5077\n",
      "Epoch 339/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7653 - accuracy: 0.7070 - val_loss: 1.2101 - val_accuracy: 0.4796\n",
      "Epoch 340/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.7633 - accuracy: 0.7151 - val_loss: 1.2073 - val_accuracy: 0.4796\n",
      "Epoch 341/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7598 - accuracy: 0.7184 - val_loss: 1.1996 - val_accuracy: 0.5128\n",
      "Epoch 342/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7531 - accuracy: 0.7157 - val_loss: 1.2034 - val_accuracy: 0.5051\n",
      "Epoch 343/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7558 - accuracy: 0.7157 - val_loss: 1.2141 - val_accuracy: 0.5026\n",
      "Epoch 344/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7478 - accuracy: 0.7224 - val_loss: 1.2015 - val_accuracy: 0.5026\n",
      "Epoch 345/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7589 - accuracy: 0.7191 - val_loss: 1.1910 - val_accuracy: 0.5026\n",
      "Epoch 346/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7457 - accuracy: 0.7319 - val_loss: 1.1927 - val_accuracy: 0.4974\n",
      "Epoch 347/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.7501 - accuracy: 0.7177 - val_loss: 1.2073 - val_accuracy: 0.4974\n",
      "Epoch 348/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7540 - accuracy: 0.7231 - val_loss: 1.2159 - val_accuracy: 0.4898\n",
      "Epoch 349/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7444 - accuracy: 0.7251 - val_loss: 1.2073 - val_accuracy: 0.4923\n",
      "Epoch 350/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7378 - accuracy: 0.7325 - val_loss: 1.2194 - val_accuracy: 0.4974\n",
      "Epoch 351/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7443 - accuracy: 0.7231 - val_loss: 1.2273 - val_accuracy: 0.4898\n",
      "Epoch 352/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7337 - accuracy: 0.7312 - val_loss: 1.2305 - val_accuracy: 0.4847\n",
      "Epoch 353/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7445 - accuracy: 0.7251 - val_loss: 1.1876 - val_accuracy: 0.5000\n",
      "Epoch 354/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7384 - accuracy: 0.7224 - val_loss: 1.2202 - val_accuracy: 0.5102\n",
      "Epoch 355/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7390 - accuracy: 0.7231 - val_loss: 1.1963 - val_accuracy: 0.5026\n",
      "Epoch 356/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7312 - accuracy: 0.7366 - val_loss: 1.1968 - val_accuracy: 0.4872\n",
      "Epoch 357/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7243 - accuracy: 0.7298 - val_loss: 1.2350 - val_accuracy: 0.4974\n",
      "Epoch 358/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7341 - accuracy: 0.7386 - val_loss: 1.1949 - val_accuracy: 0.5000\n",
      "Epoch 359/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7323 - accuracy: 0.7298 - val_loss: 1.2030 - val_accuracy: 0.4796\n",
      "Epoch 360/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7282 - accuracy: 0.7339 - val_loss: 1.2478 - val_accuracy: 0.4643\n",
      "Epoch 361/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7270 - accuracy: 0.7345 - val_loss: 1.2772 - val_accuracy: 0.4719\n",
      "Epoch 362/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7270 - accuracy: 0.7359 - val_loss: 1.2681 - val_accuracy: 0.4770\n",
      "Epoch 363/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7226 - accuracy: 0.7339 - val_loss: 1.1906 - val_accuracy: 0.5026\n",
      "Epoch 364/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7227 - accuracy: 0.7278 - val_loss: 1.1843 - val_accuracy: 0.5077\n",
      "Epoch 365/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7209 - accuracy: 0.7446 - val_loss: 1.2274 - val_accuracy: 0.4770\n",
      "Epoch 366/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7207 - accuracy: 0.7366 - val_loss: 1.2791 - val_accuracy: 0.4796\n",
      "Epoch 367/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7112 - accuracy: 0.7426 - val_loss: 1.1996 - val_accuracy: 0.4923\n",
      "Epoch 368/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7162 - accuracy: 0.7446 - val_loss: 1.2454 - val_accuracy: 0.4796\n",
      "Epoch 369/700\n",
      "93/93 [==============================] - 3s 29ms/step - loss: 0.7096 - accuracy: 0.7406 - val_loss: 1.2080 - val_accuracy: 0.4974\n",
      "Epoch 370/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.7051 - accuracy: 0.7574 - val_loss: 1.2203 - val_accuracy: 0.4898\n",
      "Epoch 371/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.7106 - accuracy: 0.7426 - val_loss: 1.2217 - val_accuracy: 0.50774\n",
      "Epoch 372/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.7094 - accuracy: 0.7359 - val_loss: 1.2129 - val_accuracy: 0.5026\n",
      "Epoch 373/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.7092 - accuracy: 0.7547 - val_loss: 1.2170 - val_accuracy: 0.5000\n",
      "Epoch 374/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7049 - accuracy: 0.7339 - val_loss: 1.1929 - val_accuracy: 0.4923\n",
      "Epoch 375/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.7037 - accuracy: 0.7513 - val_loss: 1.2141 - val_accuracy: 0.5026\n",
      "Epoch 376/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6977 - accuracy: 0.7513 - val_loss: 1.2328 - val_accuracy: 0.5000\n",
      "Epoch 377/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6972 - accuracy: 0.7513 - val_loss: 1.2048 - val_accuracy: 0.5026s - l\n",
      "Epoch 378/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6950 - accuracy: 0.7480 - val_loss: 1.2312 - val_accuracy: 0.4770\n",
      "Epoch 379/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6945 - accuracy: 0.7527 - val_loss: 1.2284 - val_accuracy: 0.4821\n",
      "Epoch 380/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6965 - accuracy: 0.7446 - val_loss: 1.2379 - val_accuracy: 0.4847\n",
      "Epoch 381/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6891 - accuracy: 0.7285 - val_loss: 1.2216 - val_accuracy: 0.5077\n",
      "Epoch 382/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6874 - accuracy: 0.7413 - val_loss: 1.1958 - val_accuracy: 0.5179\n",
      "Epoch 383/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6960 - accuracy: 0.7500 - val_loss: 1.2260 - val_accuracy: 0.5026\n",
      "Epoch 384/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6871 - accuracy: 0.7547 - val_loss: 1.1842 - val_accuracy: 0.5026\n",
      "Epoch 385/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6810 - accuracy: 0.7567 - val_loss: 1.2403 - val_accuracy: 0.4796\n",
      "Epoch 386/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6885 - accuracy: 0.7480 - val_loss: 1.2417 - val_accuracy: 0.4872\n",
      "Epoch 387/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6843 - accuracy: 0.7587 - val_loss: 1.2113 - val_accuracy: 0.5128\n",
      "Epoch 388/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6822 - accuracy: 0.7634 - val_loss: 1.2236 - val_accuracy: 0.4872\n",
      "Epoch 389/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6785 - accuracy: 0.7634 - val_loss: 1.1839 - val_accuracy: 0.5051\n",
      "Epoch 390/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6744 - accuracy: 0.7473 - val_loss: 1.1974 - val_accuracy: 0.5026\n",
      "Epoch 391/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6771 - accuracy: 0.7621 - val_loss: 1.1885 - val_accuracy: 0.5026\n",
      "Epoch 392/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6704 - accuracy: 0.7594 - val_loss: 1.2515 - val_accuracy: 0.4796\n",
      "Epoch 393/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.6742 - accuracy: 0.7608 - val_loss: 1.2271 - val_accuracy: 0.4898\n",
      "Epoch 394/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6706 - accuracy: 0.7641 - val_loss: 1.2246 - val_accuracy: 0.4949\n",
      "Epoch 395/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6689 - accuracy: 0.7688 - val_loss: 1.1926 - val_accuracy: 0.4974\n",
      "Epoch 396/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6639 - accuracy: 0.7681 - val_loss: 1.1892 - val_accuracy: 0.5128\n",
      "Epoch 397/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6694 - accuracy: 0.7628 - val_loss: 1.2296 - val_accuracy: 0.5102\n",
      "Epoch 398/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6635 - accuracy: 0.7695 - val_loss: 1.2426 - val_accuracy: 0.4898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6625 - accuracy: 0.7668 - val_loss: 1.2437 - val_accuracy: 0.4949\n",
      "Epoch 400/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6634 - accuracy: 0.7614 - val_loss: 1.2004 - val_accuracy: 0.4821\n",
      "Epoch 401/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6616 - accuracy: 0.7621 - val_loss: 1.2427 - val_accuracy: 0.4872\n",
      "Epoch 402/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6608 - accuracy: 0.7594 - val_loss: 1.1949 - val_accuracy: 0.4923\n",
      "Epoch 403/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6416 - accuracy: 0.7789 - val_loss: 1.2439 - val_accuracy: 0.5051\n",
      "Epoch 404/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6548 - accuracy: 0.7527 - val_loss: 1.2045 - val_accuracy: 0.4796\n",
      "Epoch 405/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6553 - accuracy: 0.7547 - val_loss: 1.1908 - val_accuracy: 0.5332\n",
      "Epoch 406/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6476 - accuracy: 0.7655 - val_loss: 1.2135 - val_accuracy: 0.4872\n",
      "Epoch 407/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6509 - accuracy: 0.7695 - val_loss: 1.2124 - val_accuracy: 0.5102\n",
      "Epoch 408/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6537 - accuracy: 0.7608 - val_loss: 1.2196 - val_accuracy: 0.5000\n",
      "Epoch 409/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6438 - accuracy: 0.7648 - val_loss: 1.2075 - val_accuracy: 0.5026\n",
      "Epoch 410/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.6435 - accuracy: 0.7722 - val_loss: 1.2010 - val_accuracy: 0.5051\n",
      "Epoch 411/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6425 - accuracy: 0.7708 - val_loss: 1.2030 - val_accuracy: 0.4949\n",
      "Epoch 412/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6413 - accuracy: 0.7742 - val_loss: 1.2858 - val_accuracy: 0.4643\n",
      "Epoch 413/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6485 - accuracy: 0.7655 - val_loss: 1.1886 - val_accuracy: 0.5102\n",
      "Epoch 414/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6375 - accuracy: 0.7769 - val_loss: 1.1846 - val_accuracy: 0.5051\n",
      "Epoch 415/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6373 - accuracy: 0.7769 - val_loss: 1.2080 - val_accuracy: 0.5000\n",
      "Epoch 416/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6383 - accuracy: 0.7823 - val_loss: 1.2171 - val_accuracy: 0.5128\n",
      "Epoch 417/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6348 - accuracy: 0.7897 - val_loss: 1.2063 - val_accuracy: 0.4923\n",
      "Epoch 418/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6350 - accuracy: 0.7762 - val_loss: 1.1897 - val_accuracy: 0.5051\n",
      "Epoch 419/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6346 - accuracy: 0.7782 - val_loss: 1.1978 - val_accuracy: 0.5128\n",
      "Epoch 420/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6288 - accuracy: 0.7836 - val_loss: 1.2258 - val_accuracy: 0.5128\n",
      "Epoch 421/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6283 - accuracy: 0.7668 - val_loss: 1.1933 - val_accuracy: 0.5255\n",
      "Epoch 422/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6243 - accuracy: 0.7883 - val_loss: 1.2129 - val_accuracy: 0.4949\n",
      "Epoch 423/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6234 - accuracy: 0.7829 - val_loss: 1.2299 - val_accuracy: 0.4949\n",
      "Epoch 424/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6208 - accuracy: 0.7769 - val_loss: 1.2238 - val_accuracy: 0.5153\n",
      "Epoch 425/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6216 - accuracy: 0.7829 - val_loss: 1.2160 - val_accuracy: 0.5077\n",
      "Epoch 426/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6214 - accuracy: 0.7776 - val_loss: 1.2121 - val_accuracy: 0.5000\n",
      "Epoch 427/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6151 - accuracy: 0.7890 - val_loss: 1.2679 - val_accuracy: 0.4923\n",
      "Epoch 428/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6142 - accuracy: 0.7856 - val_loss: 1.2547 - val_accuracy: 0.5000\n",
      "Epoch 429/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6130 - accuracy: 0.7836 - val_loss: 1.2387 - val_accuracy: 0.4923\n",
      "Epoch 430/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6163 - accuracy: 0.7829 - val_loss: 1.2515 - val_accuracy: 0.4770\n",
      "Epoch 431/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6057 - accuracy: 0.7876 - val_loss: 1.2286 - val_accuracy: 0.4923\n",
      "Epoch 432/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6110 - accuracy: 0.7897 - val_loss: 1.2278 - val_accuracy: 0.4847\n",
      "Epoch 433/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6076 - accuracy: 0.7802 - val_loss: 1.2311 - val_accuracy: 0.4974\n",
      "Epoch 434/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6087 - accuracy: 0.7917 - val_loss: 1.2149 - val_accuracy: 0.5026\n",
      "Epoch 435/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6003 - accuracy: 0.7964 - val_loss: 1.2088 - val_accuracy: 0.5179\n",
      "Epoch 436/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6043 - accuracy: 0.7930 - val_loss: 1.2150 - val_accuracy: 0.4923\n",
      "Epoch 437/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.6016 - accuracy: 0.7883 - val_loss: 1.2355 - val_accuracy: 0.4949\n",
      "Epoch 438/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.6027 - accuracy: 0.7991 - val_loss: 1.2149 - val_accuracy: 0.5153\n",
      "Epoch 439/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5937 - accuracy: 0.7964 - val_loss: 1.2048 - val_accuracy: 0.5281\n",
      "Epoch 440/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5959 - accuracy: 0.8038 - val_loss: 1.2500 - val_accuracy: 0.4949\n",
      "Epoch 441/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5950 - accuracy: 0.7930 - val_loss: 1.2288 - val_accuracy: 0.5000\n",
      "Epoch 442/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5934 - accuracy: 0.8024 - val_loss: 1.2268 - val_accuracy: 0.4923\n",
      "Epoch 443/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.5924 - accuracy: 0.7977 - val_loss: 1.2136 - val_accuracy: 0.5102\n",
      "Epoch 444/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5901 - accuracy: 0.7964 - val_loss: 1.2111 - val_accuracy: 0.5204\n",
      "Epoch 445/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5913 - accuracy: 0.8024 - val_loss: 1.2261 - val_accuracy: 0.5102\n",
      "Epoch 446/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5922 - accuracy: 0.7910 - val_loss: 1.2044 - val_accuracy: 0.5179\n",
      "Epoch 447/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5843 - accuracy: 0.7997 - val_loss: 1.2261 - val_accuracy: 0.4796\n",
      "Epoch 448/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5793 - accuracy: 0.8024 - val_loss: 1.2497 - val_accuracy: 0.4923\n",
      "Epoch 449/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5813 - accuracy: 0.7950 - val_loss: 1.2086 - val_accuracy: 0.5000\n",
      "Epoch 450/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5814 - accuracy: 0.8058 - val_loss: 1.2248 - val_accuracy: 0.5128\n",
      "Epoch 451/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.5772 - accuracy: 0.8011 - val_loss: 1.2049 - val_accuracy: 0.5077\n",
      "Epoch 452/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.5708 - accuracy: 0.8085 - val_loss: 1.2521 - val_accuracy: 0.4923\n",
      "Epoch 453/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.5712 - accuracy: 0.8044 - val_loss: 1.2109 - val_accuracy: 0.5153\n",
      "Epoch 454/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5752 - accuracy: 0.8038 - val_loss: 1.2604 - val_accuracy: 0.4949\n",
      "Epoch 455/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5707 - accuracy: 0.7997 - val_loss: 1.2244 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5685 - accuracy: 0.8065 - val_loss: 1.2056 - val_accuracy: 0.5179\n",
      "Epoch 457/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5714 - accuracy: 0.8105 - val_loss: 1.2212 - val_accuracy: 0.5000\n",
      "Epoch 458/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5705 - accuracy: 0.8091 - val_loss: 1.2259 - val_accuracy: 0.5051\n",
      "Epoch 459/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5715 - accuracy: 0.8132 - val_loss: 1.2453 - val_accuracy: 0.4872\n",
      "Epoch 460/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5617 - accuracy: 0.8098 - val_loss: 1.2354 - val_accuracy: 0.4898\n",
      "Epoch 461/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5608 - accuracy: 0.8065 - val_loss: 1.2875 - val_accuracy: 0.4770\n",
      "Epoch 462/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5574 - accuracy: 0.8125 - val_loss: 1.2146 - val_accuracy: 0.5179\n",
      "Epoch 463/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5563 - accuracy: 0.8152 - val_loss: 1.2244 - val_accuracy: 0.5204\n",
      "Epoch 464/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5606 - accuracy: 0.8058 - val_loss: 1.2221 - val_accuracy: 0.5077\n",
      "Epoch 465/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5605 - accuracy: 0.8125 - val_loss: 1.2294 - val_accuracy: 0.4898\n",
      "Epoch 466/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5529 - accuracy: 0.8159 - val_loss: 1.2240 - val_accuracy: 0.5051\n",
      "Epoch 467/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5513 - accuracy: 0.8031 - val_loss: 1.2519 - val_accuracy: 0.5000\n",
      "Epoch 468/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5492 - accuracy: 0.8239 - val_loss: 1.1999 - val_accuracy: 0.5153\n",
      "Epoch 469/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5478 - accuracy: 0.8206 - val_loss: 1.2109 - val_accuracy: 0.5077\n",
      "Epoch 470/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5495 - accuracy: 0.8044 - val_loss: 1.2067 - val_accuracy: 0.4949\n",
      "Epoch 471/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5401 - accuracy: 0.8145 - val_loss: 1.2306 - val_accuracy: 0.4974\n",
      "Epoch 472/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5412 - accuracy: 0.8179 - val_loss: 1.2152 - val_accuracy: 0.5102\n",
      "Epoch 473/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5411 - accuracy: 0.8239 - val_loss: 1.2473 - val_accuracy: 0.5077\n",
      "Epoch 474/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5360 - accuracy: 0.8212 - val_loss: 1.2415 - val_accuracy: 0.5000\n",
      "Epoch 475/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5396 - accuracy: 0.8118 - val_loss: 1.3205 - val_accuracy: 0.4898\n",
      "Epoch 476/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5373 - accuracy: 0.8259 - val_loss: 1.2839 - val_accuracy: 0.4847\n",
      "Epoch 477/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.5430 - accuracy: 0.8179 - val_loss: 1.2176 - val_accuracy: 0.5179\n",
      "Epoch 478/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5268 - accuracy: 0.8273 - val_loss: 1.2406 - val_accuracy: 0.5179\n",
      "Epoch 479/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5284 - accuracy: 0.8219 - val_loss: 1.1990 - val_accuracy: 0.5230\n",
      "Epoch 480/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5312 - accuracy: 0.8199 - val_loss: 1.2166 - val_accuracy: 0.5026\n",
      "Epoch 481/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5309 - accuracy: 0.8212 - val_loss: 1.2406 - val_accuracy: 0.5077\n",
      "Epoch 482/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5298 - accuracy: 0.8340 - val_loss: 1.1999 - val_accuracy: 0.5153\n",
      "Epoch 483/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5289 - accuracy: 0.8300 - val_loss: 1.2329 - val_accuracy: 0.5051\n",
      "Epoch 484/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5290 - accuracy: 0.8387 - val_loss: 1.2004 - val_accuracy: 0.5230\n",
      "Epoch 485/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5220 - accuracy: 0.8347 - val_loss: 1.2131 - val_accuracy: 0.5102\n",
      "Epoch 486/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5195 - accuracy: 0.8293 - val_loss: 1.2172 - val_accuracy: 0.5077\n",
      "Epoch 487/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5258 - accuracy: 0.8246 - val_loss: 1.2531 - val_accuracy: 0.4898\n",
      "Epoch 488/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5182 - accuracy: 0.8313 - val_loss: 1.2086 - val_accuracy: 0.5281\n",
      "Epoch 489/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5129 - accuracy: 0.8333 - val_loss: 1.2017 - val_accuracy: 0.5306\n",
      "Epoch 490/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5222 - accuracy: 0.8320 - val_loss: 1.2788 - val_accuracy: 0.4821\n",
      "Epoch 491/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5148 - accuracy: 0.8306 - val_loss: 1.2264 - val_accuracy: 0.5102\n",
      "Epoch 492/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5155 - accuracy: 0.8273 - val_loss: 1.2202 - val_accuracy: 0.5077\n",
      "Epoch 493/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5076 - accuracy: 0.8300 - val_loss: 1.2725 - val_accuracy: 0.4898\n",
      "Epoch 494/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5110 - accuracy: 0.8327 - val_loss: 1.2728 - val_accuracy: 0.4847\n",
      "Epoch 495/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5056 - accuracy: 0.8280 - val_loss: 1.2137 - val_accuracy: 0.5179\n",
      "Epoch 496/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5022 - accuracy: 0.8401 - val_loss: 1.2663 - val_accuracy: 0.4923\n",
      "Epoch 497/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.5031 - accuracy: 0.8347 - val_loss: 1.2206 - val_accuracy: 0.5128\n",
      "Epoch 498/700\n",
      "93/93 [==============================] - ETA: 0s - loss: 0.4996 - accuracy: 0.82 - 2s 27ms/step - loss: 0.4996 - accuracy: 0.8280 - val_loss: 1.2791 - val_accuracy: 0.4770\n",
      "Epoch 499/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4996 - accuracy: 0.8360 - val_loss: 1.2020 - val_accuracy: 0.5357\n",
      "Epoch 500/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4943 - accuracy: 0.8508 - val_loss: 1.2565 - val_accuracy: 0.5051\n",
      "Epoch 501/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5024 - accuracy: 0.8407 - val_loss: 1.2125 - val_accuracy: 0.5204\n",
      "Epoch 502/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4926 - accuracy: 0.8374 - val_loss: 1.2806 - val_accuracy: 0.4872\n",
      "Epoch 503/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.5004 - accuracy: 0.8441 - val_loss: 1.2278 - val_accuracy: 0.5179\n",
      "Epoch 504/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4955 - accuracy: 0.8353 - val_loss: 1.2160 - val_accuracy: 0.5179\n",
      "Epoch 505/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4979 - accuracy: 0.8327 - val_loss: 1.2330 - val_accuracy: 0.5077\n",
      "Epoch 506/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4904 - accuracy: 0.8434 - val_loss: 1.2583 - val_accuracy: 0.4923\n",
      "Epoch 507/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4841 - accuracy: 0.8434 - val_loss: 1.2400 - val_accuracy: 0.4974\n",
      "Epoch 508/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4853 - accuracy: 0.8367 - val_loss: 1.2361 - val_accuracy: 0.5128\n",
      "Epoch 509/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4860 - accuracy: 0.8401 - val_loss: 1.2348 - val_accuracy: 0.5077\n",
      "Epoch 510/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4879 - accuracy: 0.8448 - val_loss: 1.2748 - val_accuracy: 0.4974\n",
      "Epoch 511/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4774 - accuracy: 0.8495 - val_loss: 1.2426 - val_accuracy: 0.4949\n",
      "Epoch 512/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4794 - accuracy: 0.8394 - val_loss: 1.2874 - val_accuracy: 0.4719\n",
      "Epoch 513/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.4790 - accuracy: 0.8474 - val_loss: 1.2562 - val_accuracy: 0.4847\n",
      "Epoch 514/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4785 - accuracy: 0.8407 - val_loss: 1.2539 - val_accuracy: 0.5077\n",
      "Epoch 515/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4789 - accuracy: 0.8448 - val_loss: 1.2671 - val_accuracy: 0.5000\n",
      "Epoch 516/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4745 - accuracy: 0.8569 - val_loss: 1.2285 - val_accuracy: 0.5153\n",
      "Epoch 517/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4709 - accuracy: 0.8468 - val_loss: 1.2251 - val_accuracy: 0.5051\n",
      "Epoch 518/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4695 - accuracy: 0.8508 - val_loss: 1.2238 - val_accuracy: 0.5357\n",
      "Epoch 519/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4651 - accuracy: 0.8542 - val_loss: 1.2436 - val_accuracy: 0.5026\n",
      "Epoch 520/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4703 - accuracy: 0.8481 - val_loss: 1.2708 - val_accuracy: 0.5153\n",
      "Epoch 521/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4719 - accuracy: 0.8575 - val_loss: 1.2217 - val_accuracy: 0.5204\n",
      "Epoch 522/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4598 - accuracy: 0.8609 - val_loss: 1.2735 - val_accuracy: 0.5026\n",
      "Epoch 523/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4625 - accuracy: 0.8542 - val_loss: 1.3011 - val_accuracy: 0.4796\n",
      "Epoch 524/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4625 - accuracy: 0.8488 - val_loss: 1.2700 - val_accuracy: 0.5026\n",
      "Epoch 525/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4600 - accuracy: 0.8434 - val_loss: 1.2785 - val_accuracy: 0.5077\n",
      "Epoch 526/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4652 - accuracy: 0.8495 - val_loss: 1.2862 - val_accuracy: 0.4872\n",
      "Epoch 527/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4610 - accuracy: 0.8609 - val_loss: 1.2346 - val_accuracy: 0.5128\n",
      "Epoch 528/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4480 - accuracy: 0.8609 - val_loss: 1.2339 - val_accuracy: 0.5179\n",
      "Epoch 529/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4567 - accuracy: 0.8616 - val_loss: 1.2377 - val_accuracy: 0.5179\n",
      "Epoch 530/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4513 - accuracy: 0.8703 - val_loss: 1.2596 - val_accuracy: 0.5383\n",
      "Epoch 531/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4524 - accuracy: 0.8562 - val_loss: 1.2371 - val_accuracy: 0.5077\n",
      "Epoch 532/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.4473 - accuracy: 0.8636 - val_loss: 1.2570 - val_accuracy: 0.4898\n",
      "Epoch 533/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4464 - accuracy: 0.8575 - val_loss: 1.2819 - val_accuracy: 0.5102\n",
      "Epoch 534/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4437 - accuracy: 0.8642 - val_loss: 1.2456 - val_accuracy: 0.5153\n",
      "Epoch 535/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4430 - accuracy: 0.8602 - val_loss: 1.2624 - val_accuracy: 0.4974\n",
      "Epoch 536/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4454 - accuracy: 0.8569 - val_loss: 1.2973 - val_accuracy: 0.4974\n",
      "Epoch 537/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4402 - accuracy: 0.8562 - val_loss: 1.2621 - val_accuracy: 0.5000\n",
      "Epoch 538/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4371 - accuracy: 0.8602 - val_loss: 1.2543 - val_accuracy: 0.5077\n",
      "Epoch 539/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4369 - accuracy: 0.8582 - val_loss: 1.2448 - val_accuracy: 0.5230\n",
      "Epoch 540/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4325 - accuracy: 0.8676 - val_loss: 1.2543 - val_accuracy: 0.5332\n",
      "Epoch 541/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4410 - accuracy: 0.8609 - val_loss: 1.2940 - val_accuracy: 0.4898\n",
      "Epoch 542/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4318 - accuracy: 0.8622 - val_loss: 1.2946 - val_accuracy: 0.5077\n",
      "Epoch 543/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4413 - accuracy: 0.8569 - val_loss: 1.3004 - val_accuracy: 0.5026\n",
      "Epoch 544/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4270 - accuracy: 0.8636 - val_loss: 1.2662 - val_accuracy: 0.5102\n",
      "Epoch 545/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4253 - accuracy: 0.8703 - val_loss: 1.3702 - val_accuracy: 0.4745\n",
      "Epoch 546/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4327 - accuracy: 0.8696 - val_loss: 1.2785 - val_accuracy: 0.5102\n",
      "Epoch 547/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4261 - accuracy: 0.8710 - val_loss: 1.2508 - val_accuracy: 0.5281\n",
      "Epoch 548/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4190 - accuracy: 0.8757 - val_loss: 1.2689 - val_accuracy: 0.5153\n",
      "Epoch 549/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4246 - accuracy: 0.8750 - val_loss: 1.2447 - val_accuracy: 0.5230\n",
      "Epoch 550/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4263 - accuracy: 0.8730 - val_loss: 1.3030 - val_accuracy: 0.5051\n",
      "Epoch 551/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4167 - accuracy: 0.8716 - val_loss: 1.2540 - val_accuracy: 0.5153\n",
      "Epoch 552/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4229 - accuracy: 0.8723 - val_loss: 1.2632 - val_accuracy: 0.5000\n",
      "Epoch 553/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4210 - accuracy: 0.8716 - val_loss: 1.2836 - val_accuracy: 0.5281\n",
      "Epoch 554/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4209 - accuracy: 0.8629 - val_loss: 1.2704 - val_accuracy: 0.4949\n",
      "Epoch 555/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4177 - accuracy: 0.8790 - val_loss: 1.3089 - val_accuracy: 0.4770\n",
      "Epoch 556/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4192 - accuracy: 0.8810 - val_loss: 1.2790 - val_accuracy: 0.5102\n",
      "Epoch 557/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4091 - accuracy: 0.8743 - val_loss: 1.2935 - val_accuracy: 0.4923\n",
      "Epoch 558/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4104 - accuracy: 0.8743 - val_loss: 1.3492 - val_accuracy: 0.5128\n",
      "Epoch 559/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4117 - accuracy: 0.8804 - val_loss: 1.2842 - val_accuracy: 0.5077\n",
      "Epoch 560/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4062 - accuracy: 0.8810 - val_loss: 1.2899 - val_accuracy: 0.5051\n",
      "Epoch 561/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4053 - accuracy: 0.8770 - val_loss: 1.2553 - val_accuracy: 0.5179\n",
      "Epoch 562/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4048 - accuracy: 0.8683 - val_loss: 1.2928 - val_accuracy: 0.4872\n",
      "Epoch 563/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4082 - accuracy: 0.8777 - val_loss: 1.2640 - val_accuracy: 0.5153\n",
      "Epoch 564/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4037 - accuracy: 0.8737 - val_loss: 1.2980 - val_accuracy: 0.5102\n",
      "Epoch 565/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.4045 - accuracy: 0.8730 - val_loss: 1.3123 - val_accuracy: 0.5000\n",
      "Epoch 566/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3965 - accuracy: 0.8831 - val_loss: 1.3281 - val_accuracy: 0.4949\n",
      "Epoch 567/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.4041 - accuracy: 0.8770 - val_loss: 1.2884 - val_accuracy: 0.5102\n",
      "Epoch 568/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3909 - accuracy: 0.8810 - val_loss: 1.2459 - val_accuracy: 0.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 569/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3917 - accuracy: 0.8884 - val_loss: 1.2710 - val_accuracy: 0.5077\n",
      "Epoch 570/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3962 - accuracy: 0.8810 - val_loss: 1.2793 - val_accuracy: 0.5077\n",
      "Epoch 571/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3926 - accuracy: 0.8837 - val_loss: 1.2687 - val_accuracy: 0.5026\n",
      "Epoch 572/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3898 - accuracy: 0.8844 - val_loss: 1.3754 - val_accuracy: 0.4668\n",
      "Epoch 573/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3874 - accuracy: 0.8784 - val_loss: 1.2751 - val_accuracy: 0.4949\n",
      "Epoch 574/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3894 - accuracy: 0.8871 - val_loss: 1.2686 - val_accuracy: 0.5179\n",
      "Epoch 575/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3881 - accuracy: 0.8918 - val_loss: 1.2911 - val_accuracy: 0.5153\n",
      "Epoch 576/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3868 - accuracy: 0.8891 - val_loss: 1.2981 - val_accuracy: 0.5077\n",
      "Epoch 577/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3851 - accuracy: 0.8945 - val_loss: 1.3022 - val_accuracy: 0.5179\n",
      "Epoch 578/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3801 - accuracy: 0.8891 - val_loss: 1.2695 - val_accuracy: 0.5179\n",
      "Epoch 579/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3842 - accuracy: 0.8864 - val_loss: 1.2775 - val_accuracy: 0.4949\n",
      "Epoch 580/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3847 - accuracy: 0.8831 - val_loss: 1.2586 - val_accuracy: 0.5128\n",
      "Epoch 581/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3791 - accuracy: 0.8844 - val_loss: 1.3498 - val_accuracy: 0.4847\n",
      "Epoch 582/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3782 - accuracy: 0.8824 - val_loss: 1.2734 - val_accuracy: 0.5204\n",
      "Epoch 583/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3725 - accuracy: 0.8905 - val_loss: 1.2889 - val_accuracy: 0.5230\n",
      "Epoch 584/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3706 - accuracy: 0.8952 - val_loss: 1.3077 - val_accuracy: 0.4923\n",
      "Epoch 585/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3701 - accuracy: 0.8918 - val_loss: 1.2722 - val_accuracy: 0.5230\n",
      "Epoch 586/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3747 - accuracy: 0.8871 - val_loss: 1.2864 - val_accuracy: 0.5255\n",
      "Epoch 587/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3671 - accuracy: 0.8945 - val_loss: 1.3026 - val_accuracy: 0.5051\n",
      "Epoch 588/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3651 - accuracy: 0.8945 - val_loss: 1.2729 - val_accuracy: 0.5204\n",
      "Epoch 589/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3698 - accuracy: 0.8965 - val_loss: 1.3135 - val_accuracy: 0.5102\n",
      "Epoch 590/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3685 - accuracy: 0.8925 - val_loss: 1.3078 - val_accuracy: 0.5102\n",
      "Epoch 591/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3581 - accuracy: 0.8952 - val_loss: 1.3142 - val_accuracy: 0.5102\n",
      "Epoch 592/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3622 - accuracy: 0.8945 - val_loss: 1.4499 - val_accuracy: 0.4847\n",
      "Epoch 593/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3595 - accuracy: 0.8918 - val_loss: 1.2997 - val_accuracy: 0.5102\n",
      "Epoch 594/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3617 - accuracy: 0.8985 - val_loss: 1.2960 - val_accuracy: 0.5000\n",
      "Epoch 595/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3548 - accuracy: 0.8918 - val_loss: 1.2752 - val_accuracy: 0.5153\n",
      "Epoch 596/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3601 - accuracy: 0.8965 - val_loss: 1.2886 - val_accuracy: 0.5077\n",
      "Epoch 597/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3540 - accuracy: 0.8958 - val_loss: 1.2793 - val_accuracy: 0.5306\n",
      "Epoch 598/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3518 - accuracy: 0.8999 - val_loss: 1.2946 - val_accuracy: 0.4949\n",
      "Epoch 599/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3508 - accuracy: 0.8985 - val_loss: 1.3093 - val_accuracy: 0.5077\n",
      "Epoch 600/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3466 - accuracy: 0.9039 - val_loss: 1.3469 - val_accuracy: 0.5102\n",
      "Epoch 601/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3518 - accuracy: 0.8999 - val_loss: 1.3129 - val_accuracy: 0.5102\n",
      "Epoch 602/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3522 - accuracy: 0.9046 - val_loss: 1.3178 - val_accuracy: 0.5128\n",
      "Epoch 603/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3465 - accuracy: 0.9012 - val_loss: 1.2923 - val_accuracy: 0.5102\n",
      "Epoch 604/700\n",
      "93/93 [==============================] - 3s 31ms/step - loss: 0.3441 - accuracy: 0.8992 - val_loss: 1.3096 - val_accuracy: 0.5153\n",
      "Epoch 605/700\n",
      "93/93 [==============================] - 3s 29ms/step - loss: 0.3427 - accuracy: 0.9073 - val_loss: 1.3378 - val_accuracy: 0.4974\n",
      "Epoch 606/700\n",
      "93/93 [==============================] - 2s 26ms/step - loss: 0.3373 - accuracy: 0.9093 - val_loss: 1.3098 - val_accuracy: 0.5102\n",
      "Epoch 607/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3360 - accuracy: 0.9059 - val_loss: 1.3185 - val_accuracy: 0.5102s - loss: 0.3\n",
      "Epoch 608/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3399 - accuracy: 0.9066 - val_loss: 1.3293 - val_accuracy: 0.5204\n",
      "Epoch 609/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3387 - accuracy: 0.9066 - val_loss: 1.3315 - val_accuracy: 0.5230\n",
      "Epoch 610/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3408 - accuracy: 0.9012 - val_loss: 1.3371 - val_accuracy: 0.4949\n",
      "Epoch 611/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3321 - accuracy: 0.9079 - val_loss: 1.2863 - val_accuracy: 0.5102\n",
      "Epoch 612/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3378 - accuracy: 0.9113 - val_loss: 1.3488 - val_accuracy: 0.5230\n",
      "Epoch 613/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3347 - accuracy: 0.9026 - val_loss: 1.3543 - val_accuracy: 0.5204\n",
      "Epoch 614/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3323 - accuracy: 0.9180 - val_loss: 1.3502 - val_accuracy: 0.5051\n",
      "Epoch 615/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3324 - accuracy: 0.9039 - val_loss: 1.2868 - val_accuracy: 0.5306\n",
      "Epoch 616/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.3300 - accuracy: 0.9113 - val_loss: 1.3157 - val_accuracy: 0.5332\n",
      "Epoch 617/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3281 - accuracy: 0.9106 - val_loss: 1.3182 - val_accuracy: 0.5204\n",
      "Epoch 618/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3313 - accuracy: 0.9079 - val_loss: 1.3730 - val_accuracy: 0.4949\n",
      "Epoch 619/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3202 - accuracy: 0.9133 - val_loss: 1.3873 - val_accuracy: 0.4872\n",
      "Epoch 620/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3232 - accuracy: 0.9133 - val_loss: 1.3337 - val_accuracy: 0.5077\n",
      "Epoch 621/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3245 - accuracy: 0.9079 - val_loss: 1.3734 - val_accuracy: 0.4974\n",
      "Epoch 622/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3216 - accuracy: 0.9079 - val_loss: 1.3151 - val_accuracy: 0.5128\n",
      "Epoch 623/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3276 - accuracy: 0.9099 - val_loss: 1.3321 - val_accuracy: 0.5128\n",
      "Epoch 624/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3168 - accuracy: 0.9187 - val_loss: 1.3123 - val_accuracy: 0.5306\n",
      "Epoch 625/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3181 - accuracy: 0.9180 - val_loss: 1.3554 - val_accuracy: 0.5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3205 - accuracy: 0.9106 - val_loss: 1.3546 - val_accuracy: 0.4923\n",
      "Epoch 627/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3109 - accuracy: 0.9234 - val_loss: 1.3047 - val_accuracy: 0.5179\n",
      "Epoch 628/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3100 - accuracy: 0.9099 - val_loss: 1.3442 - val_accuracy: 0.5128\n",
      "Epoch 629/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3094 - accuracy: 0.9160 - val_loss: 1.3239 - val_accuracy: 0.5306\n",
      "Epoch 630/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3109 - accuracy: 0.9133 - val_loss: 1.3515 - val_accuracy: 0.5051\n",
      "Epoch 631/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3101 - accuracy: 0.9153 - val_loss: 1.4017 - val_accuracy: 0.4949\n",
      "Epoch 632/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3152 - accuracy: 0.9147 - val_loss: 1.4116 - val_accuracy: 0.4770\n",
      "Epoch 633/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3040 - accuracy: 0.9160 - val_loss: 1.3614 - val_accuracy: 0.5000\n",
      "Epoch 634/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3059 - accuracy: 0.9133 - val_loss: 1.3329 - val_accuracy: 0.4872\n",
      "Epoch 635/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3014 - accuracy: 0.9261 - val_loss: 1.3324 - val_accuracy: 0.5332\n",
      "Epoch 636/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3010 - accuracy: 0.9153 - val_loss: 1.3366 - val_accuracy: 0.5102\n",
      "Epoch 637/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.3044 - accuracy: 0.9254 - val_loss: 1.3560 - val_accuracy: 0.5051\n",
      "Epoch 638/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2942 - accuracy: 0.9194 - val_loss: 1.3761 - val_accuracy: 0.4949\n",
      "Epoch 639/700\n",
      "93/93 [==============================] - 3s 29ms/step - loss: 0.2948 - accuracy: 0.9214 - val_loss: 1.3500 - val_accuracy: 0.5000\n",
      "Epoch 640/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2924 - accuracy: 0.9234 - val_loss: 1.3898 - val_accuracy: 0.5051\n",
      "Epoch 641/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2955 - accuracy: 0.9220 - val_loss: 1.3262 - val_accuracy: 0.5179\n",
      "Epoch 642/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.3000 - accuracy: 0.9153 - val_loss: 1.3484 - val_accuracy: 0.5230\n",
      "Epoch 643/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2959 - accuracy: 0.9200 - val_loss: 1.3523 - val_accuracy: 0.5230\n",
      "Epoch 644/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2944 - accuracy: 0.9200 - val_loss: 1.3768 - val_accuracy: 0.5051\n",
      "Epoch 645/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2900 - accuracy: 0.9234 - val_loss: 1.3388 - val_accuracy: 0.5128\n",
      "Epoch 646/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2937 - accuracy: 0.9180 - val_loss: 1.3414 - val_accuracy: 0.5102\n",
      "Epoch 647/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2867 - accuracy: 0.9335 - val_loss: 1.3744 - val_accuracy: 0.4923\n",
      "Epoch 648/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2828 - accuracy: 0.9200 - val_loss: 1.4142 - val_accuracy: 0.5000\n",
      "Epoch 649/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2819 - accuracy: 0.9308 - val_loss: 1.3987 - val_accuracy: 0.4847\n",
      "Epoch 650/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2815 - accuracy: 0.9274 - val_loss: 1.3859 - val_accuracy: 0.4949\n",
      "Epoch 651/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2821 - accuracy: 0.9315 - val_loss: 1.3356 - val_accuracy: 0.5281\n",
      "Epoch 652/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2754 - accuracy: 0.9308 - val_loss: 1.3858 - val_accuracy: 0.5000\n",
      "Epoch 653/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2793 - accuracy: 0.9294 - val_loss: 1.3633 - val_accuracy: 0.4872\n",
      "Epoch 654/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2785 - accuracy: 0.9294 - val_loss: 1.4121 - val_accuracy: 0.5000\n",
      "Epoch 655/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2774 - accuracy: 0.9315 - val_loss: 1.3837 - val_accuracy: 0.5051\n",
      "Epoch 656/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2764 - accuracy: 0.9335 - val_loss: 1.3951 - val_accuracy: 0.5153\n",
      "Epoch 657/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2723 - accuracy: 0.9315 - val_loss: 1.3441 - val_accuracy: 0.5281\n",
      "Epoch 658/700\n",
      "93/93 [==============================] - 3s 29ms/step - loss: 0.2727 - accuracy: 0.9267 - val_loss: 1.3483 - val_accuracy: 0.5128\n",
      "Epoch 659/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2750 - accuracy: 0.9241 - val_loss: 1.3521 - val_accuracy: 0.5102\n",
      "Epoch 660/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2735 - accuracy: 0.9281 - val_loss: 1.3756 - val_accuracy: 0.5153\n",
      "Epoch 661/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2725 - accuracy: 0.9288 - val_loss: 1.3644 - val_accuracy: 0.5128\n",
      "Epoch 662/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2682 - accuracy: 0.9375 - val_loss: 1.4049 - val_accuracy: 0.4923\n",
      "Epoch 663/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2696 - accuracy: 0.9328 - val_loss: 1.4114 - val_accuracy: 0.4949\n",
      "Epoch 664/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2655 - accuracy: 0.9375 - val_loss: 1.3643 - val_accuracy: 0.5204\n",
      "Epoch 665/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2600 - accuracy: 0.9442 - val_loss: 1.4025 - val_accuracy: 0.5153\n",
      "Epoch 666/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2631 - accuracy: 0.9388 - val_loss: 1.3768 - val_accuracy: 0.4974\n",
      "Epoch 667/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2634 - accuracy: 0.9348 - val_loss: 1.4041 - val_accuracy: 0.5153\n",
      "Epoch 668/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2627 - accuracy: 0.9274 - val_loss: 1.4086 - val_accuracy: 0.5179\n",
      "Epoch 669/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2605 - accuracy: 0.9301 - val_loss: 1.3647 - val_accuracy: 0.5306\n",
      "Epoch 670/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2634 - accuracy: 0.9301 - val_loss: 1.3748 - val_accuracy: 0.5204\n",
      "Epoch 671/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2546 - accuracy: 0.9382 - val_loss: 1.3789 - val_accuracy: 0.5153\n",
      "Epoch 672/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2563 - accuracy: 0.9368 - val_loss: 1.4793 - val_accuracy: 0.4847\n",
      "Epoch 673/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2528 - accuracy: 0.9382 - val_loss: 1.4265 - val_accuracy: 0.5128\n",
      "Epoch 674/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2492 - accuracy: 0.9395 - val_loss: 1.3710 - val_accuracy: 0.5128\n",
      "Epoch 675/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2555 - accuracy: 0.9288 - val_loss: 1.3757 - val_accuracy: 0.5102\n",
      "Epoch 676/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2532 - accuracy: 0.9328 - val_loss: 1.3767 - val_accuracy: 0.5204\n",
      "Epoch 677/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2472 - accuracy: 0.9382 - val_loss: 1.4086 - val_accuracy: 0.5204\n",
      "Epoch 678/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2464 - accuracy: 0.9402 - val_loss: 1.3941 - val_accuracy: 0.5077\n",
      "Epoch 679/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2457 - accuracy: 0.9422 - val_loss: 1.3781 - val_accuracy: 0.5077\n",
      "Epoch 680/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2441 - accuracy: 0.9395 - val_loss: 1.4001 - val_accuracy: 0.5255\n",
      "Epoch 681/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2395 - accuracy: 0.9388 - val_loss: 1.3777 - val_accuracy: 0.5153\n",
      "Epoch 682/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2456 - accuracy: 0.9409 - val_loss: 1.3801 - val_accuracy: 0.5179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2398 - accuracy: 0.9409 - val_loss: 1.4006 - val_accuracy: 0.5153\n",
      "Epoch 684/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2438 - accuracy: 0.9415 - val_loss: 1.4161 - val_accuracy: 0.5255\n",
      "Epoch 685/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2400 - accuracy: 0.9462 - val_loss: 1.3817 - val_accuracy: 0.5153\n",
      "Epoch 686/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2375 - accuracy: 0.9422 - val_loss: 1.4672 - val_accuracy: 0.5128\n",
      "Epoch 687/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2410 - accuracy: 0.9422 - val_loss: 1.4750 - val_accuracy: 0.5077\n",
      "Epoch 688/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2375 - accuracy: 0.9422 - val_loss: 1.4331 - val_accuracy: 0.5128\n",
      "Epoch 689/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2304 - accuracy: 0.9483 - val_loss: 1.4062 - val_accuracy: 0.5153\n",
      "Epoch 690/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2371 - accuracy: 0.9456 - val_loss: 1.4108 - val_accuracy: 0.5153\n",
      "Epoch 691/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2317 - accuracy: 0.9489 - val_loss: 1.4261 - val_accuracy: 0.5051\n",
      "Epoch 692/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2300 - accuracy: 0.9496 - val_loss: 1.4145 - val_accuracy: 0.5204\n",
      "Epoch 693/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2374 - accuracy: 0.9456 - val_loss: 1.4194 - val_accuracy: 0.5128\n",
      "Epoch 694/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2270 - accuracy: 0.9456 - val_loss: 1.4554 - val_accuracy: 0.5153\n",
      "Epoch 695/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2300 - accuracy: 0.9449 - val_loss: 1.4158 - val_accuracy: 0.5026\n",
      "Epoch 696/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2240 - accuracy: 0.9469 - val_loss: 1.4264 - val_accuracy: 0.5153\n",
      "Epoch 697/700\n",
      "93/93 [==============================] - 2s 27ms/step - loss: 0.2301 - accuracy: 0.9435 - val_loss: 1.4317 - val_accuracy: 0.5026\n",
      "Epoch 698/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2262 - accuracy: 0.9523 - val_loss: 1.4248 - val_accuracy: 0.4974\n",
      "Epoch 699/700\n",
      "93/93 [==============================] - 3s 28ms/step - loss: 0.2256 - accuracy: 0.9429 - val_loss: 1.4501 - val_accuracy: 0.5051\n",
      "Epoch 700/700\n",
      "93/93 [==============================] - 3s 27ms/step - loss: 0.2270 - accuracy: 0.9469 - val_loss: 1.4526 - val_accuracy: 0.5153\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUZfbA8e9JISEkJJAA0kIAAem9F1GRZhcWBbGtirqu5efqWnbt7lrXtS827GIB7IqK0hSkg/TeQksoIQkh/f398c5kJpNJATKZSeZ8nifPzNx7584ZSO65bxdjDEoppYJXiL8DUEop5V+aCJRSKshpIlBKqSCniUAppYKcJgKllApymgiUUirIaSJQqoJE5B0RebyCx+4QkWGneh6lqoImAqWUCnKaCJRSKshpIlA1iqNK5m4R+UNEjonIWyLSSES+F5EMEZklIvXcjr9QRNaKSJqIzBGR9m77uovIcsf7PgEiPT7rfBFZ6XjvAhHpcpIx3yAiW0TksIh8JSJNHNtFRP4rIikictTxnTo59o0WkXWO2PaIyF0n9Q+mFJoIVM00BjgXaAtcAHwP3A8kYH/nbwMQkbbAVOAOoAHwHfC1iNQSkVrAF8D7QH3gM8d5cby3BzAFuBGIB14DvhKRiBMJVETOBp4AxgGNgZ3Ax47dw4Ehju8RB1wGHHLsewu40RgTA3QCfjmRz1XKnSYCVRO9ZIw5YIzZA8wHFhljVhhjcoDPge6O4y4DvjXG/GSMyQOeBWoDA4B+QDjwvDEmzxgzDVji9hk3AK8ZYxYZYwqMMe8COY73nYgrgCnGmOWO+O4D+otIEpAHxABnAGKMWW+M2ed4Xx7QQUTqGmOOGGOWn+DnKlVEE4GqiQ64PT/u5XW043kT7B04AMaYQmA30NSxb48pPivjTrfnLYC/OaqF0kQkDWjueN+J8IwhE3vX39QY8wvwMvAKcEBEXheRuo5DxwCjgZ0iMldE+p/g5ypVRBOBCmZ7sRd0wNbJYy/me4B9QFPHNqdEt+e7gX8ZY+LcfqKMMVNPMYY62KqmPQDGmBeNMT2Bjtgqorsd25cYYy4CGmKrsD49wc9VqogmAhXMPgXOE5FzRCQc+Bu2emcBsBDIB24TkTARuRTo4/beN4CbRKSvo1G3joicJyIxJxjDR8C1ItLN0b7wb2xV1g4R6e04fzhwDMgGChxtGFeISKyjSisdKDiFfwcV5DQRqKBljNkITAReAg5iG5YvMMbkGmNygUuBa4Aj2PaEGW7vXYptJ3jZsX+L49gTjeFn4AFgOrYU0hq43LG7LjbhHMFWHx3CtmMAXAnsEJF04CbH91DqpIguTKOUUsFNSwRKKRXkfJYIRGSKYyDMmlL2x4rI1yKyyjGg51pfxaKUUqp0viwRvAOMLGP/LcA6Y0xXYCjwH8cgHqWUUlXIZ4nAGDMPOFzWIUCMo3tetOPYfF/Fo5RSyrswP372y8BX2H7UMcBljgE9ZUpISDBJSUk+Dk0ppWqWZcuWHTTGNPC2z5+JYASwEjgb22XuJxGZb4xJ9zxQRCYBkwASExNZunRplQaqlFLVnYjsLG2fP3sNXQvMMNYWYDt2TpUSjDGvG2N6GWN6NWjgNaEppZQ6Sf5MBLuAcwBEpBHQDtjmx3iUUioo+axqSESmYnsDJYhIMvAQdjZHjDGTgceAd0RkNSDAPcaYg76KRymllHc+SwTGmPHl7N+LnW/9lOXl5ZGcnEx2dnZlnC6gRUZG0qxZM8LDw/0dilKqhvBnY3GlSU5OJiYmhqSkJIpPFlmzGGM4dOgQycnJtGzZ0t/hKKVqiBoxxUR2djbx8fE1OgkAiAjx8fFBUfJRSlWdGpEIgBqfBJyC5XsqpapOjUkE5cnOK2D/0WzyC8ods6aUUkElaBJBTl4BKRnZ5BdW/rTbaWlpvPrqqyf8vtGjR5OWllbp8Sil1IkImkTgrFLxxfoLpSWCgoKyF4367rvviIuLq/R4lFLqRNSIXkMV4qha90GBgHvvvZetW7fSrVs3wsPDiY6OpnHjxqxcuZJ169Zx8cUXs3v3brKzs7n99tuZNGkSAElJSSxdupTMzExGjRrFoEGDWLBgAU2bNuXLL7+kdu3alR+sUkp5qHGJ4JGv17Jub4npiigoNGTnFRBZK5TQE2xw7dCkLg9d0LHU/U8++SRr1qxh5cqVzJkzh/POO481a9YUdfGcMmUK9evX5/jx4/Tu3ZsxY8YQHx9f7BybN29m6tSpvPHGG4wbN47p06czcaKuPqiU8r0alwhKU3TtNxSVDnylT58+xfr5v/jii3z++ecA7N69m82bN5dIBC1btqRbt24A9OzZkx07dvg2SKWUcqhxiaC0O/esnHy2pGaSlFCHupG+HZVbp06doudz5sxh1qxZLFy4kKioKIYOHep1HEBERETR89DQUI4fP+7TGJVSyimIGovtow/aiomJiSEjI8PrvqNHj1KvXj2ioqLYsGEDv//+e+UHoJRSp6DGlQhKIz7MBPHx8QwcOJBOnTpRu3ZtGjVqVLRv5MiRTJ48mS5dutCuXTv69etX6Z+vlFKnQnzRndKXevXqZTwXplm/fj3t27cv8305eQVsPJBBYv0o4qKq99LIFfm+SinlTkSWGWN6edsXdFVDvug+qpRS1VnwJAJHVyGDZgKllHIXPInAh43FSilVnWkiUEqpIBc8iUCrhpRSyiufJQIRmSIiKSKypoxjhorIShFZKyJzfRWL/Sz7qCUCpZQqzpclgneAkaXtFJE44FXgQmNMR+BPPoyliC8SwclOQw3w/PPPk5WVVckRKaVUxfksERhj5gGHyzhkAjDDGLPLcXyKr2IBO6BMRHxSNaSJQClVnflzZHFbIFxE5gAxwAvGmPe8HSgik4BJAImJiSf9gYJvSgTu01Cfe+65NGzYkE8//ZScnBwuueQSHnnkEY4dO8a4ceNITk6moKCABx54gAMHDrB3717OOussEhISmD17duUHp5RS5fBnIggDegLnALWBhSLyuzFmk+eBxpjXgdfBjiwu86zf3wv7V3vZYTg9Nw8JCYWw0BOL9LTOMOrJUne7T0P9448/Mm3aNBYvXowxhgsvvJB58+aRmppKkyZN+PbbbwE7B1FsbCzPPfccs2fPJiEh4cRiUkqpSuLPXkPJwExjzDFjzEFgHtDVZ59WmE8kOQi+XbP4xx9/5Mcff6R79+706NGDDRs2sHnzZjp37sysWbO45557mD9/PrGxsT6NQymlKsqfJYIvgZdFJAyoBfQF/nvKZy3tzr0gFw6sJSMkgfjTmp/yx5TGGMN9993HjTfeWGLfsmXL+O6777jvvvsYPnw4Dz74oM/iUEqpivJl99GpwEKgnYgki8h1InKTiNwEYIxZD8wE/gAWA28aY0rtanrKQmuRL2GEFmZX+rrF7tNQjxgxgilTppCZmQnAnj17SElJYe/evURFRTFx4kTuuusuli9fXuK9SinlDz4rERhjxlfgmGeAZ3wVQ4nPCwknLD+f3IJCIk60naAM7tNQjxo1igkTJtC/f38AoqOj+eCDD9iyZQt33303ISEhhIeH87///Q+ASZMmMWrUKBo3bqyNxUopvwiaaagBCg5uIy8ni6y4ttSvU32notZpqJVSJ0qnoXYICQ0hUvIoOHbI36EopVTACKpEICF2reLovCMU6sIESikF1KBEUKEqrpjTKJRQwJCZk+/zmHyhulXlKaUCX41IBJGRkRw6dKj8i2RIKBLdkNqSS07W0aoJrhIZYzh06BCRkZH+DkUpVYPUiMXrmzVrRnJyMqmpqeUfbArhaAoZHONgXLzvg6tkkZGRNGvWzN9hKKVqkBqRCMLDw2nZsmWFj898ehxzMpoRe8s02p0W48PIlFIq8NWIqqETFdakK11lK7M3pkBBnr/DUUopvwrKRBDZ5kyah6Typ7nD4bEEWD3N3yEppZTfBGUioMPFAMQXHrSvt/t0cTSllCouYz88HAvb5pTcd2QnJC8tud2HgjMRxDRi+2Vu0zlEN/JfLEqp4LNnmX1c6GVBqxe6wJvnVGk4wZkIgJbt3Ga8Pp7mv0CUUsEnNMI+FuQU3+5+LarCMUNBmwgICeXtwXM5YOJgyRuQn1P+e5RS1VtBXpVeYEsV6uiwmZ9bfHvuMdfzvCzbfvnlLTbm316AA2t9Ek7wJgKgX4dWNBJHBl7udZVMpVRNYYztHPL93/0diau3omeJIO+46/mxgzD9OljxAayZDj89CCs+9Ek4QZ0IztAxBEoFj8IC+7j4df/GAa4LvmeJIC/L9TzLbXLMnQtAQmD4Yz4JJ6gTgYhwtHYiADnLPoK3RgRGsVEpVfk87779yVkVXVaJwD0RLH0LIupCSOWto+IuqBMBQMaf5wAQcWA57P4dcnS1MKVqpILc8o+pKvnOEkF28e3uJYIPxxbfl+27Ti2+XKpyioikiEiZy0+KSG8RKRCRsWUd5yvNGnjMN5SlaxUoVSNV1iwChYX2x5u03a4xALnHXNVRzvc5OUsEnlVD854t/XOv8N3AV1+WCN4BRpZ1gIiEAk8BP/gwjnIdq5XgepF12H+BKKV8p6hEIKd2nhk3wBOlTPz41rl2DEBBPvy7CXx3l91+ZCc8Wg/WfwNzn4bNPzpiyoG5z8Ce5TZx7Py15Dnrt4Ib50Gbc08t7jL4LBEYY+YB5V1VbwWmAym+iqMi0sbNcL1482z/BaKU8p3K6CJuDKyZBnnHvLcnZuyzj7t/t49Lp9hHZ6/ET66A2f9yJYLsozD7cXjjLNs91KlBe4iMgwcOwm0roLHbuCcf8NvsoyLSFLgEOBvoXc6xk4BJAImJiZUeS9NWnSv9nEqpAFMZVUPubYi5xyAiGjJTICoBQkIgIhZyjsLG713H7V0JWQe9n8+4VRfNfcr1/MrPIao+hIafeswV4M/G4ueBe4wxBeUdaIx53RjTyxjTq0GDBpUfSUgI07u84Xqdm1X6sUqp6slZNSQVrBo6shNeGwJH97i2uTfYZqdB+j54tg3Me8ZuC3OMGF74suu4xW/YMQEnIrKu61xVwJ+JoBfwsYjsAMYCr4rIxf4Kpk2f4byU7/j4d0ZDXnbZb1BKBZbMlOIXbU8nWiKY9wzsWwXrv3Ztyz5a/PkaRwPuui9s9Y+3O/+Y02DTCTaDhtU+seNPkd8SgTGmpTEmyRiTBEwD/mKM+cJf8XRqEsuReo4qor0r4I+P/RWKUgrg8HZY8HL5xzk92wb+26H0/UV99itYIji4yT7OvMfOFgrF5wLKTIEf/2mfp6yDr24tXtXjNP9ZKCwnCTXqDJGxMO49uOlXW81UhXzWRiAiU4GhQIKIJAMPAeEAxpjJvvrckxUSIlw4sAfMdGz4+nbbtavvJL/GpVTQ+uBSOLwNuk2w9eWn6kSrhtz7+B/aYu/s3auGnDOIeqoVA7lljEdqM9w2Fl8xDVZNhWGPQFzzisXkIz5LBMaY8Sdw7DW+iuNEdOw9lAu/fZp3ol6gfs4e25qviUAp/3BWwxTmV875Klo1tPF7iG5YvFfQtrl2Arj6rVzbdsz3/v7oBnDYkQgS2rpKFqOegdpx0LyvTQSnD/Npl9ATUSPWLK4s4aEh1G7Whfz9jiJkZJx/A1IqqDnu3N2nXQD4/h6okwBD7i777R9fAbXrwUWO6qV8j6qhw9tg1yLo5nbPemgrTL3cPo91u0uf97R9jGni2uZtURmw65sc3gYXvAhznrDbOlxc/Kayzw1lx17Fgn6KCU8jO53GrgJHMTSyrn+DUSqYOatwPKdhWDQZfnm8/Pdv+AZWvO967Vk1NGUUfHGT7SW44ze7ba3bmKKju0ueM2OvfYxpbB9Da5U8po6zZ6OB+NPt03MeLD9eP9JE4OG8Lo25Ne82+yI0wk7/WlhuD1elVKVzlgjK6c5d0b9Pz6qhTEcD8Pd/tz0Fp99QsQQDULepfWw32rWteT/oNAaadLevYxrD2LfhjjUQ37pi5/UTrRry0DAmkp6dOzJzQ19G7lkE0/4Mw3bBoP/zd2hK+YezrryijayVxfl5ZXXlXvcVfHqlHX3rZIz3WEubdG7zT/Zx9acl98W1gLSdJbd3nwi1ouCs+23XUYDrHF1ECwvgtM62DaCq/81OkpYIvLhhcCsOFka7Nrj3AV4zHVLWV31QSvnLI3F2lawq56wacmsj8LyrX/CSfTy42bXN21QSxrhKAJ7dR4u2e9H/ryW3nfVP6HUtXP01NGgHV38Dl7itcRASahuBq0kSAE0EXnVpFsu8uEtcG47ssJNIHdlhSwifTDz5k+9e4rPl5pTymZW+WRmrTJ4lAmNcI3idjmy3j+5LPHq2Kez4DXb86qr2cU7bEFKBCpHTvSwif6ZHI3XLwdD1svLPFcA0EXghIvxp9HDXhox9dqKorbPta/fubFt+tkvIVdRbw+B/AyonUKV8rbKmbva06hPXIC1vcrNcE7il7YJPr4Jdvxefj6cgH46l2ufu08dvmQWzn3C9fmc0vHu+63VouO2a6tm2MOatknHEt4YHDsG490vuq0E0EZRiWPuGfBQ1kc0hLe2GJW/CN3fY50d2wJwnbRH0g0uLzxroTd5xWxJQqrpxv9OuLJmp8Pkk273T3drP4eFYO6f/c+1d22f/C9Z9aXsLufv1ObdzHnA9n34dzH3S+2cPvAOOH4FFrwEGOl5qt3e8BDqXsiRKaBh0uNBOBX1jKWMHqjlNBKUQEfIG3c25Wf9iY/NxkJNe/IA5T9hfTqffXrC/yN58c6ctCaRs8F3Ap+rAWjtPui7VGfiy0+2C5pX5f2UMfPd3O7eOu/J67FTE4jdso66Ts1vmnqW2RO30+//s4x+fFB/B66zz3+vWIAw2QRSds4w5htwNvL34e/veaB+7XeH9eHeNu0LjLhX7nGpGE0EZLu3RlB6JcfxlW3/y41qWPGCG2wCRnx6Ez66xf6SenHOTp3hpG9i3Cr67++T+qBe9Dl/fceLvc/r8JtjwrX3+9ij7x1EZf/jKytgPycsgfW/lJtlv/s823pY2xcHJOJYKi1+DD8YU3+4+mMtzVa6M/bax1vm9lr1jB1m9NcIOzHL67i7bs8fJvX/+B4478ml/ht2L7PMjO4p/jrO3j7feO2Dr+v/4pJQv5sFzqorEfnbOf+cI3363QI+roesEmOClF1ENpd1HyxATGc5jF3fivBfTuDj0Jb66sy0hISG2qPhUEuDlD/vJ5vDnHyB1g52v6KJX7ChD8N5I/NoQ+3jmPfbOJ7x2xedV+d7RaHXB8yf61ew8Squm2p+Hj7qG82enQ606J34+VdLU8bB3OTTsaG8CzjgfGpUxKVpFpTsGNXmOuAVblSOhEB55YufMzXQ88ejp4l41lHcMImJcr2dMgu1z7R1/57Ew/z+ufXOegDFv2qTgZIz9nJ8eKvn5a6a7npf4O/H4O+t9va2qdWrYAfb/Udo3Kykk3E4Cd/5/7Wv3Of9H/rvi56lBNBGUo0PjunRsUpc1e9I5+7V1TL95APG1y5knfIrbL797t7v9q4sf536HeDwNXu5ph8Tfs+OU4y4hfS/UdRsef/yI9ziyj0LdxuWfb+8K29jWrJd9nZ8DuxZCq6GVEW3NcGiLfXSWBKWyCuDOfv1ezvfvJnZ+m79WsE0q67CdSsV5I+C5EIp7CTHXIxE4q0vTdhZPAuBqiHWWhsF2Q+06wdXTB+zvu2dJo7xedef9p3giiPCYAaBJd1c1Ur0kaH22He3bqKPddvtK2xMp4fSyPyeIaNVQOUSEb24dxMiOp7HjUBYfLdp18idzLk8X4vhjc78YO5+7b6sob1UOm2fBxpnwXAeY9bBtfHP/Yz3utoqo+2e6z7delteH2rVZnX64H967yP4R719d9h9zQT68NdzVC6s0x9MqZ3nBitq/2rUo0fEjkLrx1M7n2Y8838sd/Mko+v8uparJOclZeTJT4emWtmHV+f/u2aXSvUSQk+l6np1e9gJOW2bB5EElt+9b6Xo+6P/s//Gj9YofU5BjV/oa72Uq+Pv3Fn/dfaJrps9Rz8BdW2z//nMcpY6+N9s7/7Puhw4X2W2xzTQJeNBEUAEiwuQrezKgdTwvz95C8pEsW3849u2SB1ekb7IpgO3zYeErrm2H3epUvV3YD6wr3t3u58dczz+eUPwP9uBm+HAMTL0M0vfAr44i8M+P2sddi+xc6k7u561oIvC0f419PJ5mLwBldZHN3G/rgz+/qexzPtWiZJ21Nwtetr1NKpo0jh20Y0HcE+CxQzbub++0r985H17pU7wx05jidd/l8fy3PJpc/ntyj9nvsnJq6cc457wv6/s+HOv6PcrJgI8us/P7A6z8yP7uPeu4GP7xqV2NC2yJYNHr9v05GcUnVnOfWvk/7eBgGYkyJ71kCRhc1aTgmNSxlGQWXhvajSq+rVEnV7Xlec/ZZHHBS64EldjXzvwZEQMDboORT0LPa0qPURXRRHACnhrThbyCQm6duoKvjneGTpfaRSTANfdI25Hln8gU2n7N8591bdsyy/V8wzfFe1kA/K8//LeT67X7ezd+Bxu+c7327OHkbtfvMGU4vHeha5uzvzYUbys4oTmWHH/QFZkyuKhvehmNp86LWGlT/bpzlnSOH7HVDE8l2Xrr0ix4ya46tXQK7Fluq0ecF6h9f9iL/QFHYnM2ZoLtcvhSD7sGbXm83S1/MrFkkk/bZWOe9QgsecvVDfKnB+zNwqPx9qL8cKxr9GxRIvAYOOXZ59+5POLW2bBpJsy8177+4mZbgit6Xy587ZhfKyTc9bt1LBUWvOg6bvEb9qaisODEOxW0GFgy5tpeZvc98x77ePow+3jzAte+G9xKkL2vg/t22QVczjjPbotzW888NAz63XzibSVBStsITkDz+lHcP7o9j3+7nhW7VrBubzp3De9I2AMHAbF1wgfW2As52LpL50XZs4HL0+rPXM+dI5dvXmB7YqQ6up0W5tk/Rm9T2KbtsHdg2eklLxDu3O9wi97r1hvjh/vtXOzvXQi9roPznyt5vLvt82xMzh4f7kmosND7SkvO0ovzonhwC6Q6pu1od559j2dvlfxs2PqzvaB4NqY768pf7Q83/GITwsx7Xf9OKRvsPPJhjpkinaW2zBR44yyoXR9GOgYgpay1F3tvnPXdh7ZAk24l9+fn2KRaWADvlbLqak66XYlq+fv292TTTDuQydkn3nnhO3YQlr3tMXhxFiS0oSiB5nlMveA5W+baGbZdyNljJ+uQ99JmulvXy9AwVzJK8zifc3Rx8lLv3600kXFw9gPwtsdNUmRs8dd/XWq/X6uzbFdNsPX6d6y2/w5hXmb6BFsNNOBW296gToomghN0/eBW9G8dz3kv/srkuVuZPHcrP/3fENo0ioGGZ9i5R8Kj7C9y7TjbgLpmBgx7GLpfaYvhv7/i/eQ9rrLrnjp5q1757i5I8lL3unclLHsPju6C1l6GxTtt/K7465gmtjui07EUV2lh6VveE8Ect9Gd715QfJ/7Un7pyVAr2l64N/9k20hGP+O6m8xJt9UVL/d0vWfQnXYFJ/eG7TfPsb1vAPr9xXXRdnImguOHXXXQdZvYC3LGPni1r/23Pf8FW2/vbBAtWn7wsKtqxJspI+3/o5O3kpIxtj0m66Cde/5oKW1JR/fYZP2V2xw2069zPS+q3ze2RODOmRScF3Nn1dCKD2HR/1xVMf3+Ar+/amfVdJe8pPw5g9yrc5y/B90mwsoPXNudNzrlSRpsL+xDSukendgf2o6Cpj2h7XBHkgNa9C9+nPudvjehYfbmRZ00n1UNicgUEUkRkTWl7L9CRP5w/CwQka6+iqWydWwSy+L7z6FdI9uD4tz/znM1IovAGaMhtqmtzzx9GFz8qq23bNLNTlbV/kK43W3gzlVf2UmrhldwCtxX+5Xctm+Va/KsrY67/gG3ljzugNt/x/DHbY8KpxFPlDzeOSI6Y78dCbr8PZhTRhc79wm83hphGyNzMuDDsbD4dcg44OqqmJ8NL3rcWf/6nL1z/OJm1zZnEnB+zyM77OCnHEedtXvvGWcDdJ2G8OGf4L+OniLL37NtDp9d4yoRuDeYu9dde3JPAlD8gpyfYx9/fc61cLlzNkpv/te/eK8yT59d43p+LKX4vuNHbF2/c9DXvpX2+375l+IX8KRB9g7cm9LmDIqMLb1XU5340uMtS6cxtqG2bhP709Gtmq12fbv044SP7dw9javNn3+NJMZHI0lFZAiQCbxnjOnkZf8AYL0x5oiIjAIeNsb0Le+8vXr1MkuXnmDR1EfyCwp59Jt1vLfQdTe56sHhxEaFl/EuNzsX2D7fiW5fe8102/1t8hDbOFcrxlYJNekO46fa6iXn5FnX/2JHLHca46paqtfS1T3vn6m2OP2wowgeHlW8bvfSN201h3M4/lVf2dWZPOt/b1lst5d1sXTqfmXxxUDAztPu3o1w2MO2J9PJkBC71N+uhZDQDgbfCZ/f6Nof08QuHpJQRmNmj6th+bvFtzn7+ldEs972IpbQ1rZPjPh38Tp3f7v6a2g5xLYpeVtcxZtOY2wX410LbUeIj8a59l0+FT4uY+VZz/9fp5sXuLpsOuUes6WemMb231BVGRFZZozp5XWfrxKB44OTgG+8JQKP4+oBa4wxTcs7ZyAlArDJYHNKJqNesMX4rs3jOLtdQ64f3JI6EadQ85aTaS96taJK7pv7jC0uO2c8LMiDXx6zdcBD/g6vDbZ3yw85esV8d7etFohuZOuk6zSwDYETp9vG0Z8fscddO9N+3k8PwbbZ0OVy+MNLFz5vWg6x7QVNehS/g3cX29xemEq76EbEQs5J9lry5Jn03DXv62rT8LWwyOJtNiFhxev9oxJcJYlTNeRu+3tzzgO2NLp6mq1KdPaOGvs2TLvW+3vPvNdOt5B12FazPOlYprHvzTDqSdu4Xtqsuw8esaWgGTfY73bBC3buHs82AOVXZSWCQGkjuA743t9BnIyw0BDaN67L7LuGctazc1i1O41Vu9NYvSeNF8d3J6rWSf4TR0SXvs9zGtzQcDj3UdfruzYXn41xtGPq3uyjsHuxrTpY9bFtlMtwNAyGRkDzPnYu9Ykz7FwvkbG2wbEg1yYY57qtl0vOWOoAACAASURBVL5h/+i7ToBmPW2dflwiTJ0AG7/1HvPp58IVn9lBRaXdebcd4X1xEHeD77JdHwvzSu+hVNpiIk4VTQINO9qGa2/dID0v4C2H2HlsPLu7RsS4EkG9ljBpjq2iArjkNVeXXoCu4+1I77IMuhN+e97Vc8hdm+H2/9Cp81jbd37PcltK7HSp7UO/ezG0vwDWTIMBt8Pyd2w7QHikbc9xH+DlXGLRfSAZ2P/7rb9A18vtv1GnS20D9/d/h+5Xee8koAKW30sEInIW8CowyBhzqJRjJgGTABITE3vu3FnGH7kfpWXl8uLPW5jym62aiYsK58p+Lbjz3LZIoC5SUVhg52np/KeSo0rBDgyb9wxc+BI80cxue+CQ7WLY98biPTW2zbXtCD2utAN9Vk2FTmNtUkkcYKupfn6seNfXv2+3CWfdF7bh8N+ljGoecKu9ULpXNayZbueoAWhwhqt31SWv29ktK+rG+bYU5RTT2DYyR8baC+8sL1MiTPjM1nv/+pyN45LX7Lw1L7jVdQ+937aLZB207TE9r7EX1IdjbWKcOM1epN84yx7vLRH8+UdbHehMkHeshqh4O4LY0727K2+d7cPb7b+Ds/ulMfbC3+AMO+ArNtHeNATq77UqIWCrhkSkC/A5MMoYU6HhkIFWNeTNqt1p/O2zVWxJsY2i1w5M4oHzOhASUs3/aNJ22z/+ul4uQk6FBfaYsnx+k73g/TMFwjym61j5kb147l0Bp3Vx3I0b78eCnYXzy1vgmu9g1wI4vAMufNG+P/uoaxzA+I/t+993LDjkXnX0jwPwr0auc55xvr3ojfiXTQbT/uxqe3ByXnTT99nJ39qNtiWUKSNs1YyzEf6nh+wd/HU/ue7Ws49CWG1Xd8iXe9t688F32STZvK9NvEunwLmP2eOyj9pE28HRk+f5LrbUM+49u4B6yyE6R5QqU0AmAhFJBH4BrjLGLPDcX5rqkAgA9h09zmdLk/l61V42OxLCP89rz/WDW/k5sgBQWGh7DpV195p91Dak56Tbfu3OBcE9GePqm+/NS71s9cWQu+zrQ1ttKef0YbYBfPtcO+nejt9sY+mM623vqf5/scfnHYd/nWb7qjdoZ5NJkx4VnxjQGJsomvYs/e75+BE7piGuhe0JlOilV5invOM2MTdoW7E4VNDzSyIQkanAUCABOAA8BIQDGGMmi8ibwBjAWc+TX1qQ7qpLInA6mJlDr8ddo4aHtmvAnee2pXPT2MCtLgoWuVm22sa9n/relbYk4l7HXZFSjlIBzm8lAl+obokAwBjDFyv38H+fFF/04/UrezK8o3ahU0r5niaCAFFYaNiamsknS3bz5q+2QfnKfi04v0tj+rY6yUE7SilVAZoIAtDuw1lc+86Sogblp8d2oWOTunRson2vlVKVTxNBgMrOK2DOxlRu+sC15OAzY7twZrsGNIzRWROVUpVHE0GAW77rCIcyc3nup02s32dn76wXFc7LE3owoHW8NiorpU6ZJoJq4nhuAU98v77Y3EXdmscxpE0CZ7dvRLfmXuZvV0qpCtBEUM1k5xVwz/Q/+HLlXhrHRrLvqJ2i4O4R7fhTr2ZabaSUOmGaCKqx7LwC3py/jednbSa/0NA4NpInLu1MUnwdkhJ0JKlSqmI0EdQAOw4e45Gv1zJ7Y2rRtu6JcTx5aRfanRZTxjuVUkoTQY3y3sIdzFi+h5W7XSuBdWpal/tHt2dA6wT/BaaUCmiaCGqgpTsOM3aya+WsWqEh3HbO6Vw3qBW1a+l0CEqp4jQR1FBbUjJZuTuNZvVq89Ivm/ltyyGaxtVm0pBWtIiPYkDrBGqF6bzwSilNBEHj+VmbeH7W5qLXbRtFM6x9I64b1JL4aC9TOCulgoYmgiCSlpXLVVMWk51XQH6hYVvqMQAGt0mgU9NYbj379JNfNU0pVW1pIghiL/68med+cq35M6B1PMPaN2JY+0YkxntZD1kpVSNpIghya/YcJSYyjE+W7GbasmRSMnKK9r1zbW8Gnp5AeKi2JShVk2kiUEXyCwqZtiyZB75cQ16B6/9eV09TqmYrKxFoZXGQCQsN4fI+iVzcvSkXvvwrmw7YabAf/3Y9+49mkxgfxejOjUnQxmWlgoaWCIJYakYOX6/aiwi88PNm0rLyivbdOKQVF3dvSvvGZawrrJSqNsoqEVSoYlhEbheRumK9JSLLRWR4Oe+ZIiIpIrKmlP0iIi+KyBYR+UNEelQkFlV5GsRE8OdBLbl2YEt+/L8hjO/jWrv3tXnbGPXCfGatO+DHCJVSVaFCJQIRWWWM6SoiI4BbgAeAt40xpV68RWQIkAm8Z4zp5GX/aOBWYDTQF3jBGNO3vFi0ROB7hYWGdxfu4JkfNpKVW0DdyDCGdWhEv5bxXNitCZHhOnJZqeqmMtoInCujjMYmgFVSzmopxph5IpJUxiEXYZOEAX4XkTgRaWyM2VfBmJSPhIQI1w5syUXdmvLewh2s35fOjOV7mLF8D58t202tsBAePL+jTnanVA1R0USwTER+BFoC94lIDFB4ip/dFNjt9jrZsa1EIhCRScAkgMTERM/dykfq16nFHcPaArYL6vOzNjNrva0qGvH8PG4e2pp7Rp7hzxCVUpWgop3HrwPuBXobY7KAcODaU/xsbyUKr/VUxpjXjTG9jDG9GjRocIofq05Gp6axvHl1L1Y9OJxxvZoRGiL8b85WBj75C//4fDXZeQX+DlEpdZIqWiLoD6w0xhwTkYlAD+CFU/zsZKC52+tmwN5TPKfysdiocJ4e25XHLu7Esz9s5I352/lw0S7Ss/MZ27MZx3MLiIsKp2/L+rrWslLVREUbi/8AugJdgPeBt4BLjTFnlvO+JOCbUhqLzwP+iqux+EVjTJ/yYtHG4sByPLeAx75dx0eLdhXbfstZrblreDtNBkoFiFMeWSwiy40xPUTkQWCPMeYt57Yy3jMVGAokAAeAh7BVShhjJjsam18GRgJZwLXGmHKv8JoIAo8xhl2Hs1i07TB/n/5H0fbBbRK4dmASnZrE0rCurrOslD9VRiKYC8wE/gwMBlKxVUWdKzPQitBEENiy8wo4nlvAlyv38J8fN5GRkw/A85d14+LuTf0cnVLBqzISwWnABGCJMWa+iCQCQ40x71VuqOXTRFB9HM8t4L2FO3ji+w0AjO3ZjJ4t6nFh1ybUidDZTZSqSpUy6ZyINAJ6O14uNsakVFJ8J0QTQfWzZs9RHv92HSt2pZGTX0hoiNA0rjY9EuO4/7z21I0M10FqSvlYZZQIxgHPAHOw3T4HA3cbY6ZVYpwVoomg+jqQns3MNfuZ8tt2dh7KKtp+QdcmPDO2CwWFRksKSvlIZSSCVcC5zlKAiDQAZhljulZqpBWgiaD6M8Ywd1Mq363ex6dLkwGIjggjOiKMT27sR4v4On6OUKma55QnnQNCPKqCDp3Ae5UqRkQY2q4hT4/tyuqHh3Ne58Y0qhvB/vRsJryxiKNus6AqpXyvouXwmSLyAzDV8foy4DvfhKSCSUxkOK9cYXshr9ydxsWv/EbXR3+kd1I9Hji/A52axBISomMRlPKlE2ksHgMMxLYRzDPGfO7LwEqjVUM122PfrOOtX7cX23Z6w2j+cV57hrZtoAPUlDpJulSlqjaMMSQfOc5fp65g1e60Yvsm9ktkSJsG9G8dT0xkuJ8iVKp6OulEICIZeJ8ITgBjjKny5as0EQQPYwwiQkZ2Hk/P3Mj7v+8s2nf7OW0Y27MZzetH+TFCpaqPk24sNsbEGGPqevmJ8UcSUMHFWQ0UExnOQxd04JoBSdQKCyEiLIQXft7M4Kdn89uWg36OUqnqT6uGVLWTmZPPtW8vZsmOI0Xb2jWK4f3r+9AwRuc0Usqbyug+qlTAiI4I442revHC5d0Ic/Qo2nggg3GTF/L5imQOZub4OUKlqhctEahqLSU9m5SMHO76bBUb9mcUbb92YBIPXdDRj5EpFVi0RKBqrIZ1I+nUNJavbx3EmB7Nira//dsObvlwOev3pXMsJ5/qdsOjVFXSEoGqUdKyctl28BiXvrqg2PaWCXV47899tJeRClo6jkAFnXmbUhGBK99aXLStfp1aDGmTwIS+LejTsr4fo1Oq6mkiUEFrzsYUPl68m6v6t+DRb9axNTWTvALD6Q2juXfkGbRtFENivJYSVM3nt0QgIiOxi9yHAm8aY5702B8LfAAkYuc9etYY83ZZ59REoE7FsZx8/vXd+mJrLD96UUcu6taU2uGh1ArTZjNVM/klEYhIKLAJOBdIBpYA440x69yOuR+INcbc45jaeiNwmjEmt7TzaiJQlWHmmv088f36YusiNI6N5K7h7RjTs1kZ71SqevJXr6E+wBZjzDbHhf1j4CKPYwwQ41jIPho4DOT7MCalABjZ6TTm3n0Wj1zo6mK672g2f/tsFev3pfsxMqWqni+Xg2oK7HZ7nQz09TjmZeArYC8QA1xmjCn0PJGITAImASQmJvokWBWcJvZrQa2wENbtTS+ay2jUC/NJio9iSNsGPHRBR0J1GmxVw/kyEXj76/GshxoBrATOBloDP4nIfGNMsVsyY8zrwOtgq4Z8EKsKUqEhwvg+9ubist7NST6SxdTFu5m7KZUdC3fy3sKd/KlnM/59aWfCQ7X9QNVMvkwEyUBzt9fNsHf+7q4FnjS2oWKLiGwHzgAWo1QV69Q0lk5NYxnZqTGpGTlc9tpCEqIj+GxZMlG1QrlmYEtaJugymqrm8eUtzhKgjYi0FJFawOXYaiB3u4BzAESkEdAO2ObDmJSqkAYxEfxy11CmTupH20bRvLtwJ2f/Zw53frqSzQcyKCzUgqmqOXzdfXQ08Dy2++gUY8y/ROQmAGPMZBFpArwDNMZWJT1pjPmgrHNqryFV1TJz8lm3N51/fL6azSmZRduvGZDEvaPOIDMnn4ToCD9GqFT5dECZUpXgYGYOk+dsZfWeo+w8lMX+9OyifQ+e34EJfROJDA/1Y4RKla6sRODLNgKlapSE6Aj+eX4HAAoKDb0e/4kjWXkAPPrNOvYdPc7wjqfRpVksEWGaEFT1oSUCpU5SYaHhjk9W8tWq4n0gwkKEJf8YRr06tfwUmVIladWQUj5kjOHb1fv460crim0f1ek0nv1TV+pEaMFb+Z9WDSnlQyLC+V2a0LZRDAu2HOSLlXtZuTuN79fs5+f1KUzs14JrBiTp5HYqYOkIGaUqSdtGMVwzsCVPjelC/1bxvDyhO20aRTPlt+0MeWY2z/20yd8hKuWVVg0p5UPGGGatT+GG91y/s+P7JHL/6DOIiQz3Y2Qq2OhSlUr5iYhwbodGPODobQQwdfEuzn/pVw5l5vgxMqVctESgVBVJSc8mPTufDfvT+etHKwgNEWJrhxMiwoMXdODCrk38HaKqwbSxWKkA0LBuJA3rwukNo0mIjuCV2VuYv/kgALdNXcH3q/fx3Lhu1K6lYxBU1dKqIaX8oF+reN6/ri+vXdmTGEf30u/X7Ofs/8zh5/UHKNC5jFQV0qohpfwsv6CQ93/fiQAPf20X8KtTK5SHLujI0HYNaFg30r8BqhpBq4aUCmBhoSFcO7AlAKfF1uamD5ZxLLeAv0//A4CbzmzNlf1b0DSutj/DVDWYlgiUCkDr96UzbvJCMnJcK7fePaIdvZPq0z0xThfJUSdMp5hQqhp7+Ku1vLNgR9Hre0aeQX5BIX1a1qdvq3j/BaaqFa0aUqoai/LoRfTUzA1Fz7+7bTAdmtSt6pBUDaOJQKkA9+dBLUnNyOGBCzpw5FguHy3axWvz7EJ+o1+cT88W9Xjh8m40q6dzGamTo1VDSlVD2XkF/LIhhfmbU5m+fA+1QkN4akwX+rWqT7yulqa88FsbgYiMBF7ALlX5pjHmSS/HDMUuZxkOHDTGnFnWOTURKFXcwq2HuOOTFRxIzyE8VHj84k60iK9DP20/UG78kghEJBTYBJwLJGMXsx9vjFnndkwcsAAYaYzZJSINjTEpZZ1XE4FSJWXnFfDVyr08/u060rNtT6Mz2zbg/tHtaXdajJ+jU4HAX5PO9QG2GGO2GWNygY+BizyOmQDMMMbsAigvCSilvIsMD2Vc7+bM+tuZjO/THIC5m1IZ8fw8rpqymC0pGX6OUAUyXyaCpsBut9fJjm3u2gL1RGSOiCwTkau8nUhEJonIUhFZmpqa6qNwlar+GsZE8u9LOvPKhB7cPLQ1APM2pTLsuXm8/Mtm1uw5yq5DWX6OUgUaX1YN/QkYYYy53vH6SqCPMeZWt2NeBnoB5wC1gYXAecaYUlfw0KohpSruWE4+r83dymvztpGTXwhAdEQYC+87W9dDCDL+qhpKBpq7vW4G7PVyzExjzDFjzEFgHtDVhzEpFVTqRIRx5/B2bHx8FLPuPJNxvZqRmZNP54d/5KWfN1Pdeg0q3/BliSAM21h8DrAH21g8wRiz1u2Y9sDLwAigFrAYuNwYs6a082qJQKlT8+jX65i2bHdRo/LgNgl0ax7HqE6NdXBaDeaXEoExJh/4K/ADsB741BizVkRuEpGbHMesB2YCf2CTwJtlJQGl1Kl78IIOLLp/GM3r20ns5m8+yEu/bOHeGX+QX1BIWlaunyNUVU0HlCkVpAoLDYXGsHj7YeZtPsjkuVsBCBH48pZBdG4W6+cIVWXSuYaUUiWEhAghCANOT6Bvq3hiIsN4c/42jmTlcdMHy+jbqj5/G95Op78OAloiUEoVs2jbIR79Zh1r96YDdrbT2RtTuH90e7o1j/NzdOpk+avXkFKqGurbKp5vbxvM2J7NADvb6eLth3nmhw1sScmkUJfRrHG0RKCU8qqw0LAn7TjPz9rM9OXJRdsjw0O4qGtTzu/amEGnJyAifoxSVZQuTKOUOiUzliczc81++rSszwuzNhdbOU3XRKgeNBEopSrNlpQMrnhzEQfSc4q2PTWmM5f1TvRjVKo8mgiUUpXuvYU7+G71Pn7fdhiAq/u34NIezTiclcuA1vFEhIWWfQJVpTQRKKV8Zv7mVB76ai3bUo8V2/7oRR25qn+Sf4JSJWivIaWUzwxu04Bf/jaUyRN7FNv+0Fdr+XDRTuZs1NnlA52WCJRSlSYnv4A1e44SERbK+S/9WrT9kQs70qFJXXon1fdjdMFNq4aUUlVu9oYU1u1L55kfNhZte3F8dyLCQujYpC7N6kX5Mbrgo1NMKKWq3FlnNGRouwb0axVPo7oR3PLRCm6bugKATk3rcv2gVsRGhXNWu4Z+jlRpiUApVSWycvO5e9offPvHvmLb7x99BjcMbqUD03xMq4aUUgFja2omnyzZzZ6040VJoWOTunxyY3+iI7SSwlc0ESilAlLSvd8WPa8dHkrjuEjevbYPmw5kkF9oGN6hkZYUKokmAqVUQDp6PI+IsBCW7DjMk99vKJrx1Olfl3RiTI9mRIbr4LRTpYlAKVUtLN1xmCveXEROfmHRtgGt4xnfJ5HzOjcmJERLBydLE4FSqtrIzS9k04EMbv5wGbsPHy+2b3CbBK4f3Ioz2zbwU3TVl99GFovISBHZKCJbROTeMo7rLSIFIjLWl/EopQJfrbAQOjWNZfbfhvLFLQOL1lYGu77y1VMW8/q8reQXFOraCJXEZyUCEQkFNgHnAsnAEmC8MWadl+N+ArKBKcaYaWWdV0sESgUXYwy7DmdRJyKMWesOcO+M1QDUjQzDAOd3acI1A5Jod1qMfwMNcP4qEfQBthhjthljcoGPgYu8HHcrMB3QCUmUUiWICC3i65AQHcFlvZsz7ab+XDswCWMgIzufqYt3MeL5ecxcs6/8kymvfJkImgK73V4nO7YVEZGmwCXA5LJOJCKTRGSpiCxNTU2t9ECVUtWDiNArqT4PXdCR1Y+MYMZfBhTtu+mD5Vz++kI+XLSTrNz8Ms6iPPly9Ia35n3PeqjngXuMMQVl9RU2xrwOvA62aqjSIlRKVWs9Euvx/e2DmTx3K8lHjvP7tsP8vu0w//h8DWEhwpRrejNEG5bL5ctEkAw0d3vdDNjrcUwv4GNHEkgARotIvjHmCx/GpZSqQdo3rssLl3cHICUjm437M7j+3aXk5Bdy3btL+OtZbYiPrsXEfi38HGng8mVjcRi2sfgcYA+2sXiCMWZtKce/A3yjjcVKqVOVnVdAakYOl7y6gIOZriU1n7i0M+P7BOeSmn5pLDbG5AN/BX4A1gOfGmPWishNInKTrz5XKaUiw0NpXj+Kb28bxL2jziDGMYfRfTNWk3Tvt5z5zGxSMrL9HGXg0AFlSqkar6DQ8MPa/fzlw+VF2zo0rkujuhH0SqrPLWed7sfoqoauR6CUCmqhIcLozo3Z/sRoth08xju/7eD933eybh/M3phKfoHhxjNbcfR4Ho3qRvo73CqnJQKlVFDafvAYv287xC8bUvhp3YFi+z6e1I++LevXqJlPda4hpZQqhTGGB75cw49rD5CSkVNs35gezbhnZDtW7znKOe0b+SnCyqGJQCmlKmD9vnT2p2ezbm/xtZYBbjmrNbecdTpRtapnjbq2ESilVAW0b1yX9o3rcla7hozsdBpXvrmIg5m55BYU8srsrRhjG57TsvJ4amwXf4dbaTQRKKWUF60bRLPgvnMAmLlmH3d/9gevztlatL9+dC3ObNuAfq3i/RVipdGqIaWUqoC0rFzmbExl39Fsnpq5oWj702O78P3qfdw+rC3dmsf5McKyaRuBUkpVopSMbN6av53X5m0rtj0mIoyF959DdETgVbb4bWEapZSqiRrGRHLf6Pa8fU1vxvdJ5I2relGnVigZOfnc+clKPlq0i/TsPH+HWWFaIlBKqUry5PcbmDzX1Y7QtXkcQ9okkFg/igu6NiEyPNRvsWnVkFJKVZHsvAJum7qCtON5bE3J5NCx3KJ9H1zXl4Gnx/tloJomAqWU8oPDx3LZfCCDLamZ/OPzNcX2PT22C+N6NS/lnZVPE4FSSvnZhv3p3PHxSto0iuHrVa6lWUZ0bMTLE3oQHurbJltNBEopFUAWbz/Mde8uISPbLqk56PQE6tWpRUJ0LW4Y3IqGMRGEVXJi0ESglFIBJq+gkFW70/htyyGm/Lado8ddvYzqRYVzVf8kIsNDGd6xEa0bRJ/y52kiUEqpAHbkWC7P/riRvWnHWZV8lMNuDcwA4/s057zOTWgRH0Xz+lEn9RmaCJRSqhp5ftYmXv5lC/mFxa/PV/dvwSMXdTqpc/pt0jkRGQm8AIQCbxpjnvTYfwVwj+NlJnCzMWaVL2NSSqlAd8ewttwxrC3Hcwv4bNludhzMot1p0QzvcJpPPs9niUBEQoFXgHOBZGCJiHxljFnndth24ExjzBERGQW8DvT1VUxKKVWd1K4VylX9k3z+Ob7sr9QH2GKM2WaMyQU+Bi5yP8AYs8AYc8Tx8negmQ/jUUop5YUvE0FTYLfb62THttJcB3zvbYeITBKRpSKyNDU1tRJDVEop5ctE4G0MtdeWaRE5C5sI7vG23xjzujGmlzGmV4MGDSoxRKWUUr5sLE4G3MdPNwP2eh4kIl2AN4FRxphDPoxHKaWUF74sESwB2ohISxGpBVwOfOV+gIgkAjOAK40xm3wYi1JKqVL4rERgjMkXkb8CP2C7j04xxqwVkZsc+ycDDwLxwKuO2fjyS+vnqpRSyjd0QJlSSgUBXaFMKaVUqapdiUBEUoGdJ/n2BOBgJYbjaxqv71SnWKF6xVudYoXqFe+pxNrCGOO122W1SwSnQkSWVqc2CI3Xd6pTrFC94q1OsUL1itdXsWrVkFJKBTlNBEopFeSCLRG87u8ATpDG6zvVKVaoXvFWp1ihesXrk1iDqo1AKaVUScFWIlBKKeVBE4FSSgW5oEkEIjJSRDaKyBYRudff8QCIyBQRSRGRNW7b6ovITyKy2fFYz23ffY74N4rIiCqOtbmIzBaR9SKyVkRuD9R4RSRSRBaLyCpHrI8Eaqxunx8qIitE5JtqEOsOEVktIitFZGk1iDdORKaJyAbH72//QIxXRNo5/k2dP+kickeVxGqMqfE/2LmOtgKtgFrAKqBDAMQ1BOgBrHHb9jRwr+P5vcBTjucdHHFHAC0d3ye0CmNtDPRwPI8BNjliCrh4sVOgRzuehwOLgH6BGKtbzHcCHwHfBPLvgSOGHUCCx7ZAjvdd4HrH81pAXCDH64gjFNgPtKiKWKv0y/nrB+gP/OD2+j7gPn/H5YglieKJYCPQ2PG8MbDRW8zYyfz6+zHuL7HLkAZ0vEAUsBy7BGpAxoqdov1n4Gy3RBCQsTo+01siCMh4gbrYJXGlOsTr9rnDgd+qKtZgqRo60dXS/KmRMWYfgOOxoWN7wHwHEUkCumPvtAMyXkdVy0ogBfjJGBOwsQLPA38HCt22BWqsYBeY+lFElonIJMe2QI23FZAKvO2oentTROoEcLxOlwNTHc99HmuwJIIKr5YWwALiO4hINDAduMMYk17WoV62VVm8xpgCY0w37N12HxHpVMbhfotVRM4HUowxyyr6Fi/bqvr3YKAxpgcwCrhFRIaUcay/4w3DVr/+zxjTHTiGrV4pjb/jxbF+y4XAZ+Ud6mXbScUaLImgQqulBYgDItIYwPGY4tju9+8gIuHYJPChMWaGY3PAxgtgjEkD5gAjCcxYBwIXisgO4GPgbBH5IEBjBcAYs9fxmAJ8DvQhcONNBpIdJUKAadjEEKjxgk2wy40xBxyvfR5rsCSCcldLCyBfAVc7nl+NrYt3br9cRCJEpCXQBlhcVUGJiABvAeuNMc8Fcrwi0kBE4hzPawPDgA2BGKsx5j5jTDNjTBL29/IXY8zEQIwVQETqiEiM8zm2LntNoMZrjNkP7BaRdo5N5wDrAjVeh/G4qoWcMfk21qpuBPHXDzAa29NlK/APf8fjiGkqsA/Iw2b367Artv0MbHY81nc7/h+O+Ddi13iuylgHYYudfwArHT+jAzFeoAuwwhHrGuBBx/aAi9Uj7qG4whOr9wAAAgtJREFUGosDMlZsnfsqx89a599SoMbr+PxuwFLH78MXQL1AjRfbueEQEOu2zeex6hQTSikV5IKlakgppVQpNBEopVSQ00SglFJBThOBUkoFOU0ESikV5DQRKFWFRGSoc4ZRpQKFJgKllApymgiU8kJEJjrWNFgpIq85JrHLFJH/iMhyEflZRBo4ju0mIr+LyB8i8rlzvngROV1EZoldF2G5iLR2nD7abX78Dx2jtpXyG00ESnkQkfbAZdjJ1boBBcAVQB3sHDA9gLnAQ463vAfcY4zpAqx22/4h8IoxpiswADuKHOzMrXdg55NvhZ1vSCm/CfN3AEoFoHOAnsASx816bexEX4XAJ45jPgBmiEgsEGeMmevY/i7wmWM+nqbGmM8BjDHZAI7zLTbGJDter8SuSfGr77+WUt5pIlCqJAHeNcbcV2yjyAMex5U1P0tZ1T05bs8L0L9D5WdaNaRUST8DY0WkIRStx9sC+/cy1nHMBOBXY8xR4IiIDHZsvxKYa+xaDckicrHjHBEiElWl30KpCtI7EaU8GGPWicg/satwhWBnh70Fu6hJRxFZBhzFtiOAnRp4suNCvw241rH9SuA1EXnUcY4/VeHXUKrCdPZRpSpIRDKNMdH+jkOpyqZVQ0opFeS0RKCUUkFOSwRKKRXkNBEopVSQ00SglFJBThOBUkoFOU0ESikV5P4fVUW67i5S4WgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
